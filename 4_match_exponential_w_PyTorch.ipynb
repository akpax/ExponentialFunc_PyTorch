{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkAlvuBKr1ZZNqaqZPJWa9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akpax/ExponentialFunc_PyTorch/blob/main/4_match_exponential_w_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: Use PyTorch to find the optimal exponential function parameters to match an exponential with noise  "
      ],
      "metadata": {
        "id": "_JFqzJlasMp-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Sdf7EuDzbQ23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a55975-1f5e-4887-f2a6-c1d5d4424054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install torch\n",
        "! pip install matplotlib\n",
        "! pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from matplotlib.pyplot import scatter\n",
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "z9UdHMegcfPh"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(30)\n",
        "target = torch.randn(30)*10+0.5*(x-10)**2"
      ],
      "metadata": {
        "id": "4nhrfO-7b7xN"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scatter(x,target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "pKgQjbyYcQWE",
        "outputId": "8f75bb31-e568-426c-d9f1-c4feaba205c8"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7962d2695d20>"
            ]
          },
          "metadata": {},
          "execution_count": 219
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x,params):\n",
        "  a,b,c=params\n",
        "  return a*(x**2)+(b*x)+c\n"
      ],
      "metadata": {
        "id": "Hqa0EFqBdCXQ"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize params\n",
        "params = torch.randn(3).requires_grad_()\n",
        "pred = f(x,params)"
      ],
      "metadata": {
        "id": "A82DnM2UebdH"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(pred, target):\n",
        "  return ((pred-target)**2).mean().sqrt()"
      ],
      "metadata": {
        "id": "FSwJQjB1eqwu"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = mse(pred, target)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "uQBSFpl0esB3"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(params.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwUwV1wWiJQj",
        "outputId": "6c33c9f8-d4e0-49c4-f593-b1633cd1b758"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([382.9302,  16.4901,   0.7380])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "params.data -= lr*params.grad.data\n",
        "params.grad = None"
      ],
      "metadata": {
        "id": "Bx5JZzStfYkF"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine above steps into a function\n",
        "def step_forward(params):\n",
        "  pred = f(x,params)\n",
        "  loss = mse(pred, target)\n",
        "  loss.backward()\n",
        "  params.data -= lr*params.grad.data\n",
        "  params.grad = None\n",
        "  print(params)\n",
        "  print(f\"Loss: {loss}\")\n",
        "  return pred,loss"
      ],
      "metadata": {
        "id": "uSkRyEJCgIoy"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iUnM8L9UsKxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TnAWsOiksLna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while loss>10:\n",
        "  pred,loss = step_forward(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4fRjIDcPkIah",
        "outputId": "99f7bc3f-0686-4838-fa75-fa2f287b9600"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "tensor([ 0.3029, -3.0590,  1.7072], requires_grad=True)\n",
            "Loss: 22.502803802490234\n",
            "tensor([ 0.3029, -3.0590,  1.7072], requires_grad=True)\n",
            "Loss: 22.502796173095703\n",
            "tensor([ 0.3029, -3.0590,  1.7073], requires_grad=True)\n",
            "Loss: 22.502784729003906\n",
            "tensor([ 0.3029, -3.0590,  1.7073], requires_grad=True)\n",
            "Loss: 22.502779006958008\n",
            "tensor([ 0.3029, -3.0590,  1.7073], requires_grad=True)\n",
            "Loss: 22.502769470214844\n",
            "tensor([ 0.3029, -3.0590,  1.7073], requires_grad=True)\n",
            "Loss: 22.502761840820312\n",
            "tensor([ 0.3029, -3.0590,  1.7074], requires_grad=True)\n",
            "Loss: 22.50275230407715\n",
            "tensor([ 0.3029, -3.0590,  1.7074], requires_grad=True)\n",
            "Loss: 22.502742767333984\n",
            "tensor([ 0.3029, -3.0590,  1.7074], requires_grad=True)\n",
            "Loss: 22.502735137939453\n",
            "tensor([ 0.3029, -3.0590,  1.7075], requires_grad=True)\n",
            "Loss: 22.50272560119629\n",
            "tensor([ 0.3029, -3.0590,  1.7075], requires_grad=True)\n",
            "Loss: 22.502716064453125\n",
            "tensor([ 0.3029, -3.0590,  1.7075], requires_grad=True)\n",
            "Loss: 22.502710342407227\n",
            "tensor([ 0.3029, -3.0591,  1.7075], requires_grad=True)\n",
            "Loss: 22.50269889831543\n",
            "tensor([ 0.3029, -3.0591,  1.7076], requires_grad=True)\n",
            "Loss: 22.502689361572266\n",
            "tensor([ 0.3029, -3.0591,  1.7076], requires_grad=True)\n",
            "Loss: 22.502683639526367\n",
            "tensor([ 0.3029, -3.0591,  1.7076], requires_grad=True)\n",
            "Loss: 22.502674102783203\n",
            "tensor([ 0.3029, -3.0591,  1.7077], requires_grad=True)\n",
            "Loss: 22.502666473388672\n",
            "tensor([ 0.3029, -3.0591,  1.7077], requires_grad=True)\n",
            "Loss: 22.502656936645508\n",
            "tensor([ 0.3029, -3.0591,  1.7077], requires_grad=True)\n",
            "Loss: 22.502649307250977\n",
            "tensor([ 0.3029, -3.0591,  1.7077], requires_grad=True)\n",
            "Loss: 22.502639770507812\n",
            "tensor([ 0.3029, -3.0591,  1.7078], requires_grad=True)\n",
            "Loss: 22.50263214111328\n",
            "tensor([ 0.3029, -3.0591,  1.7078], requires_grad=True)\n",
            "Loss: 22.50262451171875\n",
            "tensor([ 0.3029, -3.0591,  1.7078], requires_grad=True)\n",
            "Loss: 22.502614974975586\n",
            "tensor([ 0.3029, -3.0591,  1.7079], requires_grad=True)\n",
            "Loss: 22.502607345581055\n",
            "tensor([ 0.3029, -3.0591,  1.7079], requires_grad=True)\n",
            "Loss: 22.502595901489258\n",
            "tensor([ 0.3029, -3.0592,  1.7079], requires_grad=True)\n",
            "Loss: 22.502588272094727\n",
            "tensor([ 0.3029, -3.0592,  1.7079], requires_grad=True)\n",
            "Loss: 22.502578735351562\n",
            "tensor([ 0.3029, -3.0592,  1.7080], requires_grad=True)\n",
            "Loss: 22.50257110595703\n",
            "tensor([ 0.3029, -3.0592,  1.7080], requires_grad=True)\n",
            "Loss: 22.502561569213867\n",
            "tensor([ 0.3029, -3.0592,  1.7080], requires_grad=True)\n",
            "Loss: 22.502553939819336\n",
            "tensor([ 0.3029, -3.0592,  1.7081], requires_grad=True)\n",
            "Loss: 22.502546310424805\n",
            "tensor([ 0.3029, -3.0592,  1.7081], requires_grad=True)\n",
            "Loss: 22.50253677368164\n",
            "tensor([ 0.3029, -3.0592,  1.7081], requires_grad=True)\n",
            "Loss: 22.50252914428711\n",
            "tensor([ 0.3029, -3.0592,  1.7081], requires_grad=True)\n",
            "Loss: 22.502517700195312\n",
            "tensor([ 0.3029, -3.0592,  1.7082], requires_grad=True)\n",
            "Loss: 22.502511978149414\n",
            "tensor([ 0.3029, -3.0592,  1.7082], requires_grad=True)\n",
            "Loss: 22.50250244140625\n",
            "tensor([ 0.3029, -3.0592,  1.7082], requires_grad=True)\n",
            "Loss: 22.50249481201172\n",
            "tensor([ 0.3029, -3.0592,  1.7083], requires_grad=True)\n",
            "Loss: 22.502485275268555\n",
            "tensor([ 0.3029, -3.0592,  1.7083], requires_grad=True)\n",
            "Loss: 22.50247573852539\n",
            "tensor([ 0.3029, -3.0593,  1.7083], requires_grad=True)\n",
            "Loss: 22.502470016479492\n",
            "tensor([ 0.3029, -3.0593,  1.7083], requires_grad=True)\n",
            "Loss: 22.502460479736328\n",
            "tensor([ 0.3029, -3.0593,  1.7084], requires_grad=True)\n",
            "Loss: 22.502450942993164\n",
            "tensor([ 0.3029, -3.0593,  1.7084], requires_grad=True)\n",
            "Loss: 22.50244140625\n",
            "tensor([ 0.3029, -3.0593,  1.7084], requires_grad=True)\n",
            "Loss: 22.50243377685547\n",
            "tensor([ 0.3029, -3.0593,  1.7085], requires_grad=True)\n",
            "Loss: 22.502424240112305\n",
            "tensor([ 0.3029, -3.0593,  1.7085], requires_grad=True)\n",
            "Loss: 22.502416610717773\n",
            "tensor([ 0.3029, -3.0593,  1.7085], requires_grad=True)\n",
            "Loss: 22.502408981323242\n",
            "tensor([ 0.3029, -3.0593,  1.7085], requires_grad=True)\n",
            "Loss: 22.502399444580078\n",
            "tensor([ 0.3029, -3.0593,  1.7086], requires_grad=True)\n",
            "Loss: 22.502389907836914\n",
            "tensor([ 0.3029, -3.0593,  1.7086], requires_grad=True)\n",
            "Loss: 22.502382278442383\n",
            "tensor([ 0.3029, -3.0593,  1.7086], requires_grad=True)\n",
            "Loss: 22.50237464904785\n",
            "tensor([ 0.3029, -3.0593,  1.7087], requires_grad=True)\n",
            "Loss: 22.502365112304688\n",
            "tensor([ 0.3029, -3.0594,  1.7087], requires_grad=True)\n",
            "Loss: 22.502355575561523\n",
            "tensor([ 0.3029, -3.0594,  1.7087], requires_grad=True)\n",
            "Loss: 22.502347946166992\n",
            "tensor([ 0.3029, -3.0594,  1.7087], requires_grad=True)\n",
            "Loss: 22.50234031677246\n",
            "tensor([ 0.3029, -3.0594,  1.7088], requires_grad=True)\n",
            "Loss: 22.502330780029297\n",
            "tensor([ 0.3029, -3.0594,  1.7088], requires_grad=True)\n",
            "Loss: 22.502321243286133\n",
            "tensor([ 0.3029, -3.0594,  1.7088], requires_grad=True)\n",
            "Loss: 22.50231170654297\n",
            "tensor([ 0.3029, -3.0594,  1.7089], requires_grad=True)\n",
            "Loss: 22.502304077148438\n",
            "tensor([ 0.3029, -3.0594,  1.7089], requires_grad=True)\n",
            "Loss: 22.50229835510254\n",
            "tensor([ 0.3029, -3.0594,  1.7089], requires_grad=True)\n",
            "Loss: 22.502288818359375\n",
            "tensor([ 0.3029, -3.0594,  1.7089], requires_grad=True)\n",
            "Loss: 22.502277374267578\n",
            "tensor([ 0.3029, -3.0594,  1.7090], requires_grad=True)\n",
            "Loss: 22.502269744873047\n",
            "tensor([ 0.3029, -3.0594,  1.7090], requires_grad=True)\n",
            "Loss: 22.502262115478516\n",
            "tensor([ 0.3029, -3.0594,  1.7090], requires_grad=True)\n",
            "Loss: 22.50225257873535\n",
            "tensor([ 0.3029, -3.0594,  1.7091], requires_grad=True)\n",
            "Loss: 22.502243041992188\n",
            "tensor([ 0.3029, -3.0595,  1.7091], requires_grad=True)\n",
            "Loss: 22.502235412597656\n",
            "tensor([ 0.3029, -3.0595,  1.7091], requires_grad=True)\n",
            "Loss: 22.502225875854492\n",
            "tensor([ 0.3029, -3.0595,  1.7091], requires_grad=True)\n",
            "Loss: 22.50221824645996\n",
            "tensor([ 0.3029, -3.0595,  1.7092], requires_grad=True)\n",
            "Loss: 22.502208709716797\n",
            "tensor([ 0.3029, -3.0595,  1.7092], requires_grad=True)\n",
            "Loss: 22.502201080322266\n",
            "tensor([ 0.3029, -3.0595,  1.7092], requires_grad=True)\n",
            "Loss: 22.5021915435791\n",
            "tensor([ 0.3029, -3.0595,  1.7093], requires_grad=True)\n",
            "Loss: 22.50218391418457\n",
            "tensor([ 0.3029, -3.0595,  1.7093], requires_grad=True)\n",
            "Loss: 22.50217628479004\n",
            "tensor([ 0.3029, -3.0595,  1.7093], requires_grad=True)\n",
            "Loss: 22.502166748046875\n",
            "tensor([ 0.3029, -3.0595,  1.7093], requires_grad=True)\n",
            "Loss: 22.502159118652344\n",
            "tensor([ 0.3029, -3.0595,  1.7094], requires_grad=True)\n",
            "Loss: 22.50214958190918\n",
            "tensor([ 0.3029, -3.0595,  1.7094], requires_grad=True)\n",
            "Loss: 22.502140045166016\n",
            "tensor([ 0.3029, -3.0595,  1.7094], requires_grad=True)\n",
            "Loss: 22.502134323120117\n",
            "tensor([ 0.3029, -3.0596,  1.7094], requires_grad=True)\n",
            "Loss: 22.50212287902832\n",
            "tensor([ 0.3029, -3.0596,  1.7095], requires_grad=True)\n",
            "Loss: 22.50211524963379\n",
            "tensor([ 0.3029, -3.0596,  1.7095], requires_grad=True)\n",
            "Loss: 22.502107620239258\n",
            "tensor([ 0.3029, -3.0596,  1.7095], requires_grad=True)\n",
            "Loss: 22.502098083496094\n",
            "tensor([ 0.3029, -3.0596,  1.7096], requires_grad=True)\n",
            "Loss: 22.50208854675293\n",
            "tensor([ 0.3029, -3.0596,  1.7096], requires_grad=True)\n",
            "Loss: 22.5020809173584\n",
            "tensor([ 0.3029, -3.0596,  1.7096], requires_grad=True)\n",
            "Loss: 22.502071380615234\n",
            "tensor([ 0.3029, -3.0596,  1.7096], requires_grad=True)\n",
            "Loss: 22.502063751220703\n",
            "tensor([ 0.3029, -3.0596,  1.7097], requires_grad=True)\n",
            "Loss: 22.50205421447754\n",
            "tensor([ 0.3029, -3.0596,  1.7097], requires_grad=True)\n",
            "Loss: 22.502046585083008\n",
            "tensor([ 0.3029, -3.0596,  1.7097], requires_grad=True)\n",
            "Loss: 22.502037048339844\n",
            "tensor([ 0.3029, -3.0596,  1.7098], requires_grad=True)\n",
            "Loss: 22.50202751159668\n",
            "tensor([ 0.3029, -3.0596,  1.7098], requires_grad=True)\n",
            "Loss: 22.50202178955078\n",
            "tensor([ 0.3029, -3.0596,  1.7098], requires_grad=True)\n",
            "Loss: 22.502010345458984\n",
            "tensor([ 0.3029, -3.0597,  1.7098], requires_grad=True)\n",
            "Loss: 22.502002716064453\n",
            "tensor([ 0.3029, -3.0597,  1.7099], requires_grad=True)\n",
            "Loss: 22.501995086669922\n",
            "tensor([ 0.3029, -3.0597,  1.7099], requires_grad=True)\n",
            "Loss: 22.501985549926758\n",
            "tensor([ 0.3029, -3.0597,  1.7099], requires_grad=True)\n",
            "Loss: 22.501977920532227\n",
            "tensor([ 0.3029, -3.0597,  1.7100], requires_grad=True)\n",
            "Loss: 22.501968383789062\n",
            "tensor([ 0.3029, -3.0597,  1.7100], requires_grad=True)\n",
            "Loss: 22.50196075439453\n",
            "tensor([ 0.3029, -3.0597,  1.7100], requires_grad=True)\n",
            "Loss: 22.501953125\n",
            "tensor([ 0.3029, -3.0597,  1.7100], requires_grad=True)\n",
            "Loss: 22.501943588256836\n",
            "tensor([ 0.3029, -3.0597,  1.7101], requires_grad=True)\n",
            "Loss: 22.501935958862305\n",
            "tensor([ 0.3029, -3.0597,  1.7101], requires_grad=True)\n",
            "Loss: 22.501928329467773\n",
            "tensor([ 0.3029, -3.0597,  1.7101], requires_grad=True)\n",
            "Loss: 22.50191879272461\n",
            "tensor([ 0.3029, -3.0597,  1.7102], requires_grad=True)\n",
            "Loss: 22.501907348632812\n",
            "tensor([ 0.3029, -3.0597,  1.7102], requires_grad=True)\n",
            "Loss: 22.50189971923828\n",
            "tensor([ 0.3029, -3.0598,  1.7102], requires_grad=True)\n",
            "Loss: 22.501890182495117\n",
            "tensor([ 0.3029, -3.0598,  1.7102], requires_grad=True)\n",
            "Loss: 22.501882553100586\n",
            "tensor([ 0.3029, -3.0598,  1.7103], requires_grad=True)\n",
            "Loss: 22.501874923706055\n",
            "tensor([ 0.3029, -3.0598,  1.7103], requires_grad=True)\n",
            "Loss: 22.50186538696289\n",
            "tensor([ 0.3029, -3.0598,  1.7103], requires_grad=True)\n",
            "Loss: 22.501855850219727\n",
            "tensor([ 0.3029, -3.0598,  1.7104], requires_grad=True)\n",
            "Loss: 22.501848220825195\n",
            "tensor([ 0.3029, -3.0598,  1.7104], requires_grad=True)\n",
            "Loss: 22.501840591430664\n",
            "tensor([ 0.3029, -3.0598,  1.7104], requires_grad=True)\n",
            "Loss: 22.501829147338867\n",
            "tensor([ 0.3029, -3.0598,  1.7104], requires_grad=True)\n",
            "Loss: 22.501821517944336\n",
            "tensor([ 0.3029, -3.0598,  1.7105], requires_grad=True)\n",
            "Loss: 22.501811981201172\n",
            "tensor([ 0.3029, -3.0598,  1.7105], requires_grad=True)\n",
            "Loss: 22.50180435180664\n",
            "tensor([ 0.3029, -3.0598,  1.7105], requires_grad=True)\n",
            "Loss: 22.50179672241211\n",
            "tensor([ 0.3029, -3.0598,  1.7106], requires_grad=True)\n",
            "Loss: 22.501789093017578\n",
            "tensor([ 0.3029, -3.0598,  1.7106], requires_grad=True)\n",
            "Loss: 22.501779556274414\n",
            "tensor([ 0.3029, -3.0599,  1.7106], requires_grad=True)\n",
            "Loss: 22.50177001953125\n",
            "tensor([ 0.3029, -3.0599,  1.7106], requires_grad=True)\n",
            "Loss: 22.501760482788086\n",
            "tensor([ 0.3029, -3.0599,  1.7107], requires_grad=True)\n",
            "Loss: 22.501752853393555\n",
            "tensor([ 0.3029, -3.0599,  1.7107], requires_grad=True)\n",
            "Loss: 22.501745223999023\n",
            "tensor([ 0.3029, -3.0599,  1.7107], requires_grad=True)\n",
            "Loss: 22.501737594604492\n",
            "tensor([ 0.3029, -3.0599,  1.7108], requires_grad=True)\n",
            "Loss: 22.501728057861328\n",
            "tensor([ 0.3029, -3.0599,  1.7108], requires_grad=True)\n",
            "Loss: 22.501718521118164\n",
            "tensor([ 0.3029, -3.0599,  1.7108], requires_grad=True)\n",
            "Loss: 22.501710891723633\n",
            "tensor([ 0.3029, -3.0599,  1.7108], requires_grad=True)\n",
            "Loss: 22.50170135498047\n",
            "tensor([ 0.3029, -3.0599,  1.7109], requires_grad=True)\n",
            "Loss: 22.501693725585938\n",
            "tensor([ 0.3029, -3.0599,  1.7109], requires_grad=True)\n",
            "Loss: 22.501686096191406\n",
            "tensor([ 0.3029, -3.0599,  1.7109], requires_grad=True)\n",
            "Loss: 22.501676559448242\n",
            "tensor([ 0.3029, -3.0599,  1.7110], requires_grad=True)\n",
            "Loss: 22.50166893005371\n",
            "tensor([ 0.3029, -3.0600,  1.7110], requires_grad=True)\n",
            "Loss: 22.50166130065918\n",
            "tensor([ 0.3029, -3.0600,  1.7110], requires_grad=True)\n",
            "Loss: 22.501649856567383\n",
            "tensor([ 0.3029, -3.0600,  1.7110], requires_grad=True)\n",
            "Loss: 22.50164222717285\n",
            "tensor([ 0.3029, -3.0600,  1.7111], requires_grad=True)\n",
            "Loss: 22.501632690429688\n",
            "tensor([ 0.3029, -3.0600,  1.7111], requires_grad=True)\n",
            "Loss: 22.501625061035156\n",
            "tensor([ 0.3029, -3.0600,  1.7111], requires_grad=True)\n",
            "Loss: 22.501615524291992\n",
            "tensor([ 0.3029, -3.0600,  1.7112], requires_grad=True)\n",
            "Loss: 22.50160789489746\n",
            "tensor([ 0.3029, -3.0600,  1.7112], requires_grad=True)\n",
            "Loss: 22.501598358154297\n",
            "tensor([ 0.3029, -3.0600,  1.7112], requires_grad=True)\n",
            "Loss: 22.501588821411133\n",
            "tensor([ 0.3029, -3.0600,  1.7112], requires_grad=True)\n",
            "Loss: 22.5015811920166\n",
            "tensor([ 0.3029, -3.0600,  1.7113], requires_grad=True)\n",
            "Loss: 22.501571655273438\n",
            "tensor([ 0.3029, -3.0600,  1.7113], requires_grad=True)\n",
            "Loss: 22.50156593322754\n",
            "tensor([ 0.3029, -3.0600,  1.7113], requires_grad=True)\n",
            "Loss: 22.501556396484375\n",
            "tensor([ 0.3029, -3.0600,  1.7113], requires_grad=True)\n",
            "Loss: 22.50154685974121\n",
            "tensor([ 0.3029, -3.0601,  1.7114], requires_grad=True)\n",
            "Loss: 22.50153923034668\n",
            "tensor([ 0.3029, -3.0601,  1.7114], requires_grad=True)\n",
            "Loss: 22.501529693603516\n",
            "tensor([ 0.3029, -3.0601,  1.7114], requires_grad=True)\n",
            "Loss: 22.501522064208984\n",
            "tensor([ 0.3029, -3.0601,  1.7115], requires_grad=True)\n",
            "Loss: 22.50151252746582\n",
            "tensor([ 0.3029, -3.0601,  1.7115], requires_grad=True)\n",
            "Loss: 22.50150489807129\n",
            "tensor([ 0.3029, -3.0601,  1.7115], requires_grad=True)\n",
            "Loss: 22.501495361328125\n",
            "tensor([ 0.3029, -3.0601,  1.7115], requires_grad=True)\n",
            "Loss: 22.501487731933594\n",
            "tensor([ 0.3029, -3.0601,  1.7116], requires_grad=True)\n",
            "Loss: 22.50147819519043\n",
            "tensor([ 0.3029, -3.0601,  1.7116], requires_grad=True)\n",
            "Loss: 22.501468658447266\n",
            "tensor([ 0.3029, -3.0601,  1.7116], requires_grad=True)\n",
            "Loss: 22.501461029052734\n",
            "tensor([ 0.3029, -3.0601,  1.7117], requires_grad=True)\n",
            "Loss: 22.501453399658203\n",
            "tensor([ 0.3029, -3.0601,  1.7117], requires_grad=True)\n",
            "Loss: 22.501445770263672\n",
            "tensor([ 0.3029, -3.0601,  1.7117], requires_grad=True)\n",
            "Loss: 22.501436233520508\n",
            "tensor([ 0.3029, -3.0601,  1.7117], requires_grad=True)\n",
            "Loss: 22.501426696777344\n",
            "tensor([ 0.3029, -3.0602,  1.7118], requires_grad=True)\n",
            "Loss: 22.501419067382812\n",
            "tensor([ 0.3029, -3.0602,  1.7118], requires_grad=True)\n",
            "Loss: 22.501407623291016\n",
            "tensor([ 0.3029, -3.0602,  1.7118], requires_grad=True)\n",
            "Loss: 22.501399993896484\n",
            "tensor([ 0.3029, -3.0602,  1.7119], requires_grad=True)\n",
            "Loss: 22.50139045715332\n",
            "tensor([ 0.3029, -3.0602,  1.7119], requires_grad=True)\n",
            "Loss: 22.50138282775879\n",
            "tensor([ 0.3029, -3.0602,  1.7119], requires_grad=True)\n",
            "Loss: 22.501375198364258\n",
            "tensor([ 0.3029, -3.0602,  1.7119], requires_grad=True)\n",
            "Loss: 22.501367568969727\n",
            "tensor([ 0.3029, -3.0602,  1.7120], requires_grad=True)\n",
            "Loss: 22.501358032226562\n",
            "tensor([ 0.3029, -3.0602,  1.7120], requires_grad=True)\n",
            "Loss: 22.5013484954834\n",
            "tensor([ 0.3029, -3.0602,  1.7120], requires_grad=True)\n",
            "Loss: 22.501340866088867\n",
            "tensor([ 0.3029, -3.0602,  1.7121], requires_grad=True)\n",
            "Loss: 22.501331329345703\n",
            "tensor([ 0.3029, -3.0602,  1.7121], requires_grad=True)\n",
            "Loss: 22.501323699951172\n",
            "tensor([ 0.3029, -3.0602,  1.7121], requires_grad=True)\n",
            "Loss: 22.50131607055664\n",
            "tensor([ 0.3029, -3.0603,  1.7121], requires_grad=True)\n",
            "Loss: 22.50130844116211\n",
            "tensor([ 0.3029, -3.0603,  1.7122], requires_grad=True)\n",
            "Loss: 22.501298904418945\n",
            "tensor([ 0.3029, -3.0603,  1.7122], requires_grad=True)\n",
            "Loss: 22.50128936767578\n",
            "tensor([ 0.3029, -3.0603,  1.7122], requires_grad=True)\n",
            "Loss: 22.501279830932617\n",
            "tensor([ 0.3029, -3.0603,  1.7123], requires_grad=True)\n",
            "Loss: 22.501272201538086\n",
            "tensor([ 0.3029, -3.0603,  1.7123], requires_grad=True)\n",
            "Loss: 22.501262664794922\n",
            "tensor([ 0.3029, -3.0603,  1.7123], requires_grad=True)\n",
            "Loss: 22.50125503540039\n",
            "tensor([ 0.3029, -3.0603,  1.7123], requires_grad=True)\n",
            "Loss: 22.501245498657227\n",
            "tensor([ 0.3029, -3.0603,  1.7124], requires_grad=True)\n",
            "Loss: 22.501239776611328\n",
            "tensor([ 0.3029, -3.0603,  1.7124], requires_grad=True)\n",
            "Loss: 22.501230239868164\n",
            "tensor([ 0.3029, -3.0603,  1.7124], requires_grad=True)\n",
            "Loss: 22.501218795776367\n",
            "tensor([ 0.3029, -3.0603,  1.7125], requires_grad=True)\n",
            "Loss: 22.50121307373047\n",
            "tensor([ 0.3029, -3.0603,  1.7125], requires_grad=True)\n",
            "Loss: 22.501201629638672\n",
            "tensor([ 0.3029, -3.0603,  1.7125], requires_grad=True)\n",
            "Loss: 22.50119400024414\n",
            "tensor([ 0.3029, -3.0604,  1.7125], requires_grad=True)\n",
            "Loss: 22.501188278198242\n",
            "tensor([ 0.3029, -3.0604,  1.7126], requires_grad=True)\n",
            "Loss: 22.501178741455078\n",
            "tensor([ 0.3029, -3.0604,  1.7126], requires_grad=True)\n",
            "Loss: 22.50116729736328\n",
            "tensor([ 0.3029, -3.0604,  1.7126], requires_grad=True)\n",
            "Loss: 22.50115966796875\n",
            "tensor([ 0.3029, -3.0604,  1.7127], requires_grad=True)\n",
            "Loss: 22.50115203857422\n",
            "tensor([ 0.3029, -3.0604,  1.7127], requires_grad=True)\n",
            "Loss: 22.501142501831055\n",
            "tensor([ 0.3029, -3.0604,  1.7127], requires_grad=True)\n",
            "Loss: 22.50113296508789\n",
            "tensor([ 0.3029, -3.0604,  1.7127], requires_grad=True)\n",
            "Loss: 22.501127243041992\n",
            "tensor([ 0.3029, -3.0604,  1.7128], requires_grad=True)\n",
            "Loss: 22.501117706298828\n",
            "tensor([ 0.3029, -3.0604,  1.7128], requires_grad=True)\n",
            "Loss: 22.501108169555664\n",
            "tensor([ 0.3029, -3.0604,  1.7128], requires_grad=True)\n",
            "Loss: 22.501100540161133\n",
            "tensor([ 0.3029, -3.0604,  1.7129], requires_grad=True)\n",
            "Loss: 22.50109100341797\n",
            "tensor([ 0.3029, -3.0604,  1.7129], requires_grad=True)\n",
            "Loss: 22.501083374023438\n",
            "tensor([ 0.3029, -3.0605,  1.7129], requires_grad=True)\n",
            "Loss: 22.50107192993164\n",
            "tensor([ 0.3029, -3.0605,  1.7129], requires_grad=True)\n",
            "Loss: 22.501066207885742\n",
            "tensor([ 0.3029, -3.0605,  1.7130], requires_grad=True)\n",
            "Loss: 22.501056671142578\n",
            "tensor([ 0.3029, -3.0605,  1.7130], requires_grad=True)\n",
            "Loss: 22.501049041748047\n",
            "tensor([ 0.3029, -3.0605,  1.7130], requires_grad=True)\n",
            "Loss: 22.501039505004883\n",
            "tensor([ 0.3029, -3.0605,  1.7131], requires_grad=True)\n",
            "Loss: 22.50102996826172\n",
            "tensor([ 0.3029, -3.0605,  1.7131], requires_grad=True)\n",
            "Loss: 22.501020431518555\n",
            "tensor([ 0.3029, -3.0605,  1.7131], requires_grad=True)\n",
            "Loss: 22.501014709472656\n",
            "tensor([ 0.3029, -3.0605,  1.7131], requires_grad=True)\n",
            "Loss: 22.501005172729492\n",
            "tensor([ 0.3029, -3.0605,  1.7132], requires_grad=True)\n",
            "Loss: 22.50099754333496\n",
            "tensor([ 0.3029, -3.0605,  1.7132], requires_grad=True)\n",
            "Loss: 22.500988006591797\n",
            "tensor([ 0.3029, -3.0605,  1.7132], requires_grad=True)\n",
            "Loss: 22.500978469848633\n",
            "tensor([ 0.3029, -3.0605,  1.7133], requires_grad=True)\n",
            "Loss: 22.500972747802734\n",
            "tensor([ 0.3029, -3.0605,  1.7133], requires_grad=True)\n",
            "Loss: 22.50096321105957\n",
            "tensor([ 0.3029, -3.0606,  1.7133], requires_grad=True)\n",
            "Loss: 22.50095558166504\n",
            "tensor([ 0.3029, -3.0606,  1.7133], requires_grad=True)\n",
            "Loss: 22.500946044921875\n",
            "tensor([ 0.3029, -3.0606,  1.7134], requires_grad=True)\n",
            "Loss: 22.50093650817871\n",
            "tensor([ 0.3029, -3.0606,  1.7134], requires_grad=True)\n",
            "Loss: 22.50092887878418\n",
            "tensor([ 0.3029, -3.0606,  1.7134], requires_grad=True)\n",
            "Loss: 22.500919342041016\n",
            "tensor([ 0.3029, -3.0606,  1.7134], requires_grad=True)\n",
            "Loss: 22.50090980529785\n",
            "tensor([ 0.3029, -3.0606,  1.7135], requires_grad=True)\n",
            "Loss: 22.50090217590332\n",
            "tensor([ 0.3029, -3.0606,  1.7135], requires_grad=True)\n",
            "Loss: 22.50089454650879\n",
            "tensor([ 0.3029, -3.0606,  1.7135], requires_grad=True)\n",
            "Loss: 22.500886917114258\n",
            "tensor([ 0.3029, -3.0606,  1.7136], requires_grad=True)\n",
            "Loss: 22.500877380371094\n",
            "tensor([ 0.3029, -3.0606,  1.7136], requires_grad=True)\n",
            "Loss: 22.50086784362793\n",
            "tensor([ 0.3029, -3.0606,  1.7136], requires_grad=True)\n",
            "Loss: 22.5008602142334\n",
            "tensor([ 0.3029, -3.0606,  1.7136], requires_grad=True)\n",
            "Loss: 22.5008487701416\n",
            "tensor([ 0.3029, -3.0607,  1.7137], requires_grad=True)\n",
            "Loss: 22.500843048095703\n",
            "tensor([ 0.3029, -3.0607,  1.7137], requires_grad=True)\n",
            "Loss: 22.50083351135254\n",
            "tensor([ 0.3029, -3.0607,  1.7137], requires_grad=True)\n",
            "Loss: 22.500825881958008\n",
            "tensor([ 0.3030, -3.0607,  1.7138], requires_grad=True)\n",
            "Loss: 22.500816345214844\n",
            "tensor([ 0.3030, -3.0607,  1.7138], requires_grad=True)\n",
            "Loss: 22.500804901123047\n",
            "tensor([ 0.3030, -3.0607,  1.7138], requires_grad=True)\n",
            "Loss: 22.50079917907715\n",
            "tensor([ 0.3030, -3.0607,  1.7138], requires_grad=True)\n",
            "Loss: 22.500789642333984\n",
            "tensor([ 0.3030, -3.0607,  1.7139], requires_grad=True)\n",
            "Loss: 22.500782012939453\n",
            "tensor([ 0.3030, -3.0607,  1.7139], requires_grad=True)\n",
            "Loss: 22.50077247619629\n",
            "tensor([ 0.3030, -3.0607,  1.7139], requires_grad=True)\n",
            "Loss: 22.500764846801758\n",
            "tensor([ 0.3030, -3.0607,  1.7140], requires_grad=True)\n",
            "Loss: 22.500757217407227\n",
            "tensor([ 0.3030, -3.0607,  1.7140], requires_grad=True)\n",
            "Loss: 22.50074577331543\n",
            "tensor([ 0.3030, -3.0607,  1.7140], requires_grad=True)\n",
            "Loss: 22.5007381439209\n",
            "tensor([ 0.3030, -3.0607,  1.7140], requires_grad=True)\n",
            "Loss: 22.500728607177734\n",
            "tensor([ 0.3030, -3.0608,  1.7141], requires_grad=True)\n",
            "Loss: 22.500720977783203\n",
            "tensor([ 0.3030, -3.0608,  1.7141], requires_grad=True)\n",
            "Loss: 22.50071144104004\n",
            "tensor([ 0.3030, -3.0608,  1.7141], requires_grad=True)\n",
            "Loss: 22.500703811645508\n",
            "tensor([ 0.3030, -3.0608,  1.7142], requires_grad=True)\n",
            "Loss: 22.500694274902344\n",
            "tensor([ 0.3030, -3.0608,  1.7142], requires_grad=True)\n",
            "Loss: 22.500686645507812\n",
            "tensor([ 0.3030, -3.0608,  1.7142], requires_grad=True)\n",
            "Loss: 22.50067901611328\n",
            "tensor([ 0.3030, -3.0608,  1.7142], requires_grad=True)\n",
            "Loss: 22.50067138671875\n",
            "tensor([ 0.3030, -3.0608,  1.7143], requires_grad=True)\n",
            "Loss: 22.500659942626953\n",
            "tensor([ 0.3030, -3.0608,  1.7143], requires_grad=True)\n",
            "Loss: 22.500652313232422\n",
            "tensor([ 0.3030, -3.0608,  1.7143], requires_grad=True)\n",
            "Loss: 22.50064468383789\n",
            "tensor([ 0.3030, -3.0608,  1.7144], requires_grad=True)\n",
            "Loss: 22.50063705444336\n",
            "tensor([ 0.3030, -3.0608,  1.7144], requires_grad=True)\n",
            "Loss: 22.500627517700195\n",
            "tensor([ 0.3030, -3.0608,  1.7144], requires_grad=True)\n",
            "Loss: 22.50061798095703\n",
            "tensor([ 0.3030, -3.0608,  1.7144], requires_grad=True)\n",
            "Loss: 22.500608444213867\n",
            "tensor([ 0.3030, -3.0609,  1.7145], requires_grad=True)\n",
            "Loss: 22.500600814819336\n",
            "tensor([ 0.3030, -3.0609,  1.7145], requires_grad=True)\n",
            "Loss: 22.500591278076172\n",
            "tensor([ 0.3030, -3.0609,  1.7145], requires_grad=True)\n",
            "Loss: 22.50058364868164\n",
            "tensor([ 0.3030, -3.0609,  1.7146], requires_grad=True)\n",
            "Loss: 22.500574111938477\n",
            "tensor([ 0.3030, -3.0609,  1.7146], requires_grad=True)\n",
            "Loss: 22.500566482543945\n",
            "tensor([ 0.3030, -3.0609,  1.7146], requires_grad=True)\n",
            "Loss: 22.50055694580078\n",
            "tensor([ 0.3030, -3.0609,  1.7146], requires_grad=True)\n",
            "Loss: 22.500547409057617\n",
            "tensor([ 0.3030, -3.0609,  1.7147], requires_grad=True)\n",
            "Loss: 22.50054168701172\n",
            "tensor([ 0.3030, -3.0609,  1.7147], requires_grad=True)\n",
            "Loss: 22.500532150268555\n",
            "tensor([ 0.3030, -3.0609,  1.7147], requires_grad=True)\n",
            "Loss: 22.50052261352539\n",
            "tensor([ 0.3030, -3.0609,  1.7148], requires_grad=True)\n",
            "Loss: 22.500516891479492\n",
            "tensor([ 0.3030, -3.0609,  1.7148], requires_grad=True)\n",
            "Loss: 22.500507354736328\n",
            "tensor([ 0.3030, -3.0609,  1.7148], requires_grad=True)\n",
            "Loss: 22.500497817993164\n",
            "tensor([ 0.3030, -3.0609,  1.7148], requires_grad=True)\n",
            "Loss: 22.500490188598633\n",
            "tensor([ 0.3030, -3.0610,  1.7149], requires_grad=True)\n",
            "Loss: 22.50048065185547\n",
            "tensor([ 0.3030, -3.0610,  1.7149], requires_grad=True)\n",
            "Loss: 22.500473022460938\n",
            "tensor([ 0.3030, -3.0610,  1.7149], requires_grad=True)\n",
            "Loss: 22.500463485717773\n",
            "tensor([ 0.3030, -3.0610,  1.7150], requires_grad=True)\n",
            "Loss: 22.500455856323242\n",
            "tensor([ 0.3030, -3.0610,  1.7150], requires_grad=True)\n",
            "Loss: 22.500446319580078\n",
            "tensor([ 0.3030, -3.0610,  1.7150], requires_grad=True)\n",
            "Loss: 22.500438690185547\n",
            "tensor([ 0.3030, -3.0610,  1.7150], requires_grad=True)\n",
            "Loss: 22.50042724609375\n",
            "tensor([ 0.3030, -3.0610,  1.7151], requires_grad=True)\n",
            "Loss: 22.50041961669922\n",
            "tensor([ 0.3030, -3.0610,  1.7151], requires_grad=True)\n",
            "Loss: 22.500411987304688\n",
            "tensor([ 0.3030, -3.0610,  1.7151], requires_grad=True)\n",
            "Loss: 22.500404357910156\n",
            "tensor([ 0.3030, -3.0610,  1.7152], requires_grad=True)\n",
            "Loss: 22.500394821166992\n",
            "tensor([ 0.3030, -3.0610,  1.7152], requires_grad=True)\n",
            "Loss: 22.500385284423828\n",
            "tensor([ 0.3030, -3.0610,  1.7152], requires_grad=True)\n",
            "Loss: 22.500377655029297\n",
            "tensor([ 0.3030, -3.0610,  1.7152], requires_grad=True)\n",
            "Loss: 22.500368118286133\n",
            "tensor([ 0.3030, -3.0611,  1.7153], requires_grad=True)\n",
            "Loss: 22.50035858154297\n",
            "tensor([ 0.3030, -3.0611,  1.7153], requires_grad=True)\n",
            "Loss: 22.50035285949707\n",
            "tensor([ 0.3030, -3.0611,  1.7153], requires_grad=True)\n",
            "Loss: 22.500343322753906\n",
            "tensor([ 0.3030, -3.0611,  1.7154], requires_grad=True)\n",
            "Loss: 22.500335693359375\n",
            "tensor([ 0.3030, -3.0611,  1.7154], requires_grad=True)\n",
            "Loss: 22.50032615661621\n",
            "tensor([ 0.3030, -3.0611,  1.7154], requires_grad=True)\n",
            "Loss: 22.500316619873047\n",
            "tensor([ 0.3030, -3.0611,  1.7154], requires_grad=True)\n",
            "Loss: 22.500308990478516\n",
            "tensor([ 0.3030, -3.0611,  1.7155], requires_grad=True)\n",
            "Loss: 22.50029945373535\n",
            "tensor([ 0.3030, -3.0611,  1.7155], requires_grad=True)\n",
            "Loss: 22.500293731689453\n",
            "tensor([ 0.3030, -3.0611,  1.7155], requires_grad=True)\n",
            "Loss: 22.50028419494629\n",
            "tensor([ 0.3030, -3.0611,  1.7155], requires_grad=True)\n",
            "Loss: 22.500274658203125\n",
            "tensor([ 0.3030, -3.0611,  1.7156], requires_grad=True)\n",
            "Loss: 22.500267028808594\n",
            "tensor([ 0.3030, -3.0611,  1.7156], requires_grad=True)\n",
            "Loss: 22.50025749206543\n",
            "tensor([ 0.3030, -3.0611,  1.7156], requires_grad=True)\n",
            "Loss: 22.5002498626709\n",
            "tensor([ 0.3030, -3.0612,  1.7157], requires_grad=True)\n",
            "Loss: 22.5002384185791\n",
            "tensor([ 0.3030, -3.0612,  1.7157], requires_grad=True)\n",
            "Loss: 22.500232696533203\n",
            "tensor([ 0.3030, -3.0612,  1.7157], requires_grad=True)\n",
            "Loss: 22.50022315979004\n",
            "tensor([ 0.3030, -3.0612,  1.7157], requires_grad=True)\n",
            "Loss: 22.500213623046875\n",
            "tensor([ 0.3030, -3.0612,  1.7158], requires_grad=True)\n",
            "Loss: 22.500205993652344\n",
            "tensor([ 0.3030, -3.0612,  1.7158], requires_grad=True)\n",
            "Loss: 22.500198364257812\n",
            "tensor([ 0.3030, -3.0612,  1.7158], requires_grad=True)\n",
            "Loss: 22.50018882751465\n",
            "tensor([ 0.3030, -3.0612,  1.7159], requires_grad=True)\n",
            "Loss: 22.500181198120117\n",
            "tensor([ 0.3030, -3.0612,  1.7159], requires_grad=True)\n",
            "Loss: 22.500171661376953\n",
            "tensor([ 0.3030, -3.0612,  1.7159], requires_grad=True)\n",
            "Loss: 22.50016212463379\n",
            "tensor([ 0.3030, -3.0612,  1.7159], requires_grad=True)\n",
            "Loss: 22.500154495239258\n",
            "tensor([ 0.3030, -3.0612,  1.7160], requires_grad=True)\n",
            "Loss: 22.500144958496094\n",
            "tensor([ 0.3030, -3.0612,  1.7160], requires_grad=True)\n",
            "Loss: 22.500137329101562\n",
            "tensor([ 0.3030, -3.0612,  1.7160], requires_grad=True)\n",
            "Loss: 22.50012969970703\n",
            "tensor([ 0.3030, -3.0613,  1.7161], requires_grad=True)\n",
            "Loss: 22.500120162963867\n",
            "tensor([ 0.3030, -3.0613,  1.7161], requires_grad=True)\n",
            "Loss: 22.500110626220703\n",
            "tensor([ 0.3030, -3.0613,  1.7161], requires_grad=True)\n",
            "Loss: 22.500102996826172\n",
            "tensor([ 0.3030, -3.0613,  1.7161], requires_grad=True)\n",
            "Loss: 22.50009536743164\n",
            "tensor([ 0.3030, -3.0613,  1.7162], requires_grad=True)\n",
            "Loss: 22.50008773803711\n",
            "tensor([ 0.3030, -3.0613,  1.7162], requires_grad=True)\n",
            "Loss: 22.500078201293945\n",
            "tensor([ 0.3030, -3.0613,  1.7162], requires_grad=True)\n",
            "Loss: 22.50006866455078\n",
            "tensor([ 0.3030, -3.0613,  1.7163], requires_grad=True)\n",
            "Loss: 22.50006103515625\n",
            "tensor([ 0.3030, -3.0613,  1.7163], requires_grad=True)\n",
            "Loss: 22.500051498413086\n",
            "tensor([ 0.3030, -3.0613,  1.7163], requires_grad=True)\n",
            "Loss: 22.500041961669922\n",
            "tensor([ 0.3030, -3.0613,  1.7163], requires_grad=True)\n",
            "Loss: 22.500032424926758\n",
            "tensor([ 0.3030, -3.0613,  1.7164], requires_grad=True)\n",
            "Loss: 22.50002670288086\n",
            "tensor([ 0.3030, -3.0613,  1.7164], requires_grad=True)\n",
            "Loss: 22.500017166137695\n",
            "tensor([ 0.3030, -3.0613,  1.7164], requires_grad=True)\n",
            "Loss: 22.50000762939453\n",
            "tensor([ 0.3030, -3.0614,  1.7165], requires_grad=True)\n",
            "Loss: 22.5\n",
            "tensor([ 0.3030, -3.0614,  1.7165], requires_grad=True)\n",
            "Loss: 22.499990463256836\n",
            "tensor([ 0.3030, -3.0614,  1.7165], requires_grad=True)\n",
            "Loss: 22.499980926513672\n",
            "tensor([ 0.3030, -3.0614,  1.7165], requires_grad=True)\n",
            "Loss: 22.499975204467773\n",
            "tensor([ 0.3030, -3.0614,  1.7166], requires_grad=True)\n",
            "Loss: 22.49996566772461\n",
            "tensor([ 0.3030, -3.0614,  1.7166], requires_grad=True)\n",
            "Loss: 22.499958038330078\n",
            "tensor([ 0.3030, -3.0614,  1.7166], requires_grad=True)\n",
            "Loss: 22.499948501586914\n",
            "tensor([ 0.3030, -3.0614,  1.7167], requires_grad=True)\n",
            "Loss: 22.49993896484375\n",
            "tensor([ 0.3030, -3.0614,  1.7167], requires_grad=True)\n",
            "Loss: 22.49993133544922\n",
            "tensor([ 0.3030, -3.0614,  1.7167], requires_grad=True)\n",
            "Loss: 22.499921798706055\n",
            "tensor([ 0.3030, -3.0614,  1.7167], requires_grad=True)\n",
            "Loss: 22.499916076660156\n",
            "tensor([ 0.3030, -3.0614,  1.7168], requires_grad=True)\n",
            "Loss: 22.49990463256836\n",
            "tensor([ 0.3030, -3.0614,  1.7168], requires_grad=True)\n",
            "Loss: 22.499897003173828\n",
            "tensor([ 0.3030, -3.0614,  1.7168], requires_grad=True)\n",
            "Loss: 22.499889373779297\n",
            "tensor([ 0.3030, -3.0615,  1.7169], requires_grad=True)\n",
            "Loss: 22.499879837036133\n",
            "tensor([ 0.3030, -3.0615,  1.7169], requires_grad=True)\n",
            "Loss: 22.4998722076416\n",
            "tensor([ 0.3030, -3.0615,  1.7169], requires_grad=True)\n",
            "Loss: 22.499862670898438\n",
            "tensor([ 0.3030, -3.0615,  1.7169], requires_grad=True)\n",
            "Loss: 22.49985694885254\n",
            "tensor([ 0.3030, -3.0615,  1.7170], requires_grad=True)\n",
            "Loss: 22.499845504760742\n",
            "tensor([ 0.3030, -3.0615,  1.7170], requires_grad=True)\n",
            "Loss: 22.499835968017578\n",
            "tensor([ 0.3030, -3.0615,  1.7170], requires_grad=True)\n",
            "Loss: 22.499828338623047\n",
            "tensor([ 0.3030, -3.0615,  1.7171], requires_grad=True)\n",
            "Loss: 22.499818801879883\n",
            "tensor([ 0.3030, -3.0615,  1.7171], requires_grad=True)\n",
            "Loss: 22.49981117248535\n",
            "tensor([ 0.3030, -3.0615,  1.7171], requires_grad=True)\n",
            "Loss: 22.49980354309082\n",
            "tensor([ 0.3030, -3.0615,  1.7171], requires_grad=True)\n",
            "Loss: 22.499794006347656\n",
            "tensor([ 0.3030, -3.0615,  1.7172], requires_grad=True)\n",
            "Loss: 22.499786376953125\n",
            "tensor([ 0.3030, -3.0615,  1.7172], requires_grad=True)\n",
            "Loss: 22.49977684020996\n",
            "tensor([ 0.3030, -3.0615,  1.7172], requires_grad=True)\n",
            "Loss: 22.49976921081543\n",
            "tensor([ 0.3030, -3.0616,  1.7173], requires_grad=True)\n",
            "Loss: 22.499759674072266\n",
            "tensor([ 0.3030, -3.0616,  1.7173], requires_grad=True)\n",
            "Loss: 22.499752044677734\n",
            "tensor([ 0.3030, -3.0616,  1.7173], requires_grad=True)\n",
            "Loss: 22.49974250793457\n",
            "tensor([ 0.3030, -3.0616,  1.7173], requires_grad=True)\n",
            "Loss: 22.499732971191406\n",
            "tensor([ 0.3030, -3.0616,  1.7174], requires_grad=True)\n",
            "Loss: 22.499725341796875\n",
            "tensor([ 0.3030, -3.0616,  1.7174], requires_grad=True)\n",
            "Loss: 22.49971580505371\n",
            "tensor([ 0.3030, -3.0616,  1.7174], requires_grad=True)\n",
            "Loss: 22.499706268310547\n",
            "tensor([ 0.3030, -3.0616,  1.7174], requires_grad=True)\n",
            "Loss: 22.499698638916016\n",
            "tensor([ 0.3030, -3.0616,  1.7175], requires_grad=True)\n",
            "Loss: 22.499691009521484\n",
            "tensor([ 0.3030, -3.0616,  1.7175], requires_grad=True)\n",
            "Loss: 22.499683380126953\n",
            "tensor([ 0.3030, -3.0616,  1.7175], requires_grad=True)\n",
            "Loss: 22.49967384338379\n",
            "tensor([ 0.3030, -3.0616,  1.7176], requires_grad=True)\n",
            "Loss: 22.499666213989258\n",
            "tensor([ 0.3030, -3.0616,  1.7176], requires_grad=True)\n",
            "Loss: 22.499658584594727\n",
            "tensor([ 0.3030, -3.0616,  1.7176], requires_grad=True)\n",
            "Loss: 22.49964714050293\n",
            "tensor([ 0.3030, -3.0617,  1.7176], requires_grad=True)\n",
            "Loss: 22.49964141845703\n",
            "tensor([ 0.3030, -3.0617,  1.7177], requires_grad=True)\n",
            "Loss: 22.499631881713867\n",
            "tensor([ 0.3030, -3.0617,  1.7177], requires_grad=True)\n",
            "Loss: 22.499622344970703\n",
            "tensor([ 0.3030, -3.0617,  1.7177], requires_grad=True)\n",
            "Loss: 22.49961280822754\n",
            "tensor([ 0.3030, -3.0617,  1.7178], requires_grad=True)\n",
            "Loss: 22.499605178833008\n",
            "tensor([ 0.3030, -3.0617,  1.7178], requires_grad=True)\n",
            "Loss: 22.499595642089844\n",
            "tensor([ 0.3030, -3.0617,  1.7178], requires_grad=True)\n",
            "Loss: 22.499588012695312\n",
            "tensor([ 0.3030, -3.0617,  1.7178], requires_grad=True)\n",
            "Loss: 22.49957847595215\n",
            "tensor([ 0.3030, -3.0617,  1.7179], requires_grad=True)\n",
            "Loss: 22.499568939208984\n",
            "tensor([ 0.3030, -3.0617,  1.7179], requires_grad=True)\n",
            "Loss: 22.49955940246582\n",
            "tensor([ 0.3030, -3.0617,  1.7179], requires_grad=True)\n",
            "Loss: 22.499553680419922\n",
            "tensor([ 0.3030, -3.0617,  1.7180], requires_grad=True)\n",
            "Loss: 22.49954605102539\n",
            "tensor([ 0.3030, -3.0617,  1.7180], requires_grad=True)\n",
            "Loss: 22.499536514282227\n",
            "tensor([ 0.3030, -3.0617,  1.7180], requires_grad=True)\n",
            "Loss: 22.499528884887695\n",
            "tensor([ 0.3030, -3.0618,  1.7180], requires_grad=True)\n",
            "Loss: 22.49951934814453\n",
            "tensor([ 0.3030, -3.0618,  1.7181], requires_grad=True)\n",
            "Loss: 22.499509811401367\n",
            "tensor([ 0.3030, -3.0618,  1.7181], requires_grad=True)\n",
            "Loss: 22.499500274658203\n",
            "tensor([ 0.3030, -3.0618,  1.7181], requires_grad=True)\n",
            "Loss: 22.499492645263672\n",
            "tensor([ 0.3030, -3.0618,  1.7182], requires_grad=True)\n",
            "Loss: 22.49948501586914\n",
            "tensor([ 0.3030, -3.0618,  1.7182], requires_grad=True)\n",
            "Loss: 22.499475479125977\n",
            "tensor([ 0.3030, -3.0618,  1.7182], requires_grad=True)\n",
            "Loss: 22.499467849731445\n",
            "tensor([ 0.3030, -3.0618,  1.7182], requires_grad=True)\n",
            "Loss: 22.49945831298828\n",
            "tensor([ 0.3030, -3.0618,  1.7183], requires_grad=True)\n",
            "Loss: 22.499448776245117\n",
            "tensor([ 0.3030, -3.0618,  1.7183], requires_grad=True)\n",
            "Loss: 22.499441146850586\n",
            "tensor([ 0.3030, -3.0618,  1.7183], requires_grad=True)\n",
            "Loss: 22.499431610107422\n",
            "tensor([ 0.3030, -3.0618,  1.7184], requires_grad=True)\n",
            "Loss: 22.49942398071289\n",
            "tensor([ 0.3030, -3.0618,  1.7184], requires_grad=True)\n",
            "Loss: 22.49941635131836\n",
            "tensor([ 0.3030, -3.0618,  1.7184], requires_grad=True)\n",
            "Loss: 22.499408721923828\n",
            "tensor([ 0.3030, -3.0619,  1.7184], requires_grad=True)\n",
            "Loss: 22.499399185180664\n",
            "tensor([ 0.3030, -3.0619,  1.7185], requires_grad=True)\n",
            "Loss: 22.4993896484375\n",
            "tensor([ 0.3030, -3.0619,  1.7185], requires_grad=True)\n",
            "Loss: 22.499380111694336\n",
            "tensor([ 0.3030, -3.0619,  1.7185], requires_grad=True)\n",
            "Loss: 22.499372482299805\n",
            "tensor([ 0.3030, -3.0619,  1.7186], requires_grad=True)\n",
            "Loss: 22.49936294555664\n",
            "tensor([ 0.3030, -3.0619,  1.7186], requires_grad=True)\n",
            "Loss: 22.49935531616211\n",
            "tensor([ 0.3030, -3.0619,  1.7186], requires_grad=True)\n",
            "Loss: 22.499347686767578\n",
            "tensor([ 0.3030, -3.0619,  1.7186], requires_grad=True)\n",
            "Loss: 22.499338150024414\n",
            "tensor([ 0.3030, -3.0619,  1.7187], requires_grad=True)\n",
            "Loss: 22.499330520629883\n",
            "tensor([ 0.3030, -3.0619,  1.7187], requires_grad=True)\n",
            "Loss: 22.49932098388672\n",
            "tensor([ 0.3030, -3.0619,  1.7187], requires_grad=True)\n",
            "Loss: 22.499313354492188\n",
            "tensor([ 0.3030, -3.0619,  1.7188], requires_grad=True)\n",
            "Loss: 22.499303817749023\n",
            "tensor([ 0.3030, -3.0619,  1.7188], requires_grad=True)\n",
            "Loss: 22.49929428100586\n",
            "tensor([ 0.3030, -3.0619,  1.7188], requires_grad=True)\n",
            "Loss: 22.499284744262695\n",
            "tensor([ 0.3030, -3.0620,  1.7188], requires_grad=True)\n",
            "Loss: 22.499277114868164\n",
            "tensor([ 0.3030, -3.0620,  1.7189], requires_grad=True)\n",
            "Loss: 22.499269485473633\n",
            "tensor([ 0.3030, -3.0620,  1.7189], requires_grad=True)\n",
            "Loss: 22.49925994873047\n",
            "tensor([ 0.3030, -3.0620,  1.7189], requires_grad=True)\n",
            "Loss: 22.499252319335938\n",
            "tensor([ 0.3030, -3.0620,  1.7190], requires_grad=True)\n",
            "Loss: 22.49924087524414\n",
            "tensor([ 0.3030, -3.0620,  1.7190], requires_grad=True)\n",
            "Loss: 22.499235153198242\n",
            "tensor([ 0.3030, -3.0620,  1.7190], requires_grad=True)\n",
            "Loss: 22.499225616455078\n",
            "tensor([ 0.3030, -3.0620,  1.7190], requires_grad=True)\n",
            "Loss: 22.499217987060547\n",
            "tensor([ 0.3030, -3.0620,  1.7191], requires_grad=True)\n",
            "Loss: 22.499208450317383\n",
            "tensor([ 0.3030, -3.0620,  1.7191], requires_grad=True)\n",
            "Loss: 22.49920082092285\n",
            "tensor([ 0.3030, -3.0620,  1.7191], requires_grad=True)\n",
            "Loss: 22.499189376831055\n",
            "tensor([ 0.3030, -3.0620,  1.7192], requires_grad=True)\n",
            "Loss: 22.499183654785156\n",
            "tensor([ 0.3030, -3.0620,  1.7192], requires_grad=True)\n",
            "Loss: 22.49917221069336\n",
            "tensor([ 0.3030, -3.0620,  1.7192], requires_grad=True)\n",
            "Loss: 22.499164581298828\n",
            "tensor([ 0.3030, -3.0621,  1.7192], requires_grad=True)\n",
            "Loss: 22.499156951904297\n",
            "tensor([ 0.3030, -3.0621,  1.7193], requires_grad=True)\n",
            "Loss: 22.499149322509766\n",
            "tensor([ 0.3030, -3.0621,  1.7193], requires_grad=True)\n",
            "Loss: 22.4991397857666\n",
            "tensor([ 0.3030, -3.0621,  1.7193], requires_grad=True)\n",
            "Loss: 22.49913215637207\n",
            "tensor([ 0.3030, -3.0621,  1.7194], requires_grad=True)\n",
            "Loss: 22.499122619628906\n",
            "tensor([ 0.3030, -3.0621,  1.7194], requires_grad=True)\n",
            "Loss: 22.499113082885742\n",
            "tensor([ 0.3030, -3.0621,  1.7194], requires_grad=True)\n",
            "Loss: 22.49910545349121\n",
            "tensor([ 0.3030, -3.0621,  1.7194], requires_grad=True)\n",
            "Loss: 22.499095916748047\n",
            "tensor([ 0.3030, -3.0621,  1.7195], requires_grad=True)\n",
            "Loss: 22.499088287353516\n",
            "tensor([ 0.3030, -3.0621,  1.7195], requires_grad=True)\n",
            "Loss: 22.499080657958984\n",
            "tensor([ 0.3030, -3.0621,  1.7195], requires_grad=True)\n",
            "Loss: 22.49907112121582\n",
            "tensor([ 0.3030, -3.0621,  1.7196], requires_grad=True)\n",
            "Loss: 22.49906349182129\n",
            "tensor([ 0.3030, -3.0621,  1.7196], requires_grad=True)\n",
            "Loss: 22.499053955078125\n",
            "tensor([ 0.3030, -3.0622,  1.7196], requires_grad=True)\n",
            "Loss: 22.499042510986328\n",
            "tensor([ 0.3030, -3.0622,  1.7196], requires_grad=True)\n",
            "Loss: 22.49903678894043\n",
            "tensor([ 0.3030, -3.0622,  1.7197], requires_grad=True)\n",
            "Loss: 22.499027252197266\n",
            "tensor([ 0.3030, -3.0622,  1.7197], requires_grad=True)\n",
            "Loss: 22.4990177154541\n",
            "tensor([ 0.3030, -3.0622,  1.7197], requires_grad=True)\n",
            "Loss: 22.49901008605957\n",
            "tensor([ 0.3030, -3.0622,  1.7198], requires_grad=True)\n",
            "Loss: 22.49900245666504\n",
            "tensor([ 0.3030, -3.0622,  1.7198], requires_grad=True)\n",
            "Loss: 22.498992919921875\n",
            "tensor([ 0.3030, -3.0622,  1.7198], requires_grad=True)\n",
            "Loss: 22.49898338317871\n",
            "tensor([ 0.3030, -3.0622,  1.7198], requires_grad=True)\n",
            "Loss: 22.49897575378418\n",
            "tensor([ 0.3030, -3.0622,  1.7199], requires_grad=True)\n",
            "Loss: 22.498966217041016\n",
            "tensor([ 0.3030, -3.0622,  1.7199], requires_grad=True)\n",
            "Loss: 22.498960494995117\n",
            "tensor([ 0.3030, -3.0622,  1.7199], requires_grad=True)\n",
            "Loss: 22.49894905090332\n",
            "tensor([ 0.3030, -3.0622,  1.7200], requires_grad=True)\n",
            "Loss: 22.498943328857422\n",
            "tensor([ 0.3030, -3.0622,  1.7200], requires_grad=True)\n",
            "Loss: 22.498933792114258\n",
            "tensor([ 0.3030, -3.0623,  1.7200], requires_grad=True)\n",
            "Loss: 22.49892234802246\n",
            "tensor([ 0.3030, -3.0623,  1.7200], requires_grad=True)\n",
            "Loss: 22.49891471862793\n",
            "tensor([ 0.3030, -3.0623,  1.7201], requires_grad=True)\n",
            "Loss: 22.4989070892334\n",
            "tensor([ 0.3030, -3.0623,  1.7201], requires_grad=True)\n",
            "Loss: 22.498897552490234\n",
            "tensor([ 0.3030, -3.0623,  1.7201], requires_grad=True)\n",
            "Loss: 22.498889923095703\n",
            "tensor([ 0.3030, -3.0623,  1.7202], requires_grad=True)\n",
            "Loss: 22.49888038635254\n",
            "tensor([ 0.3030, -3.0623,  1.7202], requires_grad=True)\n",
            "Loss: 22.498872756958008\n",
            "tensor([ 0.3030, -3.0623,  1.7202], requires_grad=True)\n",
            "Loss: 22.498863220214844\n",
            "tensor([ 0.3030, -3.0623,  1.7202], requires_grad=True)\n",
            "Loss: 22.49885368347168\n",
            "tensor([ 0.3030, -3.0623,  1.7203], requires_grad=True)\n",
            "Loss: 22.49884796142578\n",
            "tensor([ 0.3030, -3.0623,  1.7203], requires_grad=True)\n",
            "Loss: 22.498838424682617\n",
            "tensor([ 0.3030, -3.0623,  1.7203], requires_grad=True)\n",
            "Loss: 22.498830795288086\n",
            "tensor([ 0.3030, -3.0623,  1.7204], requires_grad=True)\n",
            "Loss: 22.498821258544922\n",
            "tensor([ 0.3030, -3.0623,  1.7204], requires_grad=True)\n",
            "Loss: 22.498811721801758\n",
            "tensor([ 0.3030, -3.0624,  1.7204], requires_grad=True)\n",
            "Loss: 22.498804092407227\n",
            "tensor([ 0.3030, -3.0624,  1.7204], requires_grad=True)\n",
            "Loss: 22.498794555664062\n",
            "tensor([ 0.3030, -3.0624,  1.7205], requires_grad=True)\n",
            "Loss: 22.4987850189209\n",
            "tensor([ 0.3030, -3.0624,  1.7205], requires_grad=True)\n",
            "Loss: 22.498777389526367\n",
            "tensor([ 0.3030, -3.0624,  1.7205], requires_grad=True)\n",
            "Loss: 22.498769760131836\n",
            "tensor([ 0.3030, -3.0624,  1.7206], requires_grad=True)\n",
            "Loss: 22.498760223388672\n",
            "tensor([ 0.3030, -3.0624,  1.7206], requires_grad=True)\n",
            "Loss: 22.49875259399414\n",
            "tensor([ 0.3030, -3.0624,  1.7206], requires_grad=True)\n",
            "Loss: 22.498743057250977\n",
            "tensor([ 0.3030, -3.0624,  1.7206], requires_grad=True)\n",
            "Loss: 22.498737335205078\n",
            "tensor([ 0.3030, -3.0624,  1.7207], requires_grad=True)\n",
            "Loss: 22.49872589111328\n",
            "tensor([ 0.3030, -3.0624,  1.7207], requires_grad=True)\n",
            "Loss: 22.498716354370117\n",
            "tensor([ 0.3030, -3.0624,  1.7207], requires_grad=True)\n",
            "Loss: 22.498708724975586\n",
            "tensor([ 0.3030, -3.0624,  1.7208], requires_grad=True)\n",
            "Loss: 22.498701095581055\n",
            "tensor([ 0.3030, -3.0624,  1.7208], requires_grad=True)\n",
            "Loss: 22.49869155883789\n",
            "tensor([ 0.3030, -3.0625,  1.7208], requires_grad=True)\n",
            "Loss: 22.49868392944336\n",
            "tensor([ 0.3030, -3.0625,  1.7208], requires_grad=True)\n",
            "Loss: 22.498674392700195\n",
            "tensor([ 0.3030, -3.0625,  1.7209], requires_grad=True)\n",
            "Loss: 22.49866485595703\n",
            "tensor([ 0.3030, -3.0625,  1.7209], requires_grad=True)\n",
            "Loss: 22.4986572265625\n",
            "tensor([ 0.3030, -3.0625,  1.7209], requires_grad=True)\n",
            "Loss: 22.498647689819336\n",
            "tensor([ 0.3030, -3.0625,  1.7210], requires_grad=True)\n",
            "Loss: 22.498640060424805\n",
            "tensor([ 0.3030, -3.0625,  1.7210], requires_grad=True)\n",
            "Loss: 22.49863052368164\n",
            "tensor([ 0.3030, -3.0625,  1.7210], requires_grad=True)\n",
            "Loss: 22.49862289428711\n",
            "tensor([ 0.3030, -3.0625,  1.7210], requires_grad=True)\n",
            "Loss: 22.498613357543945\n",
            "tensor([ 0.3030, -3.0625,  1.7211], requires_grad=True)\n",
            "Loss: 22.498607635498047\n",
            "tensor([ 0.3030, -3.0625,  1.7211], requires_grad=True)\n",
            "Loss: 22.49859619140625\n",
            "tensor([ 0.3030, -3.0625,  1.7211], requires_grad=True)\n",
            "Loss: 22.49858856201172\n",
            "tensor([ 0.3030, -3.0625,  1.7212], requires_grad=True)\n",
            "Loss: 22.498579025268555\n",
            "tensor([ 0.3030, -3.0625,  1.7212], requires_grad=True)\n",
            "Loss: 22.49856948852539\n",
            "tensor([ 0.3030, -3.0626,  1.7212], requires_grad=True)\n",
            "Loss: 22.49856185913086\n",
            "tensor([ 0.3030, -3.0626,  1.7212], requires_grad=True)\n",
            "Loss: 22.498554229736328\n",
            "tensor([ 0.3030, -3.0626,  1.7213], requires_grad=True)\n",
            "Loss: 22.498546600341797\n",
            "tensor([ 0.3030, -3.0626,  1.7213], requires_grad=True)\n",
            "Loss: 22.49853515625\n",
            "tensor([ 0.3030, -3.0626,  1.7213], requires_grad=True)\n",
            "Loss: 22.49852752685547\n",
            "tensor([ 0.3030, -3.0626,  1.7214], requires_grad=True)\n",
            "Loss: 22.498517990112305\n",
            "tensor([ 0.3030, -3.0626,  1.7214], requires_grad=True)\n",
            "Loss: 22.498510360717773\n",
            "tensor([ 0.3030, -3.0626,  1.7214], requires_grad=True)\n",
            "Loss: 22.498502731323242\n",
            "tensor([ 0.3030, -3.0626,  1.7214], requires_grad=True)\n",
            "Loss: 22.498493194580078\n",
            "tensor([ 0.3030, -3.0626,  1.7215], requires_grad=True)\n",
            "Loss: 22.498485565185547\n",
            "tensor([ 0.3030, -3.0626,  1.7215], requires_grad=True)\n",
            "Loss: 22.498476028442383\n",
            "tensor([ 0.3030, -3.0626,  1.7215], requires_grad=True)\n",
            "Loss: 22.49846649169922\n",
            "tensor([ 0.3030, -3.0626,  1.7216], requires_grad=True)\n",
            "Loss: 22.498458862304688\n",
            "tensor([ 0.3030, -3.0626,  1.7216], requires_grad=True)\n",
            "Loss: 22.498449325561523\n",
            "tensor([ 0.3030, -3.0627,  1.7216], requires_grad=True)\n",
            "Loss: 22.498441696166992\n",
            "tensor([ 0.3030, -3.0627,  1.7216], requires_grad=True)\n",
            "Loss: 22.49843406677246\n",
            "tensor([ 0.3030, -3.0627,  1.7217], requires_grad=True)\n",
            "Loss: 22.498424530029297\n",
            "tensor([ 0.3030, -3.0627,  1.7217], requires_grad=True)\n",
            "Loss: 22.498416900634766\n",
            "tensor([ 0.3030, -3.0627,  1.7217], requires_grad=True)\n",
            "Loss: 22.49840545654297\n",
            "tensor([ 0.3030, -3.0627,  1.7218], requires_grad=True)\n",
            "Loss: 22.498397827148438\n",
            "tensor([ 0.3030, -3.0627,  1.7218], requires_grad=True)\n",
            "Loss: 22.498390197753906\n",
            "tensor([ 0.3030, -3.0627,  1.7218], requires_grad=True)\n",
            "Loss: 22.498380661010742\n",
            "tensor([ 0.3030, -3.0627,  1.7218], requires_grad=True)\n",
            "Loss: 22.49837303161621\n",
            "tensor([ 0.3030, -3.0627,  1.7219], requires_grad=True)\n",
            "Loss: 22.498363494873047\n",
            "tensor([ 0.3030, -3.0627,  1.7219], requires_grad=True)\n",
            "Loss: 22.498355865478516\n",
            "tensor([ 0.3030, -3.0627,  1.7219], requires_grad=True)\n",
            "Loss: 22.49834632873535\n",
            "tensor([ 0.3030, -3.0627,  1.7220], requires_grad=True)\n",
            "Loss: 22.49833869934082\n",
            "tensor([ 0.3030, -3.0627,  1.7220], requires_grad=True)\n",
            "Loss: 22.498329162597656\n",
            "tensor([ 0.3030, -3.0628,  1.7220], requires_grad=True)\n",
            "Loss: 22.498319625854492\n",
            "tensor([ 0.3030, -3.0628,  1.7220], requires_grad=True)\n",
            "Loss: 22.49831199645996\n",
            "tensor([ 0.3030, -3.0628,  1.7221], requires_grad=True)\n",
            "Loss: 22.49830436706543\n",
            "tensor([ 0.3030, -3.0628,  1.7221], requires_grad=True)\n",
            "Loss: 22.498294830322266\n",
            "tensor([ 0.3030, -3.0628,  1.7221], requires_grad=True)\n",
            "Loss: 22.498287200927734\n",
            "tensor([ 0.3030, -3.0628,  1.7222], requires_grad=True)\n",
            "Loss: 22.49827766418457\n",
            "tensor([ 0.3030, -3.0628,  1.7222], requires_grad=True)\n",
            "Loss: 22.498268127441406\n",
            "tensor([ 0.3030, -3.0628,  1.7222], requires_grad=True)\n",
            "Loss: 22.498260498046875\n",
            "tensor([ 0.3030, -3.0628,  1.7222], requires_grad=True)\n",
            "Loss: 22.498252868652344\n",
            "tensor([ 0.3030, -3.0628,  1.7223], requires_grad=True)\n",
            "Loss: 22.49824333190918\n",
            "tensor([ 0.3030, -3.0628,  1.7223], requires_grad=True)\n",
            "Loss: 22.498233795166016\n",
            "tensor([ 0.3030, -3.0628,  1.7223], requires_grad=True)\n",
            "Loss: 22.498228073120117\n",
            "tensor([ 0.3030, -3.0628,  1.7223], requires_grad=True)\n",
            "Loss: 22.498218536376953\n",
            "tensor([ 0.3030, -3.0628,  1.7224], requires_grad=True)\n",
            "Loss: 22.49820899963379\n",
            "tensor([ 0.3030, -3.0629,  1.7224], requires_grad=True)\n",
            "Loss: 22.498199462890625\n",
            "tensor([ 0.3030, -3.0629,  1.7224], requires_grad=True)\n",
            "Loss: 22.498191833496094\n",
            "tensor([ 0.3030, -3.0629,  1.7225], requires_grad=True)\n",
            "Loss: 22.498180389404297\n",
            "tensor([ 0.3030, -3.0629,  1.7225], requires_grad=True)\n",
            "Loss: 22.4981746673584\n",
            "tensor([ 0.3030, -3.0629,  1.7225], requires_grad=True)\n",
            "Loss: 22.498167037963867\n",
            "tensor([ 0.3030, -3.0629,  1.7225], requires_grad=True)\n",
            "Loss: 22.498157501220703\n",
            "tensor([ 0.3030, -3.0629,  1.7226], requires_grad=True)\n",
            "Loss: 22.49814796447754\n",
            "tensor([ 0.3030, -3.0629,  1.7226], requires_grad=True)\n",
            "Loss: 22.498140335083008\n",
            "tensor([ 0.3030, -3.0629,  1.7226], requires_grad=True)\n",
            "Loss: 22.498130798339844\n",
            "tensor([ 0.3030, -3.0629,  1.7227], requires_grad=True)\n",
            "Loss: 22.498123168945312\n",
            "tensor([ 0.3030, -3.0629,  1.7227], requires_grad=True)\n",
            "Loss: 22.49811553955078\n",
            "tensor([ 0.3030, -3.0629,  1.7227], requires_grad=True)\n",
            "Loss: 22.498106002807617\n",
            "tensor([ 0.3030, -3.0629,  1.7227], requires_grad=True)\n",
            "Loss: 22.498096466064453\n",
            "tensor([ 0.3030, -3.0629,  1.7228], requires_grad=True)\n",
            "Loss: 22.498088836669922\n",
            "tensor([ 0.3030, -3.0630,  1.7228], requires_grad=True)\n",
            "Loss: 22.498079299926758\n",
            "tensor([ 0.3030, -3.0630,  1.7228], requires_grad=True)\n",
            "Loss: 22.498069763183594\n",
            "tensor([ 0.3030, -3.0630,  1.7229], requires_grad=True)\n",
            "Loss: 22.498062133789062\n",
            "tensor([ 0.3030, -3.0630,  1.7229], requires_grad=True)\n",
            "Loss: 22.4980525970459\n",
            "tensor([ 0.3030, -3.0630,  1.7229], requires_grad=True)\n",
            "Loss: 22.498044967651367\n",
            "tensor([ 0.3030, -3.0630,  1.7229], requires_grad=True)\n",
            "Loss: 22.498037338256836\n",
            "tensor([ 0.3030, -3.0630,  1.7230], requires_grad=True)\n",
            "Loss: 22.498027801513672\n",
            "tensor([ 0.3030, -3.0630,  1.7230], requires_grad=True)\n",
            "Loss: 22.498018264770508\n",
            "tensor([ 0.3030, -3.0630,  1.7230], requires_grad=True)\n",
            "Loss: 22.498008728027344\n",
            "tensor([ 0.3030, -3.0630,  1.7231], requires_grad=True)\n",
            "Loss: 22.498001098632812\n",
            "tensor([ 0.3030, -3.0630,  1.7231], requires_grad=True)\n",
            "Loss: 22.49799346923828\n",
            "tensor([ 0.3030, -3.0630,  1.7231], requires_grad=True)\n",
            "Loss: 22.49798583984375\n",
            "tensor([ 0.3030, -3.0630,  1.7231], requires_grad=True)\n",
            "Loss: 22.497976303100586\n",
            "tensor([ 0.3030, -3.0630,  1.7232], requires_grad=True)\n",
            "Loss: 22.497968673706055\n",
            "tensor([ 0.3030, -3.0631,  1.7232], requires_grad=True)\n",
            "Loss: 22.497957229614258\n",
            "tensor([ 0.3030, -3.0631,  1.7232], requires_grad=True)\n",
            "Loss: 22.49795150756836\n",
            "tensor([ 0.3030, -3.0631,  1.7233], requires_grad=True)\n",
            "Loss: 22.497941970825195\n",
            "tensor([ 0.3030, -3.0631,  1.7233], requires_grad=True)\n",
            "Loss: 22.497934341430664\n",
            "tensor([ 0.3030, -3.0631,  1.7233], requires_grad=True)\n",
            "Loss: 22.4979248046875\n",
            "tensor([ 0.3030, -3.0631,  1.7233], requires_grad=True)\n",
            "Loss: 22.49791717529297\n",
            "tensor([ 0.3030, -3.0631,  1.7234], requires_grad=True)\n",
            "Loss: 22.497907638549805\n",
            "tensor([ 0.3030, -3.0631,  1.7234], requires_grad=True)\n",
            "Loss: 22.497901916503906\n",
            "tensor([ 0.3030, -3.0631,  1.7234], requires_grad=True)\n",
            "Loss: 22.497888565063477\n",
            "tensor([ 0.3030, -3.0631,  1.7235], requires_grad=True)\n",
            "Loss: 22.497880935668945\n",
            "tensor([ 0.3030, -3.0631,  1.7235], requires_grad=True)\n",
            "Loss: 22.497873306274414\n",
            "tensor([ 0.3030, -3.0631,  1.7235], requires_grad=True)\n",
            "Loss: 22.49786376953125\n",
            "tensor([ 0.3030, -3.0631,  1.7235], requires_grad=True)\n",
            "Loss: 22.497854232788086\n",
            "tensor([ 0.3030, -3.0631,  1.7236], requires_grad=True)\n",
            "Loss: 22.497846603393555\n",
            "tensor([ 0.3030, -3.0632,  1.7236], requires_grad=True)\n",
            "Loss: 22.497838973999023\n",
            "tensor([ 0.3030, -3.0632,  1.7236], requires_grad=True)\n",
            "Loss: 22.49782943725586\n",
            "tensor([ 0.3030, -3.0632,  1.7237], requires_grad=True)\n",
            "Loss: 22.497821807861328\n",
            "tensor([ 0.3030, -3.0632,  1.7237], requires_grad=True)\n",
            "Loss: 22.49781036376953\n",
            "tensor([ 0.3030, -3.0632,  1.7237], requires_grad=True)\n",
            "Loss: 22.497804641723633\n",
            "tensor([ 0.3030, -3.0632,  1.7237], requires_grad=True)\n",
            "Loss: 22.49779510498047\n",
            "tensor([ 0.3030, -3.0632,  1.7238], requires_grad=True)\n",
            "Loss: 22.497787475585938\n",
            "tensor([ 0.3030, -3.0632,  1.7238], requires_grad=True)\n",
            "Loss: 22.497777938842773\n",
            "tensor([ 0.3030, -3.0632,  1.7238], requires_grad=True)\n",
            "Loss: 22.497770309448242\n",
            "tensor([ 0.3030, -3.0632,  1.7239], requires_grad=True)\n",
            "Loss: 22.49776268005371\n",
            "tensor([ 0.3030, -3.0632,  1.7239], requires_grad=True)\n",
            "Loss: 22.497751235961914\n",
            "tensor([ 0.3030, -3.0632,  1.7239], requires_grad=True)\n",
            "Loss: 22.497743606567383\n",
            "tensor([ 0.3030, -3.0632,  1.7239], requires_grad=True)\n",
            "Loss: 22.49773406982422\n",
            "tensor([ 0.3030, -3.0632,  1.7240], requires_grad=True)\n",
            "Loss: 22.497726440429688\n",
            "tensor([ 0.3030, -3.0633,  1.7240], requires_grad=True)\n",
            "Loss: 22.497716903686523\n",
            "tensor([ 0.3030, -3.0633,  1.7240], requires_grad=True)\n",
            "Loss: 22.497711181640625\n",
            "tensor([ 0.3030, -3.0633,  1.7241], requires_grad=True)\n",
            "Loss: 22.497699737548828\n",
            "tensor([ 0.3030, -3.0633,  1.7241], requires_grad=True)\n",
            "Loss: 22.497692108154297\n",
            "tensor([ 0.3030, -3.0633,  1.7241], requires_grad=True)\n",
            "Loss: 22.497682571411133\n",
            "tensor([ 0.3030, -3.0633,  1.7241], requires_grad=True)\n",
            "Loss: 22.4976749420166\n",
            "tensor([ 0.3030, -3.0633,  1.7242], requires_grad=True)\n",
            "Loss: 22.497665405273438\n",
            "tensor([ 0.3030, -3.0633,  1.7242], requires_grad=True)\n",
            "Loss: 22.497657775878906\n",
            "tensor([ 0.3030, -3.0633,  1.7242], requires_grad=True)\n",
            "Loss: 22.497648239135742\n",
            "tensor([ 0.3030, -3.0633,  1.7243], requires_grad=True)\n",
            "Loss: 22.497638702392578\n",
            "tensor([ 0.3030, -3.0633,  1.7243], requires_grad=True)\n",
            "Loss: 22.497631072998047\n",
            "tensor([ 0.3030, -3.0633,  1.7243], requires_grad=True)\n",
            "Loss: 22.497623443603516\n",
            "tensor([ 0.3030, -3.0633,  1.7243], requires_grad=True)\n",
            "Loss: 22.49761390686035\n",
            "tensor([ 0.3030, -3.0633,  1.7244], requires_grad=True)\n",
            "Loss: 22.497604370117188\n",
            "tensor([ 0.3030, -3.0634,  1.7244], requires_grad=True)\n",
            "Loss: 22.49759864807129\n",
            "tensor([ 0.3030, -3.0634,  1.7244], requires_grad=True)\n",
            "Loss: 22.497589111328125\n",
            "tensor([ 0.3030, -3.0634,  1.7245], requires_grad=True)\n",
            "Loss: 22.497581481933594\n",
            "tensor([ 0.3030, -3.0634,  1.7245], requires_grad=True)\n",
            "Loss: 22.497570037841797\n",
            "tensor([ 0.3030, -3.0634,  1.7245], requires_grad=True)\n",
            "Loss: 22.497562408447266\n",
            "tensor([ 0.3030, -3.0634,  1.7245], requires_grad=True)\n",
            "Loss: 22.497554779052734\n",
            "tensor([ 0.3030, -3.0634,  1.7246], requires_grad=True)\n",
            "Loss: 22.497547149658203\n",
            "tensor([ 0.3030, -3.0634,  1.7246], requires_grad=True)\n",
            "Loss: 22.49753761291504\n",
            "tensor([ 0.3030, -3.0634,  1.7246], requires_grad=True)\n",
            "Loss: 22.497528076171875\n",
            "tensor([ 0.3030, -3.0634,  1.7247], requires_grad=True)\n",
            "Loss: 22.49751853942871\n",
            "tensor([ 0.3030, -3.0634,  1.7247], requires_grad=True)\n",
            "Loss: 22.49751091003418\n",
            "tensor([ 0.3030, -3.0634,  1.7247], requires_grad=True)\n",
            "Loss: 22.497501373291016\n",
            "tensor([ 0.3030, -3.0634,  1.7247], requires_grad=True)\n",
            "Loss: 22.497493743896484\n",
            "tensor([ 0.3030, -3.0634,  1.7248], requires_grad=True)\n",
            "Loss: 22.49748420715332\n",
            "tensor([ 0.3030, -3.0635,  1.7248], requires_grad=True)\n",
            "Loss: 22.49747657775879\n",
            "tensor([ 0.3030, -3.0635,  1.7248], requires_grad=True)\n",
            "Loss: 22.497468948364258\n",
            "tensor([ 0.3030, -3.0635,  1.7249], requires_grad=True)\n",
            "Loss: 22.497459411621094\n",
            "tensor([ 0.3030, -3.0635,  1.7249], requires_grad=True)\n",
            "Loss: 22.497451782226562\n",
            "tensor([ 0.3030, -3.0635,  1.7249], requires_grad=True)\n",
            "Loss: 22.4974422454834\n",
            "tensor([ 0.3030, -3.0635,  1.7249], requires_grad=True)\n",
            "Loss: 22.497434616088867\n",
            "tensor([ 0.3030, -3.0635,  1.7250], requires_grad=True)\n",
            "Loss: 22.497425079345703\n",
            "tensor([ 0.3030, -3.0635,  1.7250], requires_grad=True)\n",
            "Loss: 22.49741554260254\n",
            "tensor([ 0.3030, -3.0635,  1.7250], requires_grad=True)\n",
            "Loss: 22.497407913208008\n",
            "tensor([ 0.3030, -3.0635,  1.7251], requires_grad=True)\n",
            "Loss: 22.497398376464844\n",
            "tensor([ 0.3030, -3.0635,  1.7251], requires_grad=True)\n",
            "Loss: 22.497390747070312\n",
            "tensor([ 0.3030, -3.0635,  1.7251], requires_grad=True)\n",
            "Loss: 22.49738121032715\n",
            "tensor([ 0.3030, -3.0635,  1.7251], requires_grad=True)\n",
            "Loss: 22.497373580932617\n",
            "tensor([ 0.3030, -3.0635,  1.7252], requires_grad=True)\n",
            "Loss: 22.497364044189453\n",
            "tensor([ 0.3031, -3.0636,  1.7252], requires_grad=True)\n",
            "Loss: 22.497356414794922\n",
            "tensor([ 0.3031, -3.0636,  1.7252], requires_grad=True)\n",
            "Loss: 22.497344970703125\n",
            "tensor([ 0.3031, -3.0636,  1.7253], requires_grad=True)\n",
            "Loss: 22.497339248657227\n",
            "tensor([ 0.3031, -3.0636,  1.7253], requires_grad=True)\n",
            "Loss: 22.497329711914062\n",
            "tensor([ 0.3031, -3.0636,  1.7253], requires_grad=True)\n",
            "Loss: 22.49732208251953\n",
            "tensor([ 0.3031, -3.0636,  1.7253], requires_grad=True)\n",
            "Loss: 22.497312545776367\n",
            "tensor([ 0.3031, -3.0636,  1.7254], requires_grad=True)\n",
            "Loss: 22.497304916381836\n",
            "tensor([ 0.3031, -3.0636,  1.7254], requires_grad=True)\n",
            "Loss: 22.497295379638672\n",
            "tensor([ 0.3031, -3.0636,  1.7254], requires_grad=True)\n",
            "Loss: 22.497285842895508\n",
            "tensor([ 0.3031, -3.0636,  1.7255], requires_grad=True)\n",
            "Loss: 22.497278213500977\n",
            "tensor([ 0.3031, -3.0636,  1.7255], requires_grad=True)\n",
            "Loss: 22.497270584106445\n",
            "tensor([ 0.3031, -3.0636,  1.7255], requires_grad=True)\n",
            "Loss: 22.497262954711914\n",
            "tensor([ 0.3031, -3.0636,  1.7255], requires_grad=True)\n",
            "Loss: 22.497251510620117\n",
            "tensor([ 0.3031, -3.0636,  1.7256], requires_grad=True)\n",
            "Loss: 22.497243881225586\n",
            "tensor([ 0.3031, -3.0637,  1.7256], requires_grad=True)\n",
            "Loss: 22.497234344482422\n",
            "tensor([ 0.3031, -3.0637,  1.7256], requires_grad=True)\n",
            "Loss: 22.49722671508789\n",
            "tensor([ 0.3031, -3.0637,  1.7257], requires_grad=True)\n",
            "Loss: 22.497217178344727\n",
            "tensor([ 0.3031, -3.0637,  1.7257], requires_grad=True)\n",
            "Loss: 22.497209548950195\n",
            "tensor([ 0.3031, -3.0637,  1.7257], requires_grad=True)\n",
            "Loss: 22.49720001220703\n",
            "tensor([ 0.3031, -3.0637,  1.7257], requires_grad=True)\n",
            "Loss: 22.4971923828125\n",
            "tensor([ 0.3031, -3.0637,  1.7258], requires_grad=True)\n",
            "Loss: 22.49718475341797\n",
            "tensor([ 0.3031, -3.0637,  1.7258], requires_grad=True)\n",
            "Loss: 22.497175216674805\n",
            "tensor([ 0.3031, -3.0637,  1.7258], requires_grad=True)\n",
            "Loss: 22.49716567993164\n",
            "tensor([ 0.3031, -3.0637,  1.7259], requires_grad=True)\n",
            "Loss: 22.49715805053711\n",
            "tensor([ 0.3031, -3.0637,  1.7259], requires_grad=True)\n",
            "Loss: 22.497146606445312\n",
            "tensor([ 0.3031, -3.0637,  1.7259], requires_grad=True)\n",
            "Loss: 22.497140884399414\n",
            "tensor([ 0.3031, -3.0637,  1.7259], requires_grad=True)\n",
            "Loss: 22.497133255004883\n",
            "tensor([ 0.3031, -3.0637,  1.7260], requires_grad=True)\n",
            "Loss: 22.49712371826172\n",
            "tensor([ 0.3031, -3.0638,  1.7260], requires_grad=True)\n",
            "Loss: 22.497114181518555\n",
            "tensor([ 0.3031, -3.0638,  1.7260], requires_grad=True)\n",
            "Loss: 22.49710464477539\n",
            "tensor([ 0.3031, -3.0638,  1.7261], requires_grad=True)\n",
            "Loss: 22.49709701538086\n",
            "tensor([ 0.3031, -3.0638,  1.7261], requires_grad=True)\n",
            "Loss: 22.497087478637695\n",
            "tensor([ 0.3031, -3.0638,  1.7261], requires_grad=True)\n",
            "Loss: 22.497079849243164\n",
            "tensor([ 0.3031, -3.0638,  1.7261], requires_grad=True)\n",
            "Loss: 22.497072219848633\n",
            "tensor([ 0.3031, -3.0638,  1.7262], requires_grad=True)\n",
            "Loss: 22.49706268310547\n",
            "tensor([ 0.3031, -3.0638,  1.7262], requires_grad=True)\n",
            "Loss: 22.497053146362305\n",
            "tensor([ 0.3031, -3.0638,  1.7262], requires_grad=True)\n",
            "Loss: 22.497045516967773\n",
            "tensor([ 0.3031, -3.0638,  1.7263], requires_grad=True)\n",
            "Loss: 22.49703598022461\n",
            "tensor([ 0.3031, -3.0638,  1.7263], requires_grad=True)\n",
            "Loss: 22.497026443481445\n",
            "tensor([ 0.3031, -3.0638,  1.7263], requires_grad=True)\n",
            "Loss: 22.497018814086914\n",
            "tensor([ 0.3031, -3.0638,  1.7263], requires_grad=True)\n",
            "Loss: 22.497011184692383\n",
            "tensor([ 0.3031, -3.0638,  1.7264], requires_grad=True)\n",
            "Loss: 22.49700355529785\n",
            "tensor([ 0.3031, -3.0639,  1.7264], requires_grad=True)\n",
            "Loss: 22.496994018554688\n",
            "tensor([ 0.3031, -3.0639,  1.7264], requires_grad=True)\n",
            "Loss: 22.496986389160156\n",
            "tensor([ 0.3031, -3.0639,  1.7265], requires_grad=True)\n",
            "Loss: 22.49697494506836\n",
            "tensor([ 0.3031, -3.0639,  1.7265], requires_grad=True)\n",
            "Loss: 22.49696922302246\n",
            "tensor([ 0.3031, -3.0639,  1.7265], requires_grad=True)\n",
            "Loss: 22.496959686279297\n",
            "tensor([ 0.3031, -3.0639,  1.7265], requires_grad=True)\n",
            "Loss: 22.496950149536133\n",
            "tensor([ 0.3031, -3.0639,  1.7266], requires_grad=True)\n",
            "Loss: 22.4969425201416\n",
            "tensor([ 0.3031, -3.0639,  1.7266], requires_grad=True)\n",
            "Loss: 22.496932983398438\n",
            "tensor([ 0.3031, -3.0639,  1.7266], requires_grad=True)\n",
            "Loss: 22.496925354003906\n",
            "tensor([ 0.3031, -3.0639,  1.7267], requires_grad=True)\n",
            "Loss: 22.496917724609375\n",
            "tensor([ 0.3031, -3.0639,  1.7267], requires_grad=True)\n",
            "Loss: 22.49690818786621\n",
            "tensor([ 0.3031, -3.0639,  1.7267], requires_grad=True)\n",
            "Loss: 22.49690055847168\n",
            "tensor([ 0.3031, -3.0639,  1.7267], requires_grad=True)\n",
            "Loss: 22.496891021728516\n",
            "tensor([ 0.3031, -3.0639,  1.7268], requires_grad=True)\n",
            "Loss: 22.49688148498535\n",
            "tensor([ 0.3031, -3.0640,  1.7268], requires_grad=True)\n",
            "Loss: 22.49687385559082\n",
            "tensor([ 0.3031, -3.0640,  1.7268], requires_grad=True)\n",
            "Loss: 22.496864318847656\n",
            "tensor([ 0.3031, -3.0640,  1.7269], requires_grad=True)\n",
            "Loss: 22.496856689453125\n",
            "tensor([ 0.3031, -3.0640,  1.7269], requires_grad=True)\n",
            "Loss: 22.49684715270996\n",
            "tensor([ 0.3031, -3.0640,  1.7269], requires_grad=True)\n",
            "Loss: 22.496837615966797\n",
            "tensor([ 0.3031, -3.0640,  1.7269], requires_grad=True)\n",
            "Loss: 22.496829986572266\n",
            "tensor([ 0.3031, -3.0640,  1.7270], requires_grad=True)\n",
            "Loss: 22.4968204498291\n",
            "tensor([ 0.3031, -3.0640,  1.7270], requires_grad=True)\n",
            "Loss: 22.49681282043457\n",
            "tensor([ 0.3031, -3.0640,  1.7270], requires_grad=True)\n",
            "Loss: 22.496803283691406\n",
            "tensor([ 0.3031, -3.0640,  1.7271], requires_grad=True)\n",
            "Loss: 22.496795654296875\n",
            "tensor([ 0.3031, -3.0640,  1.7271], requires_grad=True)\n",
            "Loss: 22.496788024902344\n",
            "tensor([ 0.3031, -3.0640,  1.7271], requires_grad=True)\n",
            "Loss: 22.49677848815918\n",
            "tensor([ 0.3031, -3.0640,  1.7271], requires_grad=True)\n",
            "Loss: 22.49677085876465\n",
            "tensor([ 0.3031, -3.0640,  1.7272], requires_grad=True)\n",
            "Loss: 22.496761322021484\n",
            "tensor([ 0.3031, -3.0641,  1.7272], requires_grad=True)\n",
            "Loss: 22.496753692626953\n",
            "tensor([ 0.3031, -3.0641,  1.7272], requires_grad=True)\n",
            "Loss: 22.49674415588379\n",
            "tensor([ 0.3031, -3.0641,  1.7273], requires_grad=True)\n",
            "Loss: 22.496736526489258\n",
            "tensor([ 0.3031, -3.0641,  1.7273], requires_grad=True)\n",
            "Loss: 22.496726989746094\n",
            "tensor([ 0.3031, -3.0641,  1.7273], requires_grad=True)\n",
            "Loss: 22.496719360351562\n",
            "tensor([ 0.3031, -3.0641,  1.7273], requires_grad=True)\n",
            "Loss: 22.4967098236084\n",
            "tensor([ 0.3031, -3.0641,  1.7274], requires_grad=True)\n",
            "Loss: 22.496700286865234\n",
            "tensor([ 0.3031, -3.0641,  1.7274], requires_grad=True)\n",
            "Loss: 22.49669075012207\n",
            "tensor([ 0.3031, -3.0641,  1.7274], requires_grad=True)\n",
            "Loss: 22.496685028076172\n",
            "tensor([ 0.3031, -3.0641,  1.7274], requires_grad=True)\n",
            "Loss: 22.496673583984375\n",
            "tensor([ 0.3031, -3.0641,  1.7275], requires_grad=True)\n",
            "Loss: 22.496667861938477\n",
            "tensor([ 0.3031, -3.0641,  1.7275], requires_grad=True)\n",
            "Loss: 22.496658325195312\n",
            "tensor([ 0.3031, -3.0641,  1.7275], requires_grad=True)\n",
            "Loss: 22.49664878845215\n",
            "tensor([ 0.3031, -3.0641,  1.7276], requires_grad=True)\n",
            "Loss: 22.496639251708984\n",
            "tensor([ 0.3031, -3.0642,  1.7276], requires_grad=True)\n",
            "Loss: 22.496633529663086\n",
            "tensor([ 0.3031, -3.0642,  1.7276], requires_grad=True)\n",
            "Loss: 22.496623992919922\n",
            "tensor([ 0.3031, -3.0642,  1.7276], requires_grad=True)\n",
            "Loss: 22.496614456176758\n",
            "tensor([ 0.3031, -3.0642,  1.7277], requires_grad=True)\n",
            "Loss: 22.496606826782227\n",
            "tensor([ 0.3031, -3.0642,  1.7277], requires_grad=True)\n",
            "Loss: 22.496597290039062\n",
            "tensor([ 0.3031, -3.0642,  1.7277], requires_grad=True)\n",
            "Loss: 22.4965877532959\n",
            "tensor([ 0.3031, -3.0642,  1.7278], requires_grad=True)\n",
            "Loss: 22.496580123901367\n",
            "tensor([ 0.3031, -3.0642,  1.7278], requires_grad=True)\n",
            "Loss: 22.496570587158203\n",
            "tensor([ 0.3031, -3.0642,  1.7278], requires_grad=True)\n",
            "Loss: 22.496562957763672\n",
            "tensor([ 0.3031, -3.0642,  1.7278], requires_grad=True)\n",
            "Loss: 22.49655532836914\n",
            "tensor([ 0.3031, -3.0642,  1.7279], requires_grad=True)\n",
            "Loss: 22.496545791625977\n",
            "tensor([ 0.3031, -3.0642,  1.7279], requires_grad=True)\n",
            "Loss: 22.496538162231445\n",
            "tensor([ 0.3031, -3.0642,  1.7279], requires_grad=True)\n",
            "Loss: 22.49652862548828\n",
            "tensor([ 0.3031, -3.0642,  1.7280], requires_grad=True)\n",
            "Loss: 22.49652099609375\n",
            "tensor([ 0.3031, -3.0643,  1.7280], requires_grad=True)\n",
            "Loss: 22.496511459350586\n",
            "tensor([ 0.3031, -3.0643,  1.7280], requires_grad=True)\n",
            "Loss: 22.496501922607422\n",
            "tensor([ 0.3031, -3.0643,  1.7280], requires_grad=True)\n",
            "Loss: 22.49649429321289\n",
            "tensor([ 0.3031, -3.0643,  1.7281], requires_grad=True)\n",
            "Loss: 22.496484756469727\n",
            "tensor([ 0.3031, -3.0643,  1.7281], requires_grad=True)\n",
            "Loss: 22.496477127075195\n",
            "tensor([ 0.3031, -3.0643,  1.7281], requires_grad=True)\n",
            "Loss: 22.49646759033203\n",
            "tensor([ 0.3031, -3.0643,  1.7282], requires_grad=True)\n",
            "Loss: 22.4964599609375\n",
            "tensor([ 0.3031, -3.0643,  1.7282], requires_grad=True)\n",
            "Loss: 22.496450424194336\n",
            "tensor([ 0.3031, -3.0643,  1.7282], requires_grad=True)\n",
            "Loss: 22.496442794799805\n",
            "tensor([ 0.3031, -3.0643,  1.7282], requires_grad=True)\n",
            "Loss: 22.49643325805664\n",
            "tensor([ 0.3031, -3.0643,  1.7283], requires_grad=True)\n",
            "Loss: 22.49642562866211\n",
            "tensor([ 0.3031, -3.0643,  1.7283], requires_grad=True)\n",
            "Loss: 22.496416091918945\n",
            "tensor([ 0.3031, -3.0643,  1.7283], requires_grad=True)\n",
            "Loss: 22.496408462524414\n",
            "tensor([ 0.3031, -3.0643,  1.7284], requires_grad=True)\n",
            "Loss: 22.496400833129883\n",
            "tensor([ 0.3031, -3.0644,  1.7284], requires_grad=True)\n",
            "Loss: 22.496389389038086\n",
            "tensor([ 0.3031, -3.0644,  1.7284], requires_grad=True)\n",
            "Loss: 22.496381759643555\n",
            "tensor([ 0.3031, -3.0644,  1.7284], requires_grad=True)\n",
            "Loss: 22.496374130249023\n",
            "tensor([ 0.3031, -3.0644,  1.7285], requires_grad=True)\n",
            "Loss: 22.49636459350586\n",
            "tensor([ 0.3031, -3.0644,  1.7285], requires_grad=True)\n",
            "Loss: 22.496355056762695\n",
            "tensor([ 0.3031, -3.0644,  1.7285], requires_grad=True)\n",
            "Loss: 22.496347427368164\n",
            "tensor([ 0.3031, -3.0644,  1.7286], requires_grad=True)\n",
            "Loss: 22.496339797973633\n",
            "tensor([ 0.3031, -3.0644,  1.7286], requires_grad=True)\n",
            "Loss: 22.49633026123047\n",
            "tensor([ 0.3031, -3.0644,  1.7286], requires_grad=True)\n",
            "Loss: 22.496322631835938\n",
            "tensor([ 0.3031, -3.0644,  1.7286], requires_grad=True)\n",
            "Loss: 22.496313095092773\n",
            "tensor([ 0.3031, -3.0644,  1.7287], requires_grad=True)\n",
            "Loss: 22.49630355834961\n",
            "tensor([ 0.3031, -3.0644,  1.7287], requires_grad=True)\n",
            "Loss: 22.49629783630371\n",
            "tensor([ 0.3031, -3.0644,  1.7287], requires_grad=True)\n",
            "Loss: 22.496288299560547\n",
            "tensor([ 0.3031, -3.0644,  1.7288], requires_grad=True)\n",
            "Loss: 22.496278762817383\n",
            "tensor([ 0.3031, -3.0645,  1.7288], requires_grad=True)\n",
            "Loss: 22.49626922607422\n",
            "tensor([ 0.3031, -3.0645,  1.7288], requires_grad=True)\n",
            "Loss: 22.49626350402832\n",
            "tensor([ 0.3031, -3.0645,  1.7288], requires_grad=True)\n",
            "Loss: 22.496252059936523\n",
            "tensor([ 0.3031, -3.0645,  1.7289], requires_grad=True)\n",
            "Loss: 22.496244430541992\n",
            "tensor([ 0.3031, -3.0645,  1.7289], requires_grad=True)\n",
            "Loss: 22.49623680114746\n",
            "tensor([ 0.3031, -3.0645,  1.7289], requires_grad=True)\n",
            "Loss: 22.496227264404297\n",
            "tensor([ 0.3031, -3.0645,  1.7290], requires_grad=True)\n",
            "Loss: 22.496217727661133\n",
            "tensor([ 0.3031, -3.0645,  1.7290], requires_grad=True)\n",
            "Loss: 22.4962100982666\n",
            "tensor([ 0.3031, -3.0645,  1.7290], requires_grad=True)\n",
            "Loss: 22.496200561523438\n",
            "tensor([ 0.3031, -3.0645,  1.7290], requires_grad=True)\n",
            "Loss: 22.496192932128906\n",
            "tensor([ 0.3031, -3.0645,  1.7291], requires_grad=True)\n",
            "Loss: 22.496183395385742\n",
            "tensor([ 0.3031, -3.0645,  1.7291], requires_grad=True)\n",
            "Loss: 22.49617576599121\n",
            "tensor([ 0.3031, -3.0645,  1.7291], requires_grad=True)\n",
            "Loss: 22.49616813659668\n",
            "tensor([ 0.3031, -3.0645,  1.7292], requires_grad=True)\n",
            "Loss: 22.496158599853516\n",
            "tensor([ 0.3031, -3.0646,  1.7292], requires_grad=True)\n",
            "Loss: 22.49614906311035\n",
            "tensor([ 0.3031, -3.0646,  1.7292], requires_grad=True)\n",
            "Loss: 22.496139526367188\n",
            "tensor([ 0.3031, -3.0646,  1.7292], requires_grad=True)\n",
            "Loss: 22.496131896972656\n",
            "tensor([ 0.3031, -3.0646,  1.7293], requires_grad=True)\n",
            "Loss: 22.496122360229492\n",
            "tensor([ 0.3031, -3.0646,  1.7293], requires_grad=True)\n",
            "Loss: 22.49611473083496\n",
            "tensor([ 0.3031, -3.0646,  1.7293], requires_grad=True)\n",
            "Loss: 22.49610710144043\n",
            "tensor([ 0.3031, -3.0646,  1.7294], requires_grad=True)\n",
            "Loss: 22.496097564697266\n",
            "tensor([ 0.3031, -3.0646,  1.7294], requires_grad=True)\n",
            "Loss: 22.496091842651367\n",
            "tensor([ 0.3031, -3.0646,  1.7294], requires_grad=True)\n",
            "Loss: 22.49608039855957\n",
            "tensor([ 0.3031, -3.0646,  1.7294], requires_grad=True)\n",
            "Loss: 22.496074676513672\n",
            "tensor([ 0.3031, -3.0646,  1.7295], requires_grad=True)\n",
            "Loss: 22.496063232421875\n",
            "tensor([ 0.3031, -3.0646,  1.7295], requires_grad=True)\n",
            "Loss: 22.496055603027344\n",
            "tensor([ 0.3031, -3.0646,  1.7295], requires_grad=True)\n",
            "Loss: 22.49604606628418\n",
            "tensor([ 0.3031, -3.0646,  1.7296], requires_grad=True)\n",
            "Loss: 22.49603843688965\n",
            "tensor([ 0.3031, -3.0647,  1.7296], requires_grad=True)\n",
            "Loss: 22.496028900146484\n",
            "tensor([ 0.3031, -3.0647,  1.7296], requires_grad=True)\n",
            "Loss: 22.496021270751953\n",
            "tensor([ 0.3031, -3.0647,  1.7296], requires_grad=True)\n",
            "Loss: 22.49601173400879\n",
            "tensor([ 0.3031, -3.0647,  1.7297], requires_grad=True)\n",
            "Loss: 22.496004104614258\n",
            "tensor([ 0.3031, -3.0647,  1.7297], requires_grad=True)\n",
            "Loss: 22.495994567871094\n",
            "tensor([ 0.3031, -3.0647,  1.7297], requires_grad=True)\n",
            "Loss: 22.49598503112793\n",
            "tensor([ 0.3031, -3.0647,  1.7298], requires_grad=True)\n",
            "Loss: 22.495975494384766\n",
            "tensor([ 0.3031, -3.0647,  1.7298], requires_grad=True)\n",
            "Loss: 22.495967864990234\n",
            "tensor([ 0.3031, -3.0647,  1.7298], requires_grad=True)\n",
            "Loss: 22.495960235595703\n",
            "tensor([ 0.3031, -3.0647,  1.7298], requires_grad=True)\n",
            "Loss: 22.495952606201172\n",
            "tensor([ 0.3031, -3.0647,  1.7299], requires_grad=True)\n",
            "Loss: 22.495943069458008\n",
            "tensor([ 0.3031, -3.0647,  1.7299], requires_grad=True)\n",
            "Loss: 22.495933532714844\n",
            "tensor([ 0.3031, -3.0647,  1.7299], requires_grad=True)\n",
            "Loss: 22.49592399597168\n",
            "tensor([ 0.3031, -3.0647,  1.7300], requires_grad=True)\n",
            "Loss: 22.49591827392578\n",
            "tensor([ 0.3031, -3.0648,  1.7300], requires_grad=True)\n",
            "Loss: 22.495908737182617\n",
            "tensor([ 0.3031, -3.0648,  1.7300], requires_grad=True)\n",
            "Loss: 22.495899200439453\n",
            "tensor([ 0.3031, -3.0648,  1.7300], requires_grad=True)\n",
            "Loss: 22.495891571044922\n",
            "tensor([ 0.3031, -3.0648,  1.7301], requires_grad=True)\n",
            "Loss: 22.49588394165039\n",
            "tensor([ 0.3031, -3.0648,  1.7301], requires_grad=True)\n",
            "Loss: 22.495874404907227\n",
            "tensor([ 0.3031, -3.0648,  1.7301], requires_grad=True)\n",
            "Loss: 22.495864868164062\n",
            "tensor([ 0.3031, -3.0648,  1.7302], requires_grad=True)\n",
            "Loss: 22.49585723876953\n",
            "tensor([ 0.3031, -3.0648,  1.7302], requires_grad=True)\n",
            "Loss: 22.495847702026367\n",
            "tensor([ 0.3031, -3.0648,  1.7302], requires_grad=True)\n",
            "Loss: 22.495840072631836\n",
            "tensor([ 0.3031, -3.0648,  1.7302], requires_grad=True)\n",
            "Loss: 22.495832443237305\n",
            "tensor([ 0.3031, -3.0648,  1.7303], requires_grad=True)\n",
            "Loss: 22.495824813842773\n",
            "tensor([ 0.3031, -3.0648,  1.7303], requires_grad=True)\n",
            "Loss: 22.495813369750977\n",
            "tensor([ 0.3031, -3.0648,  1.7303], requires_grad=True)\n",
            "Loss: 22.495805740356445\n",
            "tensor([ 0.3031, -3.0648,  1.7304], requires_grad=True)\n",
            "Loss: 22.49579620361328\n",
            "tensor([ 0.3031, -3.0649,  1.7304], requires_grad=True)\n",
            "Loss: 22.49578857421875\n",
            "tensor([ 0.3031, -3.0649,  1.7304], requires_grad=True)\n",
            "Loss: 22.495779037475586\n",
            "tensor([ 0.3031, -3.0649,  1.7304], requires_grad=True)\n",
            "Loss: 22.495769500732422\n",
            "tensor([ 0.3031, -3.0649,  1.7305], requires_grad=True)\n",
            "Loss: 22.49576187133789\n",
            "tensor([ 0.3031, -3.0649,  1.7305], requires_grad=True)\n",
            "Loss: 22.495752334594727\n",
            "tensor([ 0.3031, -3.0649,  1.7305], requires_grad=True)\n",
            "Loss: 22.495746612548828\n",
            "tensor([ 0.3031, -3.0649,  1.7306], requires_grad=True)\n",
            "Loss: 22.495737075805664\n",
            "tensor([ 0.3031, -3.0649,  1.7306], requires_grad=True)\n",
            "Loss: 22.4957275390625\n",
            "tensor([ 0.3031, -3.0649,  1.7306], requires_grad=True)\n",
            "Loss: 22.49571990966797\n",
            "tensor([ 0.3031, -3.0649,  1.7306], requires_grad=True)\n",
            "Loss: 22.495710372924805\n",
            "tensor([ 0.3031, -3.0649,  1.7307], requires_grad=True)\n",
            "Loss: 22.49570083618164\n",
            "tensor([ 0.3031, -3.0649,  1.7307], requires_grad=True)\n",
            "Loss: 22.49569320678711\n",
            "tensor([ 0.3031, -3.0649,  1.7307], requires_grad=True)\n",
            "Loss: 22.495683670043945\n",
            "tensor([ 0.3031, -3.0649,  1.7308], requires_grad=True)\n",
            "Loss: 22.495676040649414\n",
            "tensor([ 0.3031, -3.0650,  1.7308], requires_grad=True)\n",
            "Loss: 22.495668411254883\n",
            "tensor([ 0.3031, -3.0650,  1.7308], requires_grad=True)\n",
            "Loss: 22.49565887451172\n",
            "tensor([ 0.3031, -3.0650,  1.7308], requires_grad=True)\n",
            "Loss: 22.495649337768555\n",
            "tensor([ 0.3031, -3.0650,  1.7309], requires_grad=True)\n",
            "Loss: 22.495641708374023\n",
            "tensor([ 0.3031, -3.0650,  1.7309], requires_grad=True)\n",
            "Loss: 22.495634078979492\n",
            "tensor([ 0.3031, -3.0650,  1.7309], requires_grad=True)\n",
            "Loss: 22.495624542236328\n",
            "tensor([ 0.3031, -3.0650,  1.7310], requires_grad=True)\n",
            "Loss: 22.495615005493164\n",
            "tensor([ 0.3031, -3.0650,  1.7310], requires_grad=True)\n",
            "Loss: 22.49560546875\n",
            "tensor([ 0.3031, -3.0650,  1.7310], requires_grad=True)\n",
            "Loss: 22.49559783935547\n",
            "tensor([ 0.3031, -3.0650,  1.7310], requires_grad=True)\n",
            "Loss: 22.495590209960938\n",
            "tensor([ 0.3031, -3.0650,  1.7311], requires_grad=True)\n",
            "Loss: 22.495580673217773\n",
            "tensor([ 0.3031, -3.0650,  1.7311], requires_grad=True)\n",
            "Loss: 22.49557113647461\n",
            "tensor([ 0.3031, -3.0650,  1.7311], requires_grad=True)\n",
            "Loss: 22.495563507080078\n",
            "tensor([ 0.3031, -3.0650,  1.7312], requires_grad=True)\n",
            "Loss: 22.495553970336914\n",
            "tensor([ 0.3031, -3.0651,  1.7312], requires_grad=True)\n",
            "Loss: 22.495546340942383\n",
            "tensor([ 0.3031, -3.0651,  1.7312], requires_grad=True)\n",
            "Loss: 22.49553871154785\n",
            "tensor([ 0.3031, -3.0651,  1.7312], requires_grad=True)\n",
            "Loss: 22.495529174804688\n",
            "tensor([ 0.3031, -3.0651,  1.7313], requires_grad=True)\n",
            "Loss: 22.495519638061523\n",
            "tensor([ 0.3031, -3.0651,  1.7313], requires_grad=True)\n",
            "Loss: 22.495512008666992\n",
            "tensor([ 0.3031, -3.0651,  1.7313], requires_grad=True)\n",
            "Loss: 22.495506286621094\n",
            "tensor([ 0.3031, -3.0651,  1.7314], requires_grad=True)\n",
            "Loss: 22.495492935180664\n",
            "tensor([ 0.3031, -3.0651,  1.7314], requires_grad=True)\n",
            "Loss: 22.495487213134766\n",
            "tensor([ 0.3031, -3.0651,  1.7314], requires_grad=True)\n",
            "Loss: 22.4954776763916\n",
            "tensor([ 0.3031, -3.0651,  1.7314], requires_grad=True)\n",
            "Loss: 22.49547004699707\n",
            "tensor([ 0.3031, -3.0651,  1.7315], requires_grad=True)\n",
            "Loss: 22.495458602905273\n",
            "tensor([ 0.3031, -3.0651,  1.7315], requires_grad=True)\n",
            "Loss: 22.495452880859375\n",
            "tensor([ 0.3031, -3.0651,  1.7315], requires_grad=True)\n",
            "Loss: 22.49544334411621\n",
            "tensor([ 0.3031, -3.0651,  1.7316], requires_grad=True)\n",
            "Loss: 22.495433807373047\n",
            "tensor([ 0.3031, -3.0652,  1.7316], requires_grad=True)\n",
            "Loss: 22.495424270629883\n",
            "tensor([ 0.3031, -3.0652,  1.7316], requires_grad=True)\n",
            "Loss: 22.49541664123535\n",
            "tensor([ 0.3031, -3.0652,  1.7316], requires_grad=True)\n",
            "Loss: 22.495407104492188\n",
            "tensor([ 0.3031, -3.0652,  1.7317], requires_grad=True)\n",
            "Loss: 22.495399475097656\n",
            "tensor([ 0.3031, -3.0652,  1.7317], requires_grad=True)\n",
            "Loss: 22.495389938354492\n",
            "tensor([ 0.3031, -3.0652,  1.7317], requires_grad=True)\n",
            "Loss: 22.495384216308594\n",
            "tensor([ 0.3031, -3.0652,  1.7318], requires_grad=True)\n",
            "Loss: 22.495376586914062\n",
            "tensor([ 0.3031, -3.0652,  1.7318], requires_grad=True)\n",
            "Loss: 22.495365142822266\n",
            "tensor([ 0.3031, -3.0652,  1.7318], requires_grad=True)\n",
            "Loss: 22.495357513427734\n",
            "tensor([ 0.3031, -3.0652,  1.7318], requires_grad=True)\n",
            "Loss: 22.49534797668457\n",
            "tensor([ 0.3031, -3.0652,  1.7319], requires_grad=True)\n",
            "Loss: 22.49534034729004\n",
            "tensor([ 0.3031, -3.0652,  1.7319], requires_grad=True)\n",
            "Loss: 22.495332717895508\n",
            "tensor([ 0.3031, -3.0652,  1.7319], requires_grad=True)\n",
            "Loss: 22.49532127380371\n",
            "tensor([ 0.3031, -3.0652,  1.7320], requires_grad=True)\n",
            "Loss: 22.49531364440918\n",
            "tensor([ 0.3031, -3.0653,  1.7320], requires_grad=True)\n",
            "Loss: 22.49530601501465\n",
            "tensor([ 0.3031, -3.0653,  1.7320], requires_grad=True)\n",
            "Loss: 22.495296478271484\n",
            "tensor([ 0.3031, -3.0653,  1.7320], requires_grad=True)\n",
            "Loss: 22.49528694152832\n",
            "tensor([ 0.3031, -3.0653,  1.7321], requires_grad=True)\n",
            "Loss: 22.49527931213379\n",
            "tensor([ 0.3031, -3.0653,  1.7321], requires_grad=True)\n",
            "Loss: 22.495269775390625\n",
            "tensor([ 0.3031, -3.0653,  1.7321], requires_grad=True)\n",
            "Loss: 22.495262145996094\n",
            "tensor([ 0.3031, -3.0653,  1.7322], requires_grad=True)\n",
            "Loss: 22.495254516601562\n",
            "tensor([ 0.3031, -3.0653,  1.7322], requires_grad=True)\n",
            "Loss: 22.49524688720703\n",
            "tensor([ 0.3031, -3.0653,  1.7322], requires_grad=True)\n",
            "Loss: 22.495237350463867\n",
            "tensor([ 0.3031, -3.0653,  1.7322], requires_grad=True)\n",
            "Loss: 22.495227813720703\n",
            "tensor([ 0.3031, -3.0653,  1.7323], requires_grad=True)\n",
            "Loss: 22.49521827697754\n",
            "tensor([ 0.3031, -3.0653,  1.7323], requires_grad=True)\n",
            "Loss: 22.495210647583008\n",
            "tensor([ 0.3031, -3.0653,  1.7323], requires_grad=True)\n",
            "Loss: 22.495201110839844\n",
            "tensor([ 0.3031, -3.0653,  1.7324], requires_grad=True)\n",
            "Loss: 22.495193481445312\n",
            "tensor([ 0.3031, -3.0654,  1.7324], requires_grad=True)\n",
            "Loss: 22.49518585205078\n",
            "tensor([ 0.3031, -3.0654,  1.7324], requires_grad=True)\n",
            "Loss: 22.49517822265625\n",
            "tensor([ 0.3031, -3.0654,  1.7324], requires_grad=True)\n",
            "Loss: 22.495168685913086\n",
            "tensor([ 0.3031, -3.0654,  1.7325], requires_grad=True)\n",
            "Loss: 22.495159149169922\n",
            "tensor([ 0.3031, -3.0654,  1.7325], requires_grad=True)\n",
            "Loss: 22.495149612426758\n",
            "tensor([ 0.3031, -3.0654,  1.7325], requires_grad=True)\n",
            "Loss: 22.495141983032227\n",
            "tensor([ 0.3031, -3.0654,  1.7325], requires_grad=True)\n",
            "Loss: 22.495134353637695\n",
            "tensor([ 0.3031, -3.0654,  1.7326], requires_grad=True)\n",
            "Loss: 22.49512481689453\n",
            "tensor([ 0.3031, -3.0654,  1.7326], requires_grad=True)\n",
            "Loss: 22.4951171875\n",
            "tensor([ 0.3031, -3.0654,  1.7326], requires_grad=True)\n",
            "Loss: 22.495107650756836\n",
            "tensor([ 0.3031, -3.0654,  1.7327], requires_grad=True)\n",
            "Loss: 22.495098114013672\n",
            "tensor([ 0.3031, -3.0654,  1.7327], requires_grad=True)\n",
            "Loss: 22.495088577270508\n",
            "tensor([ 0.3031, -3.0654,  1.7327], requires_grad=True)\n",
            "Loss: 22.49508285522461\n",
            "tensor([ 0.3031, -3.0654,  1.7327], requires_grad=True)\n",
            "Loss: 22.495073318481445\n",
            "tensor([ 0.3031, -3.0655,  1.7328], requires_grad=True)\n",
            "Loss: 22.495065689086914\n",
            "tensor([ 0.3031, -3.0655,  1.7328], requires_grad=True)\n",
            "Loss: 22.49505615234375\n",
            "tensor([ 0.3031, -3.0655,  1.7328], requires_grad=True)\n",
            "Loss: 22.49504852294922\n",
            "tensor([ 0.3031, -3.0655,  1.7329], requires_grad=True)\n",
            "Loss: 22.495038986206055\n",
            "tensor([ 0.3031, -3.0655,  1.7329], requires_grad=True)\n",
            "Loss: 22.49502944946289\n",
            "tensor([ 0.3031, -3.0655,  1.7329], requires_grad=True)\n",
            "Loss: 22.49502182006836\n",
            "tensor([ 0.3031, -3.0655,  1.7329], requires_grad=True)\n",
            "Loss: 22.495012283325195\n",
            "tensor([ 0.3031, -3.0655,  1.7330], requires_grad=True)\n",
            "Loss: 22.495004653930664\n",
            "tensor([ 0.3031, -3.0655,  1.7330], requires_grad=True)\n",
            "Loss: 22.4949951171875\n",
            "tensor([ 0.3031, -3.0655,  1.7330], requires_grad=True)\n",
            "Loss: 22.49498748779297\n",
            "tensor([ 0.3031, -3.0655,  1.7331], requires_grad=True)\n",
            "Loss: 22.494977951049805\n",
            "tensor([ 0.3031, -3.0655,  1.7331], requires_grad=True)\n",
            "Loss: 22.494970321655273\n",
            "tensor([ 0.3031, -3.0655,  1.7331], requires_grad=True)\n",
            "Loss: 22.49496078491211\n",
            "tensor([ 0.3031, -3.0655,  1.7331], requires_grad=True)\n",
            "Loss: 22.494953155517578\n",
            "tensor([ 0.3031, -3.0656,  1.7332], requires_grad=True)\n",
            "Loss: 22.494943618774414\n",
            "tensor([ 0.3031, -3.0656,  1.7332], requires_grad=True)\n",
            "Loss: 22.49493408203125\n",
            "tensor([ 0.3031, -3.0656,  1.7332], requires_grad=True)\n",
            "Loss: 22.49492835998535\n",
            "tensor([ 0.3031, -3.0656,  1.7333], requires_grad=True)\n",
            "Loss: 22.494918823242188\n",
            "tensor([ 0.3031, -3.0656,  1.7333], requires_grad=True)\n",
            "Loss: 22.494909286499023\n",
            "tensor([ 0.3031, -3.0656,  1.7333], requires_grad=True)\n",
            "Loss: 22.49489974975586\n",
            "tensor([ 0.3031, -3.0656,  1.7333], requires_grad=True)\n",
            "Loss: 22.494892120361328\n",
            "tensor([ 0.3031, -3.0656,  1.7334], requires_grad=True)\n",
            "Loss: 22.494882583618164\n",
            "tensor([ 0.3031, -3.0656,  1.7334], requires_grad=True)\n",
            "Loss: 22.494874954223633\n",
            "tensor([ 0.3031, -3.0656,  1.7334], requires_grad=True)\n",
            "Loss: 22.49486541748047\n",
            "tensor([ 0.3031, -3.0656,  1.7335], requires_grad=True)\n",
            "Loss: 22.494857788085938\n",
            "tensor([ 0.3031, -3.0656,  1.7335], requires_grad=True)\n",
            "Loss: 22.494848251342773\n",
            "tensor([ 0.3031, -3.0656,  1.7335], requires_grad=True)\n",
            "Loss: 22.494840621948242\n",
            "tensor([ 0.3031, -3.0656,  1.7335], requires_grad=True)\n",
            "Loss: 22.494831085205078\n",
            "tensor([ 0.3031, -3.0657,  1.7336], requires_grad=True)\n",
            "Loss: 22.494823455810547\n",
            "tensor([ 0.3031, -3.0657,  1.7336], requires_grad=True)\n",
            "Loss: 22.494813919067383\n",
            "tensor([ 0.3031, -3.0657,  1.7336], requires_grad=True)\n",
            "Loss: 22.49480438232422\n",
            "tensor([ 0.3031, -3.0657,  1.7337], requires_grad=True)\n",
            "Loss: 22.49479866027832\n",
            "tensor([ 0.3031, -3.0657,  1.7337], requires_grad=True)\n",
            "Loss: 22.494789123535156\n",
            "tensor([ 0.3031, -3.0657,  1.7337], requires_grad=True)\n",
            "Loss: 22.494779586791992\n",
            "tensor([ 0.3031, -3.0657,  1.7337], requires_grad=True)\n",
            "Loss: 22.494770050048828\n",
            "tensor([ 0.3031, -3.0657,  1.7338], requires_grad=True)\n",
            "Loss: 22.494762420654297\n",
            "tensor([ 0.3031, -3.0657,  1.7338], requires_grad=True)\n",
            "Loss: 22.494754791259766\n",
            "tensor([ 0.3031, -3.0657,  1.7338], requires_grad=True)\n",
            "Loss: 22.4947452545166\n",
            "tensor([ 0.3031, -3.0657,  1.7339], requires_grad=True)\n",
            "Loss: 22.494735717773438\n",
            "tensor([ 0.3031, -3.0657,  1.7339], requires_grad=True)\n",
            "Loss: 22.494728088378906\n",
            "tensor([ 0.3031, -3.0657,  1.7339], requires_grad=True)\n",
            "Loss: 22.494720458984375\n",
            "tensor([ 0.3031, -3.0657,  1.7339], requires_grad=True)\n",
            "Loss: 22.49471092224121\n",
            "tensor([ 0.3031, -3.0658,  1.7340], requires_grad=True)\n",
            "Loss: 22.494701385498047\n",
            "tensor([ 0.3031, -3.0658,  1.7340], requires_grad=True)\n",
            "Loss: 22.49469566345215\n",
            "tensor([ 0.3031, -3.0658,  1.7340], requires_grad=True)\n",
            "Loss: 22.494686126708984\n",
            "tensor([ 0.3031, -3.0658,  1.7341], requires_grad=True)\n",
            "Loss: 22.49467658996582\n",
            "tensor([ 0.3031, -3.0658,  1.7341], requires_grad=True)\n",
            "Loss: 22.49466896057129\n",
            "tensor([ 0.3031, -3.0658,  1.7341], requires_grad=True)\n",
            "Loss: 22.494657516479492\n",
            "tensor([ 0.3031, -3.0658,  1.7341], requires_grad=True)\n",
            "Loss: 22.49464988708496\n",
            "tensor([ 0.3031, -3.0658,  1.7342], requires_grad=True)\n",
            "Loss: 22.49464225769043\n",
            "tensor([ 0.3031, -3.0658,  1.7342], requires_grad=True)\n",
            "Loss: 22.494632720947266\n",
            "tensor([ 0.3031, -3.0658,  1.7342], requires_grad=True)\n",
            "Loss: 22.4946231842041\n",
            "tensor([ 0.3031, -3.0658,  1.7343], requires_grad=True)\n",
            "Loss: 22.49461555480957\n",
            "tensor([ 0.3031, -3.0658,  1.7343], requires_grad=True)\n",
            "Loss: 22.49460792541504\n",
            "tensor([ 0.3031, -3.0658,  1.7343], requires_grad=True)\n",
            "Loss: 22.494598388671875\n",
            "tensor([ 0.3031, -3.0658,  1.7343], requires_grad=True)\n",
            "Loss: 22.494590759277344\n",
            "tensor([ 0.3031, -3.0659,  1.7344], requires_grad=True)\n",
            "Loss: 22.49458122253418\n",
            "tensor([ 0.3031, -3.0659,  1.7344], requires_grad=True)\n",
            "Loss: 22.49457550048828\n",
            "tensor([ 0.3031, -3.0659,  1.7344], requires_grad=True)\n",
            "Loss: 22.494564056396484\n",
            "tensor([ 0.3031, -3.0659,  1.7345], requires_grad=True)\n",
            "Loss: 22.494556427001953\n",
            "tensor([ 0.3031, -3.0659,  1.7345], requires_grad=True)\n",
            "Loss: 22.494548797607422\n",
            "tensor([ 0.3031, -3.0659,  1.7345], requires_grad=True)\n",
            "Loss: 22.494539260864258\n",
            "tensor([ 0.3031, -3.0659,  1.7345], requires_grad=True)\n",
            "Loss: 22.494529724121094\n",
            "tensor([ 0.3031, -3.0659,  1.7346], requires_grad=True)\n",
            "Loss: 22.494522094726562\n",
            "tensor([ 0.3031, -3.0659,  1.7346], requires_grad=True)\n",
            "Loss: 22.4945125579834\n",
            "tensor([ 0.3031, -3.0659,  1.7346], requires_grad=True)\n",
            "Loss: 22.494504928588867\n",
            "tensor([ 0.3031, -3.0659,  1.7347], requires_grad=True)\n",
            "Loss: 22.494495391845703\n",
            "tensor([ 0.3031, -3.0659,  1.7347], requires_grad=True)\n",
            "Loss: 22.494487762451172\n",
            "tensor([ 0.3031, -3.0659,  1.7347], requires_grad=True)\n",
            "Loss: 22.494478225708008\n",
            "tensor([ 0.3031, -3.0659,  1.7347], requires_grad=True)\n",
            "Loss: 22.494470596313477\n",
            "tensor([ 0.3031, -3.0660,  1.7348], requires_grad=True)\n",
            "Loss: 22.494461059570312\n",
            "tensor([ 0.3031, -3.0660,  1.7348], requires_grad=True)\n",
            "Loss: 22.49445343017578\n",
            "tensor([ 0.3031, -3.0660,  1.7348], requires_grad=True)\n",
            "Loss: 22.494443893432617\n",
            "tensor([ 0.3031, -3.0660,  1.7349], requires_grad=True)\n",
            "Loss: 22.494436264038086\n",
            "tensor([ 0.3031, -3.0660,  1.7349], requires_grad=True)\n",
            "Loss: 22.494426727294922\n",
            "tensor([ 0.3031, -3.0660,  1.7349], requires_grad=True)\n",
            "Loss: 22.49441909790039\n",
            "tensor([ 0.3031, -3.0660,  1.7349], requires_grad=True)\n",
            "Loss: 22.494409561157227\n",
            "tensor([ 0.3031, -3.0660,  1.7350], requires_grad=True)\n",
            "Loss: 22.494401931762695\n",
            "tensor([ 0.3031, -3.0660,  1.7350], requires_grad=True)\n",
            "Loss: 22.49439239501953\n",
            "tensor([ 0.3031, -3.0660,  1.7350], requires_grad=True)\n",
            "Loss: 22.494384765625\n",
            "tensor([ 0.3031, -3.0660,  1.7351], requires_grad=True)\n",
            "Loss: 22.49437713623047\n",
            "tensor([ 0.3031, -3.0660,  1.7351], requires_grad=True)\n",
            "Loss: 22.494365692138672\n",
            "tensor([ 0.3031, -3.0660,  1.7351], requires_grad=True)\n",
            "Loss: 22.494356155395508\n",
            "tensor([ 0.3031, -3.0660,  1.7351], requires_grad=True)\n",
            "Loss: 22.494348526000977\n",
            "tensor([ 0.3031, -3.0661,  1.7352], requires_grad=True)\n",
            "Loss: 22.494340896606445\n",
            "tensor([ 0.3031, -3.0661,  1.7352], requires_grad=True)\n",
            "Loss: 22.494333267211914\n",
            "tensor([ 0.3031, -3.0661,  1.7352], requires_grad=True)\n",
            "Loss: 22.49432373046875\n",
            "tensor([ 0.3031, -3.0661,  1.7353], requires_grad=True)\n",
            "Loss: 22.49431610107422\n",
            "tensor([ 0.3031, -3.0661,  1.7353], requires_grad=True)\n",
            "Loss: 22.494304656982422\n",
            "tensor([ 0.3031, -3.0661,  1.7353], requires_grad=True)\n",
            "Loss: 22.49429702758789\n",
            "tensor([ 0.3031, -3.0661,  1.7353], requires_grad=True)\n",
            "Loss: 22.494287490844727\n",
            "tensor([ 0.3031, -3.0661,  1.7354], requires_grad=True)\n",
            "Loss: 22.494281768798828\n",
            "tensor([ 0.3031, -3.0661,  1.7354], requires_grad=True)\n",
            "Loss: 22.494272232055664\n",
            "tensor([ 0.3031, -3.0661,  1.7354], requires_grad=True)\n",
            "Loss: 22.4942626953125\n",
            "tensor([ 0.3031, -3.0661,  1.7355], requires_grad=True)\n",
            "Loss: 22.49425506591797\n",
            "tensor([ 0.3031, -3.0661,  1.7355], requires_grad=True)\n",
            "Loss: 22.494245529174805\n",
            "tensor([ 0.3031, -3.0661,  1.7355], requires_grad=True)\n",
            "Loss: 22.494237899780273\n",
            "tensor([ 0.3031, -3.0661,  1.7355], requires_grad=True)\n",
            "Loss: 22.49422836303711\n",
            "tensor([ 0.3031, -3.0662,  1.7356], requires_grad=True)\n",
            "Loss: 22.494220733642578\n",
            "tensor([ 0.3031, -3.0662,  1.7356], requires_grad=True)\n",
            "Loss: 22.494213104248047\n",
            "tensor([ 0.3031, -3.0662,  1.7356], requires_grad=True)\n",
            "Loss: 22.494203567504883\n",
            "tensor([ 0.3031, -3.0662,  1.7357], requires_grad=True)\n",
            "Loss: 22.49419403076172\n",
            "tensor([ 0.3031, -3.0662,  1.7357], requires_grad=True)\n",
            "Loss: 22.494184494018555\n",
            "tensor([ 0.3031, -3.0662,  1.7357], requires_grad=True)\n",
            "Loss: 22.49417495727539\n",
            "tensor([ 0.3031, -3.0662,  1.7357], requires_grad=True)\n",
            "Loss: 22.49416732788086\n",
            "tensor([ 0.3031, -3.0662,  1.7358], requires_grad=True)\n",
            "Loss: 22.494159698486328\n",
            "tensor([ 0.3031, -3.0662,  1.7358], requires_grad=True)\n",
            "Loss: 22.494152069091797\n",
            "tensor([ 0.3031, -3.0662,  1.7358], requires_grad=True)\n",
            "Loss: 22.494142532348633\n",
            "tensor([ 0.3031, -3.0662,  1.7359], requires_grad=True)\n",
            "Loss: 22.49413299560547\n",
            "tensor([ 0.3031, -3.0662,  1.7359], requires_grad=True)\n",
            "Loss: 22.494125366210938\n",
            "tensor([ 0.3031, -3.0662,  1.7359], requires_grad=True)\n",
            "Loss: 22.494117736816406\n",
            "tensor([ 0.3031, -3.0662,  1.7359], requires_grad=True)\n",
            "Loss: 22.494108200073242\n",
            "tensor([ 0.3031, -3.0663,  1.7360], requires_grad=True)\n",
            "Loss: 22.494098663330078\n",
            "tensor([ 0.3031, -3.0663,  1.7360], requires_grad=True)\n",
            "Loss: 22.494091033935547\n",
            "tensor([ 0.3031, -3.0663,  1.7360], requires_grad=True)\n",
            "Loss: 22.494083404541016\n",
            "tensor([ 0.3031, -3.0663,  1.7361], requires_grad=True)\n",
            "Loss: 22.49407386779785\n",
            "tensor([ 0.3031, -3.0663,  1.7361], requires_grad=True)\n",
            "Loss: 22.494064331054688\n",
            "tensor([ 0.3031, -3.0663,  1.7361], requires_grad=True)\n",
            "Loss: 22.494054794311523\n",
            "tensor([ 0.3031, -3.0663,  1.7361], requires_grad=True)\n",
            "Loss: 22.494047164916992\n",
            "tensor([ 0.3031, -3.0663,  1.7362], requires_grad=True)\n",
            "Loss: 22.49403953552246\n",
            "tensor([ 0.3031, -3.0663,  1.7362], requires_grad=True)\n",
            "Loss: 22.49403190612793\n",
            "tensor([ 0.3031, -3.0663,  1.7362], requires_grad=True)\n",
            "Loss: 22.494022369384766\n",
            "tensor([ 0.3031, -3.0663,  1.7363], requires_grad=True)\n",
            "Loss: 22.4940128326416\n",
            "tensor([ 0.3031, -3.0663,  1.7363], requires_grad=True)\n",
            "Loss: 22.49400520324707\n",
            "tensor([ 0.3031, -3.0663,  1.7363], requires_grad=True)\n",
            "Loss: 22.493995666503906\n",
            "tensor([ 0.3031, -3.0663,  1.7363], requires_grad=True)\n",
            "Loss: 22.493988037109375\n",
            "tensor([ 0.3031, -3.0664,  1.7364], requires_grad=True)\n",
            "Loss: 22.49397850036621\n",
            "tensor([ 0.3031, -3.0664,  1.7364], requires_grad=True)\n",
            "Loss: 22.493968963623047\n",
            "tensor([ 0.3031, -3.0664,  1.7364], requires_grad=True)\n",
            "Loss: 22.493961334228516\n",
            "tensor([ 0.3031, -3.0664,  1.7365], requires_grad=True)\n",
            "Loss: 22.49395179748535\n",
            "tensor([ 0.3031, -3.0664,  1.7365], requires_grad=True)\n",
            "Loss: 22.49394416809082\n",
            "tensor([ 0.3031, -3.0664,  1.7365], requires_grad=True)\n",
            "Loss: 22.49393653869629\n",
            "tensor([ 0.3031, -3.0664,  1.7365], requires_grad=True)\n",
            "Loss: 22.493927001953125\n",
            "tensor([ 0.3031, -3.0664,  1.7366], requires_grad=True)\n",
            "Loss: 22.493919372558594\n",
            "tensor([ 0.3031, -3.0664,  1.7366], requires_grad=True)\n",
            "Loss: 22.49390983581543\n",
            "tensor([ 0.3031, -3.0664,  1.7366], requires_grad=True)\n",
            "Loss: 22.493900299072266\n",
            "tensor([ 0.3031, -3.0664,  1.7367], requires_grad=True)\n",
            "Loss: 22.493892669677734\n",
            "tensor([ 0.3032, -3.0664,  1.7367], requires_grad=True)\n",
            "Loss: 22.493885040283203\n",
            "tensor([ 0.3032, -3.0664,  1.7367], requires_grad=True)\n",
            "Loss: 22.49387550354004\n",
            "tensor([ 0.3032, -3.0664,  1.7367], requires_grad=True)\n",
            "Loss: 22.493867874145508\n",
            "tensor([ 0.3032, -3.0665,  1.7368], requires_grad=True)\n",
            "Loss: 22.493858337402344\n",
            "tensor([ 0.3032, -3.0665,  1.7368], requires_grad=True)\n",
            "Loss: 22.49384880065918\n",
            "tensor([ 0.3032, -3.0665,  1.7368], requires_grad=True)\n",
            "Loss: 22.49384117126465\n",
            "tensor([ 0.3032, -3.0665,  1.7369], requires_grad=True)\n",
            "Loss: 22.493833541870117\n",
            "tensor([ 0.3032, -3.0665,  1.7369], requires_grad=True)\n",
            "Loss: 22.493824005126953\n",
            "tensor([ 0.3032, -3.0665,  1.7369], requires_grad=True)\n",
            "Loss: 22.49381446838379\n",
            "tensor([ 0.3032, -3.0665,  1.7369], requires_grad=True)\n",
            "Loss: 22.493806838989258\n",
            "tensor([ 0.3032, -3.0665,  1.7370], requires_grad=True)\n",
            "Loss: 22.493799209594727\n",
            "tensor([ 0.3032, -3.0665,  1.7370], requires_grad=True)\n",
            "Loss: 22.49378776550293\n",
            "tensor([ 0.3032, -3.0665,  1.7370], requires_grad=True)\n",
            "Loss: 22.4937801361084\n",
            "tensor([ 0.3032, -3.0665,  1.7371], requires_grad=True)\n",
            "Loss: 22.493772506713867\n",
            "tensor([ 0.3032, -3.0665,  1.7371], requires_grad=True)\n",
            "Loss: 22.493762969970703\n",
            "tensor([ 0.3032, -3.0665,  1.7371], requires_grad=True)\n",
            "Loss: 22.493755340576172\n",
            "tensor([ 0.3032, -3.0665,  1.7371], requires_grad=True)\n",
            "Loss: 22.493745803833008\n",
            "tensor([ 0.3032, -3.0666,  1.7372], requires_grad=True)\n",
            "Loss: 22.493738174438477\n",
            "tensor([ 0.3032, -3.0666,  1.7372], requires_grad=True)\n",
            "Loss: 22.493728637695312\n",
            "tensor([ 0.3032, -3.0666,  1.7372], requires_grad=True)\n",
            "Loss: 22.49371910095215\n",
            "tensor([ 0.3032, -3.0666,  1.7373], requires_grad=True)\n",
            "Loss: 22.49371337890625\n",
            "tensor([ 0.3032, -3.0666,  1.7373], requires_grad=True)\n",
            "Loss: 22.493703842163086\n",
            "tensor([ 0.3032, -3.0666,  1.7373], requires_grad=True)\n",
            "Loss: 22.493694305419922\n",
            "tensor([ 0.3032, -3.0666,  1.7373], requires_grad=True)\n",
            "Loss: 22.49368667602539\n",
            "tensor([ 0.3032, -3.0666,  1.7374], requires_grad=True)\n",
            "Loss: 22.493677139282227\n",
            "tensor([ 0.3032, -3.0666,  1.7374], requires_grad=True)\n",
            "Loss: 22.493669509887695\n",
            "tensor([ 0.3032, -3.0666,  1.7374], requires_grad=True)\n",
            "Loss: 22.49365997314453\n",
            "tensor([ 0.3032, -3.0666,  1.7375], requires_grad=True)\n",
            "Loss: 22.49365234375\n",
            "tensor([ 0.3032, -3.0666,  1.7375], requires_grad=True)\n",
            "Loss: 22.493642807006836\n",
            "tensor([ 0.3032, -3.0666,  1.7375], requires_grad=True)\n",
            "Loss: 22.493633270263672\n",
            "tensor([ 0.3032, -3.0666,  1.7375], requires_grad=True)\n",
            "Loss: 22.49362564086914\n",
            "tensor([ 0.3032, -3.0667,  1.7376], requires_grad=True)\n",
            "Loss: 22.49361801147461\n",
            "tensor([ 0.3032, -3.0667,  1.7376], requires_grad=True)\n",
            "Loss: 22.493608474731445\n",
            "tensor([ 0.3032, -3.0667,  1.7376], requires_grad=True)\n",
            "Loss: 22.493600845336914\n",
            "tensor([ 0.3032, -3.0667,  1.7376], requires_grad=True)\n",
            "Loss: 22.493593215942383\n",
            "tensor([ 0.3032, -3.0667,  1.7377], requires_grad=True)\n",
            "Loss: 22.49358367919922\n",
            "tensor([ 0.3032, -3.0667,  1.7377], requires_grad=True)\n",
            "Loss: 22.493574142456055\n",
            "tensor([ 0.3032, -3.0667,  1.7377], requires_grad=True)\n",
            "Loss: 22.49356460571289\n",
            "tensor([ 0.3032, -3.0667,  1.7378], requires_grad=True)\n",
            "Loss: 22.49355697631836\n",
            "tensor([ 0.3032, -3.0667,  1.7378], requires_grad=True)\n",
            "Loss: 22.493549346923828\n",
            "tensor([ 0.3032, -3.0667,  1.7378], requires_grad=True)\n",
            "Loss: 22.493541717529297\n",
            "tensor([ 0.3032, -3.0667,  1.7378], requires_grad=True)\n",
            "Loss: 22.4935302734375\n",
            "tensor([ 0.3032, -3.0667,  1.7379], requires_grad=True)\n",
            "Loss: 22.49352264404297\n",
            "tensor([ 0.3032, -3.0667,  1.7379], requires_grad=True)\n",
            "Loss: 22.493513107299805\n",
            "tensor([ 0.3032, -3.0667,  1.7379], requires_grad=True)\n",
            "Loss: 22.49350357055664\n",
            "tensor([ 0.3032, -3.0668,  1.7380], requires_grad=True)\n",
            "Loss: 22.49349594116211\n",
            "tensor([ 0.3032, -3.0668,  1.7380], requires_grad=True)\n",
            "Loss: 22.493488311767578\n",
            "tensor([ 0.3032, -3.0668,  1.7380], requires_grad=True)\n",
            "Loss: 22.493480682373047\n",
            "tensor([ 0.3032, -3.0668,  1.7380], requires_grad=True)\n",
            "Loss: 22.49346923828125\n",
            "tensor([ 0.3032, -3.0668,  1.7381], requires_grad=True)\n",
            "Loss: 22.49346351623535\n",
            "tensor([ 0.3032, -3.0668,  1.7381], requires_grad=True)\n",
            "Loss: 22.493453979492188\n",
            "tensor([ 0.3032, -3.0668,  1.7381], requires_grad=True)\n",
            "Loss: 22.493444442749023\n",
            "tensor([ 0.3032, -3.0668,  1.7382], requires_grad=True)\n",
            "Loss: 22.493436813354492\n",
            "tensor([ 0.3032, -3.0668,  1.7382], requires_grad=True)\n",
            "Loss: 22.493427276611328\n",
            "tensor([ 0.3032, -3.0668,  1.7382], requires_grad=True)\n",
            "Loss: 22.493419647216797\n",
            "tensor([ 0.3032, -3.0668,  1.7382], requires_grad=True)\n",
            "Loss: 22.493410110473633\n",
            "tensor([ 0.3032, -3.0668,  1.7383], requires_grad=True)\n",
            "Loss: 22.4934024810791\n",
            "tensor([ 0.3032, -3.0668,  1.7383], requires_grad=True)\n",
            "Loss: 22.493392944335938\n",
            "tensor([ 0.3032, -3.0668,  1.7383], requires_grad=True)\n",
            "Loss: 22.493383407592773\n",
            "tensor([ 0.3032, -3.0669,  1.7384], requires_grad=True)\n",
            "Loss: 22.493377685546875\n",
            "tensor([ 0.3032, -3.0669,  1.7384], requires_grad=True)\n",
            "Loss: 22.49336814880371\n",
            "tensor([ 0.3032, -3.0669,  1.7384], requires_grad=True)\n",
            "Loss: 22.493358612060547\n",
            "tensor([ 0.3032, -3.0669,  1.7384], requires_grad=True)\n",
            "Loss: 22.493350982666016\n",
            "tensor([ 0.3032, -3.0669,  1.7385], requires_grad=True)\n",
            "Loss: 22.493343353271484\n",
            "tensor([ 0.3032, -3.0669,  1.7385], requires_grad=True)\n",
            "Loss: 22.493331909179688\n",
            "tensor([ 0.3032, -3.0669,  1.7385], requires_grad=True)\n",
            "Loss: 22.493324279785156\n",
            "tensor([ 0.3032, -3.0669,  1.7386], requires_grad=True)\n",
            "Loss: 22.493316650390625\n",
            "tensor([ 0.3032, -3.0669,  1.7386], requires_grad=True)\n",
            "Loss: 22.493309020996094\n",
            "tensor([ 0.3032, -3.0669,  1.7386], requires_grad=True)\n",
            "Loss: 22.49329948425293\n",
            "tensor([ 0.3032, -3.0669,  1.7386], requires_grad=True)\n",
            "Loss: 22.493289947509766\n",
            "tensor([ 0.3032, -3.0669,  1.7387], requires_grad=True)\n",
            "Loss: 22.493282318115234\n",
            "tensor([ 0.3032, -3.0669,  1.7387], requires_grad=True)\n",
            "Loss: 22.49327278137207\n",
            "tensor([ 0.3032, -3.0669,  1.7387], requires_grad=True)\n",
            "Loss: 22.493263244628906\n",
            "tensor([ 0.3032, -3.0670,  1.7388], requires_grad=True)\n",
            "Loss: 22.493253707885742\n",
            "tensor([ 0.3032, -3.0670,  1.7388], requires_grad=True)\n",
            "Loss: 22.493247985839844\n",
            "tensor([ 0.3032, -3.0670,  1.7388], requires_grad=True)\n",
            "Loss: 22.49323844909668\n",
            "tensor([ 0.3032, -3.0670,  1.7388], requires_grad=True)\n",
            "Loss: 22.49323081970215\n",
            "tensor([ 0.3032, -3.0670,  1.7389], requires_grad=True)\n",
            "Loss: 22.493221282958984\n",
            "tensor([ 0.3032, -3.0670,  1.7389], requires_grad=True)\n",
            "Loss: 22.49321174621582\n",
            "tensor([ 0.3032, -3.0670,  1.7389], requires_grad=True)\n",
            "Loss: 22.49320411682129\n",
            "tensor([ 0.3032, -3.0670,  1.7390], requires_grad=True)\n",
            "Loss: 22.493196487426758\n",
            "tensor([ 0.3032, -3.0670,  1.7390], requires_grad=True)\n",
            "Loss: 22.493186950683594\n",
            "tensor([ 0.3032, -3.0670,  1.7390], requires_grad=True)\n",
            "Loss: 22.49317741394043\n",
            "tensor([ 0.3032, -3.0670,  1.7390], requires_grad=True)\n",
            "Loss: 22.49317169189453\n",
            "tensor([ 0.3032, -3.0670,  1.7391], requires_grad=True)\n",
            "Loss: 22.493160247802734\n",
            "tensor([ 0.3032, -3.0670,  1.7391], requires_grad=True)\n",
            "Loss: 22.493152618408203\n",
            "tensor([ 0.3032, -3.0670,  1.7391], requires_grad=True)\n",
            "Loss: 22.493141174316406\n",
            "tensor([ 0.3032, -3.0671,  1.7392], requires_grad=True)\n",
            "Loss: 22.493135452270508\n",
            "tensor([ 0.3032, -3.0671,  1.7392], requires_grad=True)\n",
            "Loss: 22.493125915527344\n",
            "tensor([ 0.3032, -3.0671,  1.7392], requires_grad=True)\n",
            "Loss: 22.49311637878418\n",
            "tensor([ 0.3032, -3.0671,  1.7392], requires_grad=True)\n",
            "Loss: 22.49310874938965\n",
            "tensor([ 0.3032, -3.0671,  1.7393], requires_grad=True)\n",
            "Loss: 22.493099212646484\n",
            "tensor([ 0.3032, -3.0671,  1.7393], requires_grad=True)\n",
            "Loss: 22.493091583251953\n",
            "tensor([ 0.3032, -3.0671,  1.7393], requires_grad=True)\n",
            "Loss: 22.493083953857422\n",
            "tensor([ 0.3032, -3.0671,  1.7394], requires_grad=True)\n",
            "Loss: 22.493074417114258\n",
            "tensor([ 0.3032, -3.0671,  1.7394], requires_grad=True)\n",
            "Loss: 22.493064880371094\n",
            "tensor([ 0.3032, -3.0671,  1.7394], requires_grad=True)\n",
            "Loss: 22.493057250976562\n",
            "tensor([ 0.3032, -3.0671,  1.7394], requires_grad=True)\n",
            "Loss: 22.49304962158203\n",
            "tensor([ 0.3032, -3.0671,  1.7395], requires_grad=True)\n",
            "Loss: 22.4930419921875\n",
            "tensor([ 0.3032, -3.0671,  1.7395], requires_grad=True)\n",
            "Loss: 22.493030548095703\n",
            "tensor([ 0.3032, -3.0671,  1.7395], requires_grad=True)\n",
            "Loss: 22.493024826049805\n",
            "tensor([ 0.3032, -3.0672,  1.7396], requires_grad=True)\n",
            "Loss: 22.493011474609375\n",
            "tensor([ 0.3032, -3.0672,  1.7396], requires_grad=True)\n",
            "Loss: 22.493005752563477\n",
            "tensor([ 0.3032, -3.0672,  1.7396], requires_grad=True)\n",
            "Loss: 22.492996215820312\n",
            "tensor([ 0.3032, -3.0672,  1.7396], requires_grad=True)\n",
            "Loss: 22.49298858642578\n",
            "tensor([ 0.3032, -3.0672,  1.7397], requires_grad=True)\n",
            "Loss: 22.492979049682617\n",
            "tensor([ 0.3032, -3.0672,  1.7397], requires_grad=True)\n",
            "Loss: 22.492971420288086\n",
            "tensor([ 0.3032, -3.0672,  1.7397], requires_grad=True)\n",
            "Loss: 22.492963790893555\n",
            "tensor([ 0.3032, -3.0672,  1.7398], requires_grad=True)\n",
            "Loss: 22.49295425415039\n",
            "tensor([ 0.3032, -3.0672,  1.7398], requires_grad=True)\n",
            "Loss: 22.492944717407227\n",
            "tensor([ 0.3032, -3.0672,  1.7398], requires_grad=True)\n",
            "Loss: 22.492937088012695\n",
            "tensor([ 0.3032, -3.0672,  1.7398], requires_grad=True)\n",
            "Loss: 22.49292755126953\n",
            "tensor([ 0.3032, -3.0672,  1.7399], requires_grad=True)\n",
            "Loss: 22.492919921875\n",
            "tensor([ 0.3032, -3.0672,  1.7399], requires_grad=True)\n",
            "Loss: 22.49291229248047\n",
            "tensor([ 0.3032, -3.0672,  1.7399], requires_grad=True)\n",
            "Loss: 22.492902755737305\n",
            "tensor([ 0.3032, -3.0673,  1.7400], requires_grad=True)\n",
            "Loss: 22.49289321899414\n",
            "tensor([ 0.3032, -3.0673,  1.7400], requires_grad=True)\n",
            "Loss: 22.492883682250977\n",
            "tensor([ 0.3032, -3.0673,  1.7400], requires_grad=True)\n",
            "Loss: 22.492877960205078\n",
            "tensor([ 0.3032, -3.0673,  1.7400], requires_grad=True)\n",
            "Loss: 22.492868423461914\n",
            "tensor([ 0.3032, -3.0673,  1.7401], requires_grad=True)\n",
            "Loss: 22.49285888671875\n",
            "tensor([ 0.3032, -3.0673,  1.7401], requires_grad=True)\n",
            "Loss: 22.49285125732422\n",
            "tensor([ 0.3032, -3.0673,  1.7401], requires_grad=True)\n",
            "Loss: 22.492843627929688\n",
            "tensor([ 0.3032, -3.0673,  1.7402], requires_grad=True)\n",
            "Loss: 22.492834091186523\n",
            "tensor([ 0.3032, -3.0673,  1.7402], requires_grad=True)\n",
            "Loss: 22.49282455444336\n",
            "tensor([ 0.3032, -3.0673,  1.7402], requires_grad=True)\n",
            "Loss: 22.492816925048828\n",
            "tensor([ 0.3032, -3.0673,  1.7402], requires_grad=True)\n",
            "Loss: 22.49280548095703\n",
            "tensor([ 0.3032, -3.0673,  1.7403], requires_grad=True)\n",
            "Loss: 22.492799758911133\n",
            "tensor([ 0.3032, -3.0673,  1.7403], requires_grad=True)\n",
            "Loss: 22.4927921295166\n",
            "tensor([ 0.3032, -3.0673,  1.7403], requires_grad=True)\n",
            "Loss: 22.492782592773438\n",
            "tensor([ 0.3032, -3.0674,  1.7404], requires_grad=True)\n",
            "Loss: 22.492773056030273\n",
            "tensor([ 0.3032, -3.0674,  1.7404], requires_grad=True)\n",
            "Loss: 22.492765426635742\n",
            "tensor([ 0.3032, -3.0674,  1.7404], requires_grad=True)\n",
            "Loss: 22.492753982543945\n",
            "tensor([ 0.3032, -3.0674,  1.7404], requires_grad=True)\n",
            "Loss: 22.492748260498047\n",
            "tensor([ 0.3032, -3.0674,  1.7405], requires_grad=True)\n",
            "Loss: 22.492738723754883\n",
            "tensor([ 0.3032, -3.0674,  1.7405], requires_grad=True)\n",
            "Loss: 22.49272918701172\n",
            "tensor([ 0.3032, -3.0674,  1.7405], requires_grad=True)\n",
            "Loss: 22.492721557617188\n",
            "tensor([ 0.3032, -3.0674,  1.7406], requires_grad=True)\n",
            "Loss: 22.492713928222656\n",
            "tensor([ 0.3032, -3.0674,  1.7406], requires_grad=True)\n",
            "Loss: 22.492704391479492\n",
            "tensor([ 0.3032, -3.0674,  1.7406], requires_grad=True)\n",
            "Loss: 22.492694854736328\n",
            "tensor([ 0.3032, -3.0674,  1.7406], requires_grad=True)\n",
            "Loss: 22.492685317993164\n",
            "tensor([ 0.3032, -3.0674,  1.7407], requires_grad=True)\n",
            "Loss: 22.492679595947266\n",
            "tensor([ 0.3032, -3.0674,  1.7407], requires_grad=True)\n",
            "Loss: 22.492671966552734\n",
            "tensor([ 0.3032, -3.0674,  1.7407], requires_grad=True)\n",
            "Loss: 22.49266242980957\n",
            "tensor([ 0.3032, -3.0675,  1.7408], requires_grad=True)\n",
            "Loss: 22.49265480041504\n",
            "tensor([ 0.3032, -3.0675,  1.7408], requires_grad=True)\n",
            "Loss: 22.492643356323242\n",
            "tensor([ 0.3032, -3.0675,  1.7408], requires_grad=True)\n",
            "Loss: 22.49263572692871\n",
            "tensor([ 0.3032, -3.0675,  1.7408], requires_grad=True)\n",
            "Loss: 22.492626190185547\n",
            "tensor([ 0.3032, -3.0675,  1.7409], requires_grad=True)\n",
            "Loss: 22.492618560791016\n",
            "tensor([ 0.3032, -3.0675,  1.7409], requires_grad=True)\n",
            "Loss: 22.492610931396484\n",
            "tensor([ 0.3032, -3.0675,  1.7409], requires_grad=True)\n",
            "Loss: 22.49260139465332\n",
            "tensor([ 0.3032, -3.0675,  1.7410], requires_grad=True)\n",
            "Loss: 22.492591857910156\n",
            "tensor([ 0.3032, -3.0675,  1.7410], requires_grad=True)\n",
            "Loss: 22.492586135864258\n",
            "tensor([ 0.3032, -3.0675,  1.7410], requires_grad=True)\n",
            "Loss: 22.492576599121094\n",
            "tensor([ 0.3032, -3.0675,  1.7410], requires_grad=True)\n",
            "Loss: 22.49256706237793\n",
            "tensor([ 0.3032, -3.0675,  1.7411], requires_grad=True)\n",
            "Loss: 22.492557525634766\n",
            "tensor([ 0.3032, -3.0675,  1.7411], requires_grad=True)\n",
            "Loss: 22.4925479888916\n",
            "tensor([ 0.3032, -3.0675,  1.7411], requires_grad=True)\n",
            "Loss: 22.492542266845703\n",
            "tensor([ 0.3032, -3.0676,  1.7412], requires_grad=True)\n",
            "Loss: 22.49253273010254\n",
            "tensor([ 0.3032, -3.0676,  1.7412], requires_grad=True)\n",
            "Loss: 22.492525100708008\n",
            "tensor([ 0.3032, -3.0676,  1.7412], requires_grad=True)\n",
            "Loss: 22.49251365661621\n",
            "tensor([ 0.3032, -3.0676,  1.7412], requires_grad=True)\n",
            "Loss: 22.492507934570312\n",
            "tensor([ 0.3032, -3.0676,  1.7413], requires_grad=True)\n",
            "Loss: 22.49249839782715\n",
            "tensor([ 0.3032, -3.0676,  1.7413], requires_grad=True)\n",
            "Loss: 22.492488861083984\n",
            "tensor([ 0.3032, -3.0676,  1.7413], requires_grad=True)\n",
            "Loss: 22.492481231689453\n",
            "tensor([ 0.3032, -3.0676,  1.7414], requires_grad=True)\n",
            "Loss: 22.49247169494629\n",
            "tensor([ 0.3032, -3.0676,  1.7414], requires_grad=True)\n",
            "Loss: 22.492464065551758\n",
            "tensor([ 0.3032, -3.0676,  1.7414], requires_grad=True)\n",
            "Loss: 22.492454528808594\n",
            "tensor([ 0.3032, -3.0676,  1.7414], requires_grad=True)\n",
            "Loss: 22.492446899414062\n",
            "tensor([ 0.3032, -3.0676,  1.7415], requires_grad=True)\n",
            "Loss: 22.4924373626709\n",
            "tensor([ 0.3032, -3.0676,  1.7415], requires_grad=True)\n",
            "Loss: 22.492427825927734\n",
            "tensor([ 0.3032, -3.0676,  1.7415], requires_grad=True)\n",
            "Loss: 22.492422103881836\n",
            "tensor([ 0.3032, -3.0676,  1.7416], requires_grad=True)\n",
            "Loss: 22.49241065979004\n",
            "tensor([ 0.3032, -3.0677,  1.7416], requires_grad=True)\n",
            "Loss: 22.49240493774414\n",
            "tensor([ 0.3032, -3.0677,  1.7416], requires_grad=True)\n",
            "Loss: 22.492393493652344\n",
            "tensor([ 0.3032, -3.0677,  1.7416], requires_grad=True)\n",
            "Loss: 22.492387771606445\n",
            "tensor([ 0.3032, -3.0677,  1.7417], requires_grad=True)\n",
            "Loss: 22.49237823486328\n",
            "tensor([ 0.3032, -3.0677,  1.7417], requires_grad=True)\n",
            "Loss: 22.492368698120117\n",
            "tensor([ 0.3032, -3.0677,  1.7417], requires_grad=True)\n",
            "Loss: 22.492361068725586\n",
            "tensor([ 0.3032, -3.0677,  1.7418], requires_grad=True)\n",
            "Loss: 22.492351531982422\n",
            "tensor([ 0.3032, -3.0677,  1.7418], requires_grad=True)\n",
            "Loss: 22.492341995239258\n",
            "tensor([ 0.3032, -3.0677,  1.7418], requires_grad=True)\n",
            "Loss: 22.49233627319336\n",
            "tensor([ 0.3032, -3.0677,  1.7418], requires_grad=True)\n",
            "Loss: 22.492328643798828\n",
            "tensor([ 0.3032, -3.0677,  1.7419], requires_grad=True)\n",
            "Loss: 22.49231719970703\n",
            "tensor([ 0.3032, -3.0677,  1.7419], requires_grad=True)\n",
            "Loss: 22.4923095703125\n",
            "tensor([ 0.3032, -3.0677,  1.7419], requires_grad=True)\n",
            "Loss: 22.492300033569336\n",
            "tensor([ 0.3032, -3.0677,  1.7420], requires_grad=True)\n",
            "Loss: 22.492292404174805\n",
            "tensor([ 0.3032, -3.0678,  1.7420], requires_grad=True)\n",
            "Loss: 22.492284774780273\n",
            "tensor([ 0.3032, -3.0678,  1.7420], requires_grad=True)\n",
            "Loss: 22.49227523803711\n",
            "tensor([ 0.3032, -3.0678,  1.7420], requires_grad=True)\n",
            "Loss: 22.492265701293945\n",
            "tensor([ 0.3032, -3.0678,  1.7421], requires_grad=True)\n",
            "Loss: 22.492259979248047\n",
            "tensor([ 0.3032, -3.0678,  1.7421], requires_grad=True)\n",
            "Loss: 22.49224853515625\n",
            "tensor([ 0.3032, -3.0678,  1.7421], requires_grad=True)\n",
            "Loss: 22.49224090576172\n",
            "tensor([ 0.3032, -3.0678,  1.7422], requires_grad=True)\n",
            "Loss: 22.492231369018555\n",
            "tensor([ 0.3032, -3.0678,  1.7422], requires_grad=True)\n",
            "Loss: 22.492223739624023\n",
            "tensor([ 0.3032, -3.0678,  1.7422], requires_grad=True)\n",
            "Loss: 22.492216110229492\n",
            "tensor([ 0.3032, -3.0678,  1.7422], requires_grad=True)\n",
            "Loss: 22.492206573486328\n",
            "tensor([ 0.3032, -3.0678,  1.7423], requires_grad=True)\n",
            "Loss: 22.492198944091797\n",
            "tensor([ 0.3032, -3.0678,  1.7423], requires_grad=True)\n",
            "Loss: 22.492189407348633\n",
            "tensor([ 0.3032, -3.0678,  1.7423], requires_grad=True)\n",
            "Loss: 22.4921817779541\n",
            "tensor([ 0.3032, -3.0678,  1.7424], requires_grad=True)\n",
            "Loss: 22.492170333862305\n",
            "tensor([ 0.3032, -3.0678,  1.7424], requires_grad=True)\n",
            "Loss: 22.492162704467773\n",
            "tensor([ 0.3032, -3.0679,  1.7424], requires_grad=True)\n",
            "Loss: 22.492155075073242\n",
            "tensor([ 0.3032, -3.0679,  1.7424], requires_grad=True)\n",
            "Loss: 22.492145538330078\n",
            "tensor([ 0.3032, -3.0679,  1.7425], requires_grad=True)\n",
            "Loss: 22.492136001586914\n",
            "tensor([ 0.3032, -3.0679,  1.7425], requires_grad=True)\n",
            "Loss: 22.492130279541016\n",
            "tensor([ 0.3032, -3.0679,  1.7425], requires_grad=True)\n",
            "Loss: 22.49212074279785\n",
            "tensor([ 0.3032, -3.0679,  1.7425], requires_grad=True)\n",
            "Loss: 22.492109298706055\n",
            "tensor([ 0.3032, -3.0679,  1.7426], requires_grad=True)\n",
            "Loss: 22.492101669311523\n",
            "tensor([ 0.3032, -3.0679,  1.7426], requires_grad=True)\n",
            "Loss: 22.492095947265625\n",
            "tensor([ 0.3032, -3.0679,  1.7426], requires_grad=True)\n",
            "Loss: 22.49208641052246\n",
            "tensor([ 0.3032, -3.0679,  1.7427], requires_grad=True)\n",
            "Loss: 22.492076873779297\n",
            "tensor([ 0.3032, -3.0679,  1.7427], requires_grad=True)\n",
            "Loss: 22.492069244384766\n",
            "tensor([ 0.3032, -3.0679,  1.7427], requires_grad=True)\n",
            "Loss: 22.4920597076416\n",
            "tensor([ 0.3032, -3.0679,  1.7427], requires_grad=True)\n",
            "Loss: 22.49205207824707\n",
            "tensor([ 0.3032, -3.0679,  1.7428], requires_grad=True)\n",
            "Loss: 22.492042541503906\n",
            "tensor([ 0.3032, -3.0680,  1.7428], requires_grad=True)\n",
            "Loss: 22.492034912109375\n",
            "tensor([ 0.3032, -3.0680,  1.7428], requires_grad=True)\n",
            "Loss: 22.492027282714844\n",
            "tensor([ 0.3032, -3.0680,  1.7429], requires_grad=True)\n",
            "Loss: 22.492015838623047\n",
            "tensor([ 0.3032, -3.0680,  1.7429], requires_grad=True)\n",
            "Loss: 22.492008209228516\n",
            "tensor([ 0.3032, -3.0680,  1.7429], requires_grad=True)\n",
            "Loss: 22.492000579833984\n",
            "tensor([ 0.3032, -3.0680,  1.7429], requires_grad=True)\n",
            "Loss: 22.491992950439453\n",
            "tensor([ 0.3032, -3.0680,  1.7430], requires_grad=True)\n",
            "Loss: 22.491981506347656\n",
            "tensor([ 0.3032, -3.0680,  1.7430], requires_grad=True)\n",
            "Loss: 22.491973876953125\n",
            "tensor([ 0.3032, -3.0680,  1.7430], requires_grad=True)\n",
            "Loss: 22.49196434020996\n",
            "tensor([ 0.3032, -3.0680,  1.7431], requires_grad=True)\n",
            "Loss: 22.49195671081543\n",
            "tensor([ 0.3032, -3.0680,  1.7431], requires_grad=True)\n",
            "Loss: 22.491947174072266\n",
            "tensor([ 0.3032, -3.0680,  1.7431], requires_grad=True)\n",
            "Loss: 22.491943359375\n",
            "tensor([ 0.3032, -3.0680,  1.7431], requires_grad=True)\n",
            "Loss: 22.49193000793457\n",
            "tensor([ 0.3032, -3.0680,  1.7432], requires_grad=True)\n",
            "Loss: 22.491920471191406\n",
            "tensor([ 0.3032, -3.0680,  1.7432], requires_grad=True)\n",
            "Loss: 22.491912841796875\n",
            "tensor([ 0.3032, -3.0681,  1.7432], requires_grad=True)\n",
            "Loss: 22.491905212402344\n",
            "tensor([ 0.3032, -3.0681,  1.7433], requires_grad=True)\n",
            "Loss: 22.491897583007812\n",
            "tensor([ 0.3032, -3.0681,  1.7433], requires_grad=True)\n",
            "Loss: 22.49188804626465\n",
            "tensor([ 0.3032, -3.0681,  1.7433], requires_grad=True)\n",
            "Loss: 22.491878509521484\n",
            "tensor([ 0.3032, -3.0681,  1.7433], requires_grad=True)\n",
            "Loss: 22.491872787475586\n",
            "tensor([ 0.3032, -3.0681,  1.7434], requires_grad=True)\n",
            "Loss: 22.49186134338379\n",
            "tensor([ 0.3032, -3.0681,  1.7434], requires_grad=True)\n",
            "Loss: 22.491853713989258\n",
            "tensor([ 0.3032, -3.0681,  1.7434], requires_grad=True)\n",
            "Loss: 22.491844177246094\n",
            "tensor([ 0.3032, -3.0681,  1.7435], requires_grad=True)\n",
            "Loss: 22.491836547851562\n",
            "tensor([ 0.3032, -3.0681,  1.7435], requires_grad=True)\n",
            "Loss: 22.4918270111084\n",
            "tensor([ 0.3032, -3.0681,  1.7435], requires_grad=True)\n",
            "Loss: 22.4918212890625\n",
            "tensor([ 0.3032, -3.0681,  1.7435], requires_grad=True)\n",
            "Loss: 22.491811752319336\n",
            "tensor([ 0.3032, -3.0681,  1.7436], requires_grad=True)\n",
            "Loss: 22.491802215576172\n",
            "tensor([ 0.3032, -3.0681,  1.7436], requires_grad=True)\n",
            "Loss: 22.49179458618164\n",
            "tensor([ 0.3032, -3.0682,  1.7436], requires_grad=True)\n",
            "Loss: 22.491785049438477\n",
            "tensor([ 0.3032, -3.0682,  1.7437], requires_grad=True)\n",
            "Loss: 22.491777420043945\n",
            "tensor([ 0.3032, -3.0682,  1.7437], requires_grad=True)\n",
            "Loss: 22.49176597595215\n",
            "tensor([ 0.3032, -3.0682,  1.7437], requires_grad=True)\n",
            "Loss: 22.49176025390625\n",
            "tensor([ 0.3032, -3.0682,  1.7437], requires_grad=True)\n",
            "Loss: 22.491750717163086\n",
            "tensor([ 0.3032, -3.0682,  1.7438], requires_grad=True)\n",
            "Loss: 22.491741180419922\n",
            "tensor([ 0.3032, -3.0682,  1.7438], requires_grad=True)\n",
            "Loss: 22.49173355102539\n",
            "tensor([ 0.3032, -3.0682,  1.7438], requires_grad=True)\n",
            "Loss: 22.491724014282227\n",
            "tensor([ 0.3032, -3.0682,  1.7439], requires_grad=True)\n",
            "Loss: 22.491716384887695\n",
            "tensor([ 0.3032, -3.0682,  1.7439], requires_grad=True)\n",
            "Loss: 22.491708755493164\n",
            "tensor([ 0.3032, -3.0682,  1.7439], requires_grad=True)\n",
            "Loss: 22.49169921875\n",
            "tensor([ 0.3032, -3.0682,  1.7439], requires_grad=True)\n",
            "Loss: 22.49169158935547\n",
            "tensor([ 0.3032, -3.0682,  1.7440], requires_grad=True)\n",
            "Loss: 22.491682052612305\n",
            "tensor([ 0.3032, -3.0682,  1.7440], requires_grad=True)\n",
            "Loss: 22.491674423217773\n",
            "tensor([ 0.3032, -3.0682,  1.7440], requires_grad=True)\n",
            "Loss: 22.49166488647461\n",
            "tensor([ 0.3032, -3.0683,  1.7441], requires_grad=True)\n",
            "Loss: 22.491657257080078\n",
            "tensor([ 0.3032, -3.0683,  1.7441], requires_grad=True)\n",
            "Loss: 22.491647720336914\n",
            "tensor([ 0.3032, -3.0683,  1.7441], requires_grad=True)\n",
            "Loss: 22.491640090942383\n",
            "tensor([ 0.3032, -3.0683,  1.7441], requires_grad=True)\n",
            "Loss: 22.49163055419922\n",
            "tensor([ 0.3032, -3.0683,  1.7442], requires_grad=True)\n",
            "Loss: 22.491622924804688\n",
            "tensor([ 0.3032, -3.0683,  1.7442], requires_grad=True)\n",
            "Loss: 22.491613388061523\n",
            "tensor([ 0.3032, -3.0683,  1.7442], requires_grad=True)\n",
            "Loss: 22.49160385131836\n",
            "tensor([ 0.3032, -3.0683,  1.7443], requires_grad=True)\n",
            "Loss: 22.491596221923828\n",
            "tensor([ 0.3032, -3.0683,  1.7443], requires_grad=True)\n",
            "Loss: 22.491586685180664\n",
            "tensor([ 0.3032, -3.0683,  1.7443], requires_grad=True)\n",
            "Loss: 22.491580963134766\n",
            "tensor([ 0.3032, -3.0683,  1.7443], requires_grad=True)\n",
            "Loss: 22.49156951904297\n",
            "tensor([ 0.3032, -3.0683,  1.7444], requires_grad=True)\n",
            "Loss: 22.491559982299805\n",
            "tensor([ 0.3032, -3.0683,  1.7444], requires_grad=True)\n",
            "Loss: 22.491552352905273\n",
            "tensor([ 0.3032, -3.0683,  1.7444], requires_grad=True)\n",
            "Loss: 22.491544723510742\n",
            "tensor([ 0.3032, -3.0684,  1.7445], requires_grad=True)\n",
            "Loss: 22.491535186767578\n",
            "tensor([ 0.3032, -3.0684,  1.7445], requires_grad=True)\n",
            "Loss: 22.491527557373047\n",
            "tensor([ 0.3032, -3.0684,  1.7445], requires_grad=True)\n",
            "Loss: 22.491519927978516\n",
            "tensor([ 0.3032, -3.0684,  1.7445], requires_grad=True)\n",
            "Loss: 22.49151039123535\n",
            "tensor([ 0.3032, -3.0684,  1.7446], requires_grad=True)\n",
            "Loss: 22.491500854492188\n",
            "tensor([ 0.3032, -3.0684,  1.7446], requires_grad=True)\n",
            "Loss: 22.491493225097656\n",
            "tensor([ 0.3032, -3.0684,  1.7446], requires_grad=True)\n",
            "Loss: 22.491485595703125\n",
            "tensor([ 0.3032, -3.0684,  1.7447], requires_grad=True)\n",
            "Loss: 22.49147605895996\n",
            "tensor([ 0.3032, -3.0684,  1.7447], requires_grad=True)\n",
            "Loss: 22.491466522216797\n",
            "tensor([ 0.3032, -3.0684,  1.7447], requires_grad=True)\n",
            "Loss: 22.491458892822266\n",
            "tensor([ 0.3032, -3.0684,  1.7447], requires_grad=True)\n",
            "Loss: 22.491451263427734\n",
            "tensor([ 0.3032, -3.0684,  1.7448], requires_grad=True)\n",
            "Loss: 22.491439819335938\n",
            "tensor([ 0.3032, -3.0684,  1.7448], requires_grad=True)\n",
            "Loss: 22.491432189941406\n",
            "tensor([ 0.3032, -3.0684,  1.7448], requires_grad=True)\n",
            "Loss: 22.491424560546875\n",
            "tensor([ 0.3032, -3.0684,  1.7449], requires_grad=True)\n",
            "Loss: 22.49141502380371\n",
            "tensor([ 0.3032, -3.0685,  1.7449], requires_grad=True)\n",
            "Loss: 22.491405487060547\n",
            "tensor([ 0.3032, -3.0685,  1.7449], requires_grad=True)\n",
            "Loss: 22.491397857666016\n",
            "tensor([ 0.3032, -3.0685,  1.7449], requires_grad=True)\n",
            "Loss: 22.491390228271484\n",
            "tensor([ 0.3032, -3.0685,  1.7450], requires_grad=True)\n",
            "Loss: 22.49138069152832\n",
            "tensor([ 0.3032, -3.0685,  1.7450], requires_grad=True)\n",
            "Loss: 22.491371154785156\n",
            "tensor([ 0.3032, -3.0685,  1.7450], requires_grad=True)\n",
            "Loss: 22.491365432739258\n",
            "tensor([ 0.3032, -3.0685,  1.7451], requires_grad=True)\n",
            "Loss: 22.491355895996094\n",
            "tensor([ 0.3032, -3.0685,  1.7451], requires_grad=True)\n",
            "Loss: 22.49134635925293\n",
            "tensor([ 0.3032, -3.0685,  1.7451], requires_grad=True)\n",
            "Loss: 22.491336822509766\n",
            "tensor([ 0.3032, -3.0685,  1.7451], requires_grad=True)\n",
            "Loss: 22.4913272857666\n",
            "tensor([ 0.3032, -3.0685,  1.7452], requires_grad=True)\n",
            "Loss: 22.49131965637207\n",
            "tensor([ 0.3032, -3.0685,  1.7452], requires_grad=True)\n",
            "Loss: 22.491310119628906\n",
            "tensor([ 0.3032, -3.0685,  1.7452], requires_grad=True)\n",
            "Loss: 22.491304397583008\n",
            "tensor([ 0.3032, -3.0685,  1.7453], requires_grad=True)\n",
            "Loss: 22.491294860839844\n",
            "tensor([ 0.3032, -3.0686,  1.7453], requires_grad=True)\n",
            "Loss: 22.491287231445312\n",
            "tensor([ 0.3032, -3.0686,  1.7453], requires_grad=True)\n",
            "Loss: 22.49127769470215\n",
            "tensor([ 0.3032, -3.0686,  1.7453], requires_grad=True)\n",
            "Loss: 22.491270065307617\n",
            "tensor([ 0.3032, -3.0686,  1.7454], requires_grad=True)\n",
            "Loss: 22.491260528564453\n",
            "tensor([ 0.3032, -3.0686,  1.7454], requires_grad=True)\n",
            "Loss: 22.491252899169922\n",
            "tensor([ 0.3032, -3.0686,  1.7454], requires_grad=True)\n",
            "Loss: 22.491243362426758\n",
            "tensor([ 0.3032, -3.0686,  1.7455], requires_grad=True)\n",
            "Loss: 22.491235733032227\n",
            "tensor([ 0.3032, -3.0686,  1.7455], requires_grad=True)\n",
            "Loss: 22.491228103637695\n",
            "tensor([ 0.3032, -3.0686,  1.7455], requires_grad=True)\n",
            "Loss: 22.49121856689453\n",
            "tensor([ 0.3032, -3.0686,  1.7455], requires_grad=True)\n",
            "Loss: 22.491209030151367\n",
            "tensor([ 0.3032, -3.0686,  1.7456], requires_grad=True)\n",
            "Loss: 22.491199493408203\n",
            "tensor([ 0.3032, -3.0686,  1.7456], requires_grad=True)\n",
            "Loss: 22.49118995666504\n",
            "tensor([ 0.3032, -3.0686,  1.7456], requires_grad=True)\n",
            "Loss: 22.491186141967773\n",
            "tensor([ 0.3032, -3.0686,  1.7457], requires_grad=True)\n",
            "Loss: 22.491174697875977\n",
            "tensor([ 0.3032, -3.0686,  1.7457], requires_grad=True)\n",
            "Loss: 22.491167068481445\n",
            "tensor([ 0.3032, -3.0687,  1.7457], requires_grad=True)\n",
            "Loss: 22.49115753173828\n",
            "tensor([ 0.3032, -3.0687,  1.7457], requires_grad=True)\n",
            "Loss: 22.491147994995117\n",
            "tensor([ 0.3032, -3.0687,  1.7458], requires_grad=True)\n",
            "Loss: 22.49114227294922\n",
            "tensor([ 0.3032, -3.0687,  1.7458], requires_grad=True)\n",
            "Loss: 22.491132736206055\n",
            "tensor([ 0.3032, -3.0687,  1.7458], requires_grad=True)\n",
            "Loss: 22.491125106811523\n",
            "tensor([ 0.3032, -3.0687,  1.7459], requires_grad=True)\n",
            "Loss: 22.49111557006836\n",
            "tensor([ 0.3032, -3.0687,  1.7459], requires_grad=True)\n",
            "Loss: 22.491106033325195\n",
            "tensor([ 0.3032, -3.0687,  1.7459], requires_grad=True)\n",
            "Loss: 22.491098403930664\n",
            "tensor([ 0.3032, -3.0687,  1.7459], requires_grad=True)\n",
            "Loss: 22.4910888671875\n",
            "tensor([ 0.3032, -3.0687,  1.7460], requires_grad=True)\n",
            "Loss: 22.491079330444336\n",
            "tensor([ 0.3032, -3.0687,  1.7460], requires_grad=True)\n",
            "Loss: 22.491071701049805\n",
            "tensor([ 0.3032, -3.0687,  1.7460], requires_grad=True)\n",
            "Loss: 22.491064071655273\n",
            "tensor([ 0.3032, -3.0687,  1.7461], requires_grad=True)\n",
            "Loss: 22.49105453491211\n",
            "tensor([ 0.3032, -3.0687,  1.7461], requires_grad=True)\n",
            "Loss: 22.491044998168945\n",
            "tensor([ 0.3032, -3.0688,  1.7461], requires_grad=True)\n",
            "Loss: 22.491037368774414\n",
            "tensor([ 0.3032, -3.0688,  1.7461], requires_grad=True)\n",
            "Loss: 22.491031646728516\n",
            "tensor([ 0.3032, -3.0688,  1.7462], requires_grad=True)\n",
            "Loss: 22.49102020263672\n",
            "tensor([ 0.3032, -3.0688,  1.7462], requires_grad=True)\n",
            "Loss: 22.491010665893555\n",
            "tensor([ 0.3032, -3.0688,  1.7462], requires_grad=True)\n",
            "Loss: 22.49100112915039\n",
            "tensor([ 0.3032, -3.0688,  1.7463], requires_grad=True)\n",
            "Loss: 22.49099349975586\n",
            "tensor([ 0.3032, -3.0688,  1.7463], requires_grad=True)\n",
            "Loss: 22.490985870361328\n",
            "tensor([ 0.3032, -3.0688,  1.7463], requires_grad=True)\n",
            "Loss: 22.490978240966797\n",
            "tensor([ 0.3032, -3.0688,  1.7463], requires_grad=True)\n",
            "Loss: 22.490970611572266\n",
            "tensor([ 0.3032, -3.0688,  1.7464], requires_grad=True)\n",
            "Loss: 22.4909610748291\n",
            "tensor([ 0.3032, -3.0688,  1.7464], requires_grad=True)\n",
            "Loss: 22.490951538085938\n",
            "tensor([ 0.3032, -3.0688,  1.7464], requires_grad=True)\n",
            "Loss: 22.490942001342773\n",
            "tensor([ 0.3032, -3.0688,  1.7465], requires_grad=True)\n",
            "Loss: 22.490934371948242\n",
            "tensor([ 0.3032, -3.0688,  1.7465], requires_grad=True)\n",
            "Loss: 22.490924835205078\n",
            "tensor([ 0.3032, -3.0689,  1.7465], requires_grad=True)\n",
            "Loss: 22.490917205810547\n",
            "tensor([ 0.3032, -3.0689,  1.7465], requires_grad=True)\n",
            "Loss: 22.490909576416016\n",
            "tensor([ 0.3032, -3.0689,  1.7466], requires_grad=True)\n",
            "Loss: 22.49090003967285\n",
            "tensor([ 0.3032, -3.0689,  1.7466], requires_grad=True)\n",
            "Loss: 22.490890502929688\n",
            "tensor([ 0.3032, -3.0689,  1.7466], requires_grad=True)\n",
            "Loss: 22.490882873535156\n",
            "tensor([ 0.3032, -3.0689,  1.7467], requires_grad=True)\n",
            "Loss: 22.490875244140625\n",
            "tensor([ 0.3032, -3.0689,  1.7467], requires_grad=True)\n",
            "Loss: 22.49086570739746\n",
            "tensor([ 0.3032, -3.0689,  1.7467], requires_grad=True)\n",
            "Loss: 22.49085807800293\n",
            "tensor([ 0.3032, -3.0689,  1.7467], requires_grad=True)\n",
            "Loss: 22.490848541259766\n",
            "tensor([ 0.3032, -3.0689,  1.7468], requires_grad=True)\n",
            "Loss: 22.490840911865234\n",
            "tensor([ 0.3032, -3.0689,  1.7468], requires_grad=True)\n",
            "Loss: 22.49083137512207\n",
            "tensor([ 0.3032, -3.0689,  1.7468], requires_grad=True)\n",
            "Loss: 22.490821838378906\n",
            "tensor([ 0.3032, -3.0689,  1.7469], requires_grad=True)\n",
            "Loss: 22.490814208984375\n",
            "tensor([ 0.3032, -3.0689,  1.7469], requires_grad=True)\n",
            "Loss: 22.49080467224121\n",
            "tensor([ 0.3032, -3.0689,  1.7469], requires_grad=True)\n",
            "Loss: 22.49079704284668\n",
            "tensor([ 0.3032, -3.0690,  1.7469], requires_grad=True)\n",
            "Loss: 22.490787506103516\n",
            "tensor([ 0.3032, -3.0690,  1.7470], requires_grad=True)\n",
            "Loss: 22.49077796936035\n",
            "tensor([ 0.3032, -3.0690,  1.7470], requires_grad=True)\n",
            "Loss: 22.490772247314453\n",
            "tensor([ 0.3032, -3.0690,  1.7470], requires_grad=True)\n",
            "Loss: 22.490760803222656\n",
            "tensor([ 0.3032, -3.0690,  1.7471], requires_grad=True)\n",
            "Loss: 22.490755081176758\n",
            "tensor([ 0.3032, -3.0690,  1.7471], requires_grad=True)\n",
            "Loss: 22.49074363708496\n",
            "tensor([ 0.3032, -3.0690,  1.7471], requires_grad=True)\n",
            "Loss: 22.49073600769043\n",
            "tensor([ 0.3032, -3.0690,  1.7471], requires_grad=True)\n",
            "Loss: 22.4907283782959\n",
            "tensor([ 0.3032, -3.0690,  1.7472], requires_grad=True)\n",
            "Loss: 22.490720748901367\n",
            "tensor([ 0.3032, -3.0690,  1.7472], requires_grad=True)\n",
            "Loss: 22.490711212158203\n",
            "tensor([ 0.3032, -3.0690,  1.7472], requires_grad=True)\n",
            "Loss: 22.490703582763672\n",
            "tensor([ 0.3032, -3.0690,  1.7473], requires_grad=True)\n",
            "Loss: 22.490694046020508\n",
            "tensor([ 0.3032, -3.0690,  1.7473], requires_grad=True)\n",
            "Loss: 22.49068260192871\n",
            "tensor([ 0.3032, -3.0690,  1.7473], requires_grad=True)\n",
            "Loss: 22.490678787231445\n",
            "tensor([ 0.3032, -3.0691,  1.7473], requires_grad=True)\n",
            "Loss: 22.49066734313965\n",
            "tensor([ 0.3032, -3.0691,  1.7474], requires_grad=True)\n",
            "Loss: 22.490659713745117\n",
            "tensor([ 0.3032, -3.0691,  1.7474], requires_grad=True)\n",
            "Loss: 22.490650177001953\n",
            "tensor([ 0.3032, -3.0691,  1.7474], requires_grad=True)\n",
            "Loss: 22.490642547607422\n",
            "tensor([ 0.3032, -3.0691,  1.7475], requires_grad=True)\n",
            "Loss: 22.49063491821289\n",
            "tensor([ 0.3032, -3.0691,  1.7475], requires_grad=True)\n",
            "Loss: 22.490625381469727\n",
            "tensor([ 0.3032, -3.0691,  1.7475], requires_grad=True)\n",
            "Loss: 22.490615844726562\n",
            "tensor([ 0.3032, -3.0691,  1.7475], requires_grad=True)\n",
            "Loss: 22.49060821533203\n",
            "tensor([ 0.3032, -3.0691,  1.7476], requires_grad=True)\n",
            "Loss: 22.490598678588867\n",
            "tensor([ 0.3032, -3.0691,  1.7476], requires_grad=True)\n",
            "Loss: 22.490591049194336\n",
            "tensor([ 0.3032, -3.0691,  1.7476], requires_grad=True)\n",
            "Loss: 22.490581512451172\n",
            "tensor([ 0.3032, -3.0691,  1.7476], requires_grad=True)\n",
            "Loss: 22.490575790405273\n",
            "tensor([ 0.3032, -3.0691,  1.7477], requires_grad=True)\n",
            "Loss: 22.49056625366211\n",
            "tensor([ 0.3032, -3.0691,  1.7477], requires_grad=True)\n",
            "Loss: 22.490556716918945\n",
            "tensor([ 0.3032, -3.0691,  1.7477], requires_grad=True)\n",
            "Loss: 22.490549087524414\n",
            "tensor([ 0.3032, -3.0692,  1.7478], requires_grad=True)\n",
            "Loss: 22.490537643432617\n",
            "tensor([ 0.3032, -3.0692,  1.7478], requires_grad=True)\n",
            "Loss: 22.490530014038086\n",
            "tensor([ 0.3032, -3.0692,  1.7478], requires_grad=True)\n",
            "Loss: 22.490522384643555\n",
            "tensor([ 0.3032, -3.0692,  1.7478], requires_grad=True)\n",
            "Loss: 22.490514755249023\n",
            "tensor([ 0.3032, -3.0692,  1.7479], requires_grad=True)\n",
            "Loss: 22.490503311157227\n",
            "tensor([ 0.3032, -3.0692,  1.7479], requires_grad=True)\n",
            "Loss: 22.490495681762695\n",
            "tensor([ 0.3032, -3.0692,  1.7479], requires_grad=True)\n",
            "Loss: 22.49048614501953\n",
            "tensor([ 0.3032, -3.0692,  1.7480], requires_grad=True)\n",
            "Loss: 22.490480422973633\n",
            "tensor([ 0.3032, -3.0692,  1.7480], requires_grad=True)\n",
            "Loss: 22.490468978881836\n",
            "tensor([ 0.3032, -3.0692,  1.7480], requires_grad=True)\n",
            "Loss: 22.490461349487305\n",
            "tensor([ 0.3032, -3.0692,  1.7480], requires_grad=True)\n",
            "Loss: 22.490453720092773\n",
            "tensor([ 0.3032, -3.0692,  1.7481], requires_grad=True)\n",
            "Loss: 22.490446090698242\n",
            "tensor([ 0.3032, -3.0692,  1.7481], requires_grad=True)\n",
            "Loss: 22.490436553955078\n",
            "tensor([ 0.3032, -3.0692,  1.7481], requires_grad=True)\n",
            "Loss: 22.490427017211914\n",
            "tensor([ 0.3032, -3.0693,  1.7482], requires_grad=True)\n",
            "Loss: 22.490419387817383\n",
            "tensor([ 0.3032, -3.0693,  1.7482], requires_grad=True)\n",
            "Loss: 22.49040985107422\n",
            "tensor([ 0.3032, -3.0693,  1.7482], requires_grad=True)\n",
            "Loss: 22.490402221679688\n",
            "tensor([ 0.3032, -3.0693,  1.7482], requires_grad=True)\n",
            "Loss: 22.490392684936523\n",
            "tensor([ 0.3032, -3.0693,  1.7483], requires_grad=True)\n",
            "Loss: 22.490385055541992\n",
            "tensor([ 0.3032, -3.0693,  1.7483], requires_grad=True)\n",
            "Loss: 22.490375518798828\n",
            "tensor([ 0.3032, -3.0693,  1.7483], requires_grad=True)\n",
            "Loss: 22.490365982055664\n",
            "tensor([ 0.3032, -3.0693,  1.7484], requires_grad=True)\n",
            "Loss: 22.490358352661133\n",
            "tensor([ 0.3032, -3.0693,  1.7484], requires_grad=True)\n",
            "Loss: 22.4903507232666\n",
            "tensor([ 0.3032, -3.0693,  1.7484], requires_grad=True)\n",
            "Loss: 22.490341186523438\n",
            "tensor([ 0.3033, -3.0693,  1.7484], requires_grad=True)\n",
            "Loss: 22.490333557128906\n",
            "tensor([ 0.3033, -3.0693,  1.7485], requires_grad=True)\n",
            "Loss: 22.490325927734375\n",
            "tensor([ 0.3033, -3.0693,  1.7485], requires_grad=True)\n",
            "Loss: 22.490314483642578\n",
            "tensor([ 0.3033, -3.0693,  1.7485], requires_grad=True)\n",
            "Loss: 22.490306854248047\n",
            "tensor([ 0.3033, -3.0693,  1.7486], requires_grad=True)\n",
            "Loss: 22.490297317504883\n",
            "tensor([ 0.3033, -3.0694,  1.7486], requires_grad=True)\n",
            "Loss: 22.49028968811035\n",
            "tensor([ 0.3033, -3.0694,  1.7486], requires_grad=True)\n",
            "Loss: 22.490280151367188\n",
            "tensor([ 0.3033, -3.0694,  1.7486], requires_grad=True)\n",
            "Loss: 22.490272521972656\n",
            "tensor([ 0.3033, -3.0694,  1.7487], requires_grad=True)\n",
            "Loss: 22.490264892578125\n",
            "tensor([ 0.3033, -3.0694,  1.7487], requires_grad=True)\n",
            "Loss: 22.49025535583496\n",
            "tensor([ 0.3033, -3.0694,  1.7487], requires_grad=True)\n",
            "Loss: 22.49024772644043\n",
            "tensor([ 0.3033, -3.0694,  1.7488], requires_grad=True)\n",
            "Loss: 22.490238189697266\n",
            "tensor([ 0.3033, -3.0694,  1.7488], requires_grad=True)\n",
            "Loss: 22.4902286529541\n",
            "tensor([ 0.3033, -3.0694,  1.7488], requires_grad=True)\n",
            "Loss: 22.49022102355957\n",
            "tensor([ 0.3033, -3.0694,  1.7488], requires_grad=True)\n",
            "Loss: 22.490211486816406\n",
            "tensor([ 0.3033, -3.0694,  1.7489], requires_grad=True)\n",
            "Loss: 22.490203857421875\n",
            "tensor([ 0.3033, -3.0694,  1.7489], requires_grad=True)\n",
            "Loss: 22.490196228027344\n",
            "tensor([ 0.3033, -3.0694,  1.7489], requires_grad=True)\n",
            "Loss: 22.49018669128418\n",
            "tensor([ 0.3033, -3.0694,  1.7490], requires_grad=True)\n",
            "Loss: 22.49017906188965\n",
            "tensor([ 0.3033, -3.0695,  1.7490], requires_grad=True)\n",
            "Loss: 22.49016761779785\n",
            "tensor([ 0.3033, -3.0695,  1.7490], requires_grad=True)\n",
            "Loss: 22.49015998840332\n",
            "tensor([ 0.3033, -3.0695,  1.7490], requires_grad=True)\n",
            "Loss: 22.490154266357422\n",
            "tensor([ 0.3033, -3.0695,  1.7491], requires_grad=True)\n",
            "Loss: 22.490144729614258\n",
            "tensor([ 0.3033, -3.0695,  1.7491], requires_grad=True)\n",
            "Loss: 22.490135192871094\n",
            "tensor([ 0.3033, -3.0695,  1.7491], requires_grad=True)\n",
            "Loss: 22.490127563476562\n",
            "tensor([ 0.3033, -3.0695,  1.7492], requires_grad=True)\n",
            "Loss: 22.4901180267334\n",
            "tensor([ 0.3033, -3.0695,  1.7492], requires_grad=True)\n",
            "Loss: 22.490110397338867\n",
            "tensor([ 0.3033, -3.0695,  1.7492], requires_grad=True)\n",
            "Loss: 22.490100860595703\n",
            "tensor([ 0.3033, -3.0695,  1.7492], requires_grad=True)\n",
            "Loss: 22.49009132385254\n",
            "tensor([ 0.3033, -3.0695,  1.7493], requires_grad=True)\n",
            "Loss: 22.490083694458008\n",
            "tensor([ 0.3033, -3.0695,  1.7493], requires_grad=True)\n",
            "Loss: 22.490074157714844\n",
            "tensor([ 0.3033, -3.0695,  1.7493], requires_grad=True)\n",
            "Loss: 22.490066528320312\n",
            "tensor([ 0.3033, -3.0695,  1.7494], requires_grad=True)\n",
            "Loss: 22.49005699157715\n",
            "tensor([ 0.3033, -3.0695,  1.7494], requires_grad=True)\n",
            "Loss: 22.490049362182617\n",
            "tensor([ 0.3033, -3.0696,  1.7494], requires_grad=True)\n",
            "Loss: 22.490041732788086\n",
            "tensor([ 0.3033, -3.0696,  1.7494], requires_grad=True)\n",
            "Loss: 22.490032196044922\n",
            "tensor([ 0.3033, -3.0696,  1.7495], requires_grad=True)\n",
            "Loss: 22.49002456665039\n",
            "tensor([ 0.3033, -3.0696,  1.7495], requires_grad=True)\n",
            "Loss: 22.49001693725586\n",
            "tensor([ 0.3033, -3.0696,  1.7495], requires_grad=True)\n",
            "Loss: 22.490007400512695\n",
            "tensor([ 0.3033, -3.0696,  1.7496], requires_grad=True)\n",
            "Loss: 22.489999771118164\n",
            "tensor([ 0.3033, -3.0696,  1.7496], requires_grad=True)\n",
            "Loss: 22.489990234375\n",
            "tensor([ 0.3033, -3.0696,  1.7496], requires_grad=True)\n",
            "Loss: 22.489980697631836\n",
            "tensor([ 0.3033, -3.0696,  1.7496], requires_grad=True)\n",
            "Loss: 22.489971160888672\n",
            "tensor([ 0.3033, -3.0696,  1.7497], requires_grad=True)\n",
            "Loss: 22.48996353149414\n",
            "tensor([ 0.3033, -3.0696,  1.7497], requires_grad=True)\n",
            "Loss: 22.48995590209961\n",
            "tensor([ 0.3033, -3.0696,  1.7497], requires_grad=True)\n",
            "Loss: 22.489946365356445\n",
            "tensor([ 0.3033, -3.0696,  1.7498], requires_grad=True)\n",
            "Loss: 22.489938735961914\n",
            "tensor([ 0.3033, -3.0696,  1.7498], requires_grad=True)\n",
            "Loss: 22.489931106567383\n",
            "tensor([ 0.3033, -3.0697,  1.7498], requires_grad=True)\n",
            "Loss: 22.489919662475586\n",
            "tensor([ 0.3033, -3.0697,  1.7498], requires_grad=True)\n",
            "Loss: 22.489912033081055\n",
            "tensor([ 0.3033, -3.0697,  1.7499], requires_grad=True)\n",
            "Loss: 22.48990249633789\n",
            "tensor([ 0.3033, -3.0697,  1.7499], requires_grad=True)\n",
            "Loss: 22.48989486694336\n",
            "tensor([ 0.3033, -3.0697,  1.7499], requires_grad=True)\n",
            "Loss: 22.489885330200195\n",
            "tensor([ 0.3033, -3.0697,  1.7500], requires_grad=True)\n",
            "Loss: 22.489879608154297\n",
            "tensor([ 0.3033, -3.0697,  1.7500], requires_grad=True)\n",
            "Loss: 22.489870071411133\n",
            "tensor([ 0.3033, -3.0697,  1.7500], requires_grad=True)\n",
            "Loss: 22.48986053466797\n",
            "tensor([ 0.3033, -3.0697,  1.7500], requires_grad=True)\n",
            "Loss: 22.489850997924805\n",
            "tensor([ 0.3033, -3.0697,  1.7501], requires_grad=True)\n",
            "Loss: 22.48984146118164\n",
            "tensor([ 0.3033, -3.0697,  1.7501], requires_grad=True)\n",
            "Loss: 22.48983383178711\n",
            "tensor([ 0.3033, -3.0697,  1.7501], requires_grad=True)\n",
            "Loss: 22.489826202392578\n",
            "tensor([ 0.3033, -3.0697,  1.7502], requires_grad=True)\n",
            "Loss: 22.489816665649414\n",
            "tensor([ 0.3033, -3.0697,  1.7502], requires_grad=True)\n",
            "Loss: 22.489809036254883\n",
            "tensor([ 0.3033, -3.0697,  1.7502], requires_grad=True)\n",
            "Loss: 22.48980140686035\n",
            "tensor([ 0.3033, -3.0698,  1.7502], requires_grad=True)\n",
            "Loss: 22.489791870117188\n",
            "tensor([ 0.3033, -3.0698,  1.7503], requires_grad=True)\n",
            "Loss: 22.489784240722656\n",
            "tensor([ 0.3033, -3.0698,  1.7503], requires_grad=True)\n",
            "Loss: 22.489774703979492\n",
            "tensor([ 0.3033, -3.0698,  1.7503], requires_grad=True)\n",
            "Loss: 22.489765167236328\n",
            "tensor([ 0.3033, -3.0698,  1.7504], requires_grad=True)\n",
            "Loss: 22.489757537841797\n",
            "tensor([ 0.3033, -3.0698,  1.7504], requires_grad=True)\n",
            "Loss: 22.489748001098633\n",
            "tensor([ 0.3033, -3.0698,  1.7504], requires_grad=True)\n",
            "Loss: 22.4897403717041\n",
            "tensor([ 0.3033, -3.0698,  1.7504], requires_grad=True)\n",
            "Loss: 22.489730834960938\n",
            "tensor([ 0.3033, -3.0698,  1.7505], requires_grad=True)\n",
            "Loss: 22.489723205566406\n",
            "tensor([ 0.3033, -3.0698,  1.7505], requires_grad=True)\n",
            "Loss: 22.489713668823242\n",
            "tensor([ 0.3033, -3.0698,  1.7505], requires_grad=True)\n",
            "Loss: 22.489704132080078\n",
            "tensor([ 0.3033, -3.0698,  1.7506], requires_grad=True)\n",
            "Loss: 22.48969841003418\n",
            "tensor([ 0.3033, -3.0698,  1.7506], requires_grad=True)\n",
            "Loss: 22.489688873291016\n",
            "tensor([ 0.3033, -3.0698,  1.7506], requires_grad=True)\n",
            "Loss: 22.48967933654785\n",
            "tensor([ 0.3033, -3.0699,  1.7506], requires_grad=True)\n",
            "Loss: 22.48967170715332\n",
            "tensor([ 0.3033, -3.0699,  1.7507], requires_grad=True)\n",
            "Loss: 22.489660263061523\n",
            "tensor([ 0.3033, -3.0699,  1.7507], requires_grad=True)\n",
            "Loss: 22.489654541015625\n",
            "tensor([ 0.3033, -3.0699,  1.7507], requires_grad=True)\n",
            "Loss: 22.48964500427246\n",
            "tensor([ 0.3033, -3.0699,  1.7508], requires_grad=True)\n",
            "Loss: 22.48963737487793\n",
            "tensor([ 0.3033, -3.0699,  1.7508], requires_grad=True)\n",
            "Loss: 22.489627838134766\n",
            "tensor([ 0.3033, -3.0699,  1.7508], requires_grad=True)\n",
            "Loss: 22.489620208740234\n",
            "tensor([ 0.3033, -3.0699,  1.7508], requires_grad=True)\n",
            "Loss: 22.48961067199707\n",
            "tensor([ 0.3033, -3.0699,  1.7509], requires_grad=True)\n",
            "Loss: 22.48960304260254\n",
            "tensor([ 0.3033, -3.0699,  1.7509], requires_grad=True)\n",
            "Loss: 22.489595413208008\n",
            "tensor([ 0.3033, -3.0699,  1.7509], requires_grad=True)\n",
            "Loss: 22.48958396911621\n",
            "tensor([ 0.3033, -3.0699,  1.7510], requires_grad=True)\n",
            "Loss: 22.489578247070312\n",
            "tensor([ 0.3033, -3.0699,  1.7510], requires_grad=True)\n",
            "Loss: 22.48956871032715\n",
            "tensor([ 0.3033, -3.0699,  1.7510], requires_grad=True)\n",
            "Loss: 22.489561080932617\n",
            "tensor([ 0.3033, -3.0699,  1.7510], requires_grad=True)\n",
            "Loss: 22.48954963684082\n",
            "tensor([ 0.3033, -3.0700,  1.7511], requires_grad=True)\n",
            "Loss: 22.489543914794922\n",
            "tensor([ 0.3033, -3.0700,  1.7511], requires_grad=True)\n",
            "Loss: 22.489534378051758\n",
            "tensor([ 0.3033, -3.0700,  1.7511], requires_grad=True)\n",
            "Loss: 22.489524841308594\n",
            "tensor([ 0.3033, -3.0700,  1.7512], requires_grad=True)\n",
            "Loss: 22.489517211914062\n",
            "tensor([ 0.3033, -3.0700,  1.7512], requires_grad=True)\n",
            "Loss: 22.4895076751709\n",
            "tensor([ 0.3033, -3.0700,  1.7512], requires_grad=True)\n",
            "Loss: 22.489498138427734\n",
            "tensor([ 0.3033, -3.0700,  1.7512], requires_grad=True)\n",
            "Loss: 22.489492416381836\n",
            "tensor([ 0.3033, -3.0700,  1.7513], requires_grad=True)\n",
            "Loss: 22.489484786987305\n",
            "tensor([ 0.3033, -3.0700,  1.7513], requires_grad=True)\n",
            "Loss: 22.489473342895508\n",
            "tensor([ 0.3033, -3.0700,  1.7513], requires_grad=True)\n",
            "Loss: 22.489465713500977\n",
            "tensor([ 0.3033, -3.0700,  1.7514], requires_grad=True)\n",
            "Loss: 22.489456176757812\n",
            "tensor([ 0.3033, -3.0700,  1.7514], requires_grad=True)\n",
            "Loss: 22.48944854736328\n",
            "tensor([ 0.3033, -3.0700,  1.7514], requires_grad=True)\n",
            "Loss: 22.489439010620117\n",
            "tensor([ 0.3033, -3.0700,  1.7514], requires_grad=True)\n",
            "Loss: 22.489431381225586\n",
            "tensor([ 0.3033, -3.0701,  1.7515], requires_grad=True)\n",
            "Loss: 22.489421844482422\n",
            "tensor([ 0.3033, -3.0701,  1.7515], requires_grad=True)\n",
            "Loss: 22.48941421508789\n",
            "tensor([ 0.3033, -3.0701,  1.7515], requires_grad=True)\n",
            "Loss: 22.48940658569336\n",
            "tensor([ 0.3033, -3.0701,  1.7516], requires_grad=True)\n",
            "Loss: 22.489395141601562\n",
            "tensor([ 0.3033, -3.0701,  1.7516], requires_grad=True)\n",
            "Loss: 22.48938751220703\n",
            "tensor([ 0.3033, -3.0701,  1.7516], requires_grad=True)\n",
            "Loss: 22.4893798828125\n",
            "tensor([ 0.3033, -3.0701,  1.7516], requires_grad=True)\n",
            "Loss: 22.489370346069336\n",
            "tensor([ 0.3033, -3.0701,  1.7517], requires_grad=True)\n",
            "Loss: 22.489362716674805\n",
            "tensor([ 0.3033, -3.0701,  1.7517], requires_grad=True)\n",
            "Loss: 22.48935317993164\n",
            "tensor([ 0.3033, -3.0701,  1.7517], requires_grad=True)\n",
            "Loss: 22.489343643188477\n",
            "tensor([ 0.3033, -3.0701,  1.7518], requires_grad=True)\n",
            "Loss: 22.489337921142578\n",
            "tensor([ 0.3033, -3.0701,  1.7518], requires_grad=True)\n",
            "Loss: 22.489328384399414\n",
            "tensor([ 0.3033, -3.0701,  1.7518], requires_grad=True)\n",
            "Loss: 22.48931884765625\n",
            "tensor([ 0.3033, -3.0701,  1.7518], requires_grad=True)\n",
            "Loss: 22.489309310913086\n",
            "tensor([ 0.3033, -3.0701,  1.7519], requires_grad=True)\n",
            "Loss: 22.489303588867188\n",
            "tensor([ 0.3033, -3.0702,  1.7519], requires_grad=True)\n",
            "Loss: 22.48929214477539\n",
            "tensor([ 0.3033, -3.0702,  1.7519], requires_grad=True)\n",
            "Loss: 22.48928451538086\n",
            "tensor([ 0.3033, -3.0702,  1.7520], requires_grad=True)\n",
            "Loss: 22.489276885986328\n",
            "tensor([ 0.3033, -3.0702,  1.7520], requires_grad=True)\n",
            "Loss: 22.48926544189453\n",
            "tensor([ 0.3033, -3.0702,  1.7520], requires_grad=True)\n",
            "Loss: 22.489259719848633\n",
            "tensor([ 0.3033, -3.0702,  1.7520], requires_grad=True)\n",
            "Loss: 22.4892520904541\n",
            "tensor([ 0.3033, -3.0702,  1.7521], requires_grad=True)\n",
            "Loss: 22.489242553710938\n",
            "tensor([ 0.3033, -3.0702,  1.7521], requires_grad=True)\n",
            "Loss: 22.489233016967773\n",
            "tensor([ 0.3033, -3.0702,  1.7521], requires_grad=True)\n",
            "Loss: 22.489225387573242\n",
            "tensor([ 0.3033, -3.0702,  1.7522], requires_grad=True)\n",
            "Loss: 22.489215850830078\n",
            "tensor([ 0.3033, -3.0702,  1.7522], requires_grad=True)\n",
            "Loss: 22.489208221435547\n",
            "tensor([ 0.3033, -3.0702,  1.7522], requires_grad=True)\n",
            "Loss: 22.489198684692383\n",
            "tensor([ 0.3033, -3.0702,  1.7522], requires_grad=True)\n",
            "Loss: 22.48919105529785\n",
            "tensor([ 0.3033, -3.0702,  1.7523], requires_grad=True)\n",
            "Loss: 22.489181518554688\n",
            "tensor([ 0.3033, -3.0703,  1.7523], requires_grad=True)\n",
            "Loss: 22.489171981811523\n",
            "tensor([ 0.3033, -3.0703,  1.7523], requires_grad=True)\n",
            "Loss: 22.489166259765625\n",
            "tensor([ 0.3033, -3.0703,  1.7524], requires_grad=True)\n",
            "Loss: 22.48915672302246\n",
            "tensor([ 0.3033, -3.0703,  1.7524], requires_grad=True)\n",
            "Loss: 22.48914909362793\n",
            "tensor([ 0.3033, -3.0703,  1.7524], requires_grad=True)\n",
            "Loss: 22.4891357421875\n",
            "tensor([ 0.3033, -3.0703,  1.7524], requires_grad=True)\n",
            "Loss: 22.48912811279297\n",
            "tensor([ 0.3033, -3.0703,  1.7525], requires_grad=True)\n",
            "Loss: 22.48912239074707\n",
            "tensor([ 0.3033, -3.0703,  1.7525], requires_grad=True)\n",
            "Loss: 22.489112854003906\n",
            "tensor([ 0.3033, -3.0703,  1.7525], requires_grad=True)\n",
            "Loss: 22.489105224609375\n",
            "tensor([ 0.3033, -3.0703,  1.7526], requires_grad=True)\n",
            "Loss: 22.48909568786621\n",
            "tensor([ 0.3033, -3.0703,  1.7526], requires_grad=True)\n",
            "Loss: 22.48908805847168\n",
            "tensor([ 0.3033, -3.0703,  1.7526], requires_grad=True)\n",
            "Loss: 22.489078521728516\n",
            "tensor([ 0.3033, -3.0703,  1.7526], requires_grad=True)\n",
            "Loss: 22.48906898498535\n",
            "tensor([ 0.3033, -3.0703,  1.7527], requires_grad=True)\n",
            "Loss: 22.48906135559082\n",
            "tensor([ 0.3033, -3.0704,  1.7527], requires_grad=True)\n",
            "Loss: 22.48905372619629\n",
            "tensor([ 0.3033, -3.0704,  1.7527], requires_grad=True)\n",
            "Loss: 22.489042282104492\n",
            "tensor([ 0.3033, -3.0704,  1.7527], requires_grad=True)\n",
            "Loss: 22.48903465270996\n",
            "tensor([ 0.3033, -3.0704,  1.7528], requires_grad=True)\n",
            "Loss: 22.489028930664062\n",
            "tensor([ 0.3033, -3.0704,  1.7528], requires_grad=True)\n",
            "Loss: 22.4890193939209\n",
            "tensor([ 0.3033, -3.0704,  1.7528], requires_grad=True)\n",
            "Loss: 22.489011764526367\n",
            "tensor([ 0.3033, -3.0704,  1.7529], requires_grad=True)\n",
            "Loss: 22.489002227783203\n",
            "tensor([ 0.3033, -3.0704,  1.7529], requires_grad=True)\n",
            "Loss: 22.48899269104004\n",
            "tensor([ 0.3033, -3.0704,  1.7529], requires_grad=True)\n",
            "Loss: 22.488983154296875\n",
            "tensor([ 0.3033, -3.0704,  1.7529], requires_grad=True)\n",
            "Loss: 22.488975524902344\n",
            "tensor([ 0.3033, -3.0704,  1.7530], requires_grad=True)\n",
            "Loss: 22.48896598815918\n",
            "tensor([ 0.3033, -3.0704,  1.7530], requires_grad=True)\n",
            "Loss: 22.48896026611328\n",
            "tensor([ 0.3033, -3.0704,  1.7530], requires_grad=True)\n",
            "Loss: 22.488948822021484\n",
            "tensor([ 0.3033, -3.0704,  1.7531], requires_grad=True)\n",
            "Loss: 22.488941192626953\n",
            "tensor([ 0.3033, -3.0704,  1.7531], requires_grad=True)\n",
            "Loss: 22.48893165588379\n",
            "tensor([ 0.3033, -3.0705,  1.7531], requires_grad=True)\n",
            "Loss: 22.48892593383789\n",
            "tensor([ 0.3033, -3.0705,  1.7531], requires_grad=True)\n",
            "Loss: 22.488916397094727\n",
            "tensor([ 0.3033, -3.0705,  1.7532], requires_grad=True)\n",
            "Loss: 22.488908767700195\n",
            "tensor([ 0.3033, -3.0705,  1.7532], requires_grad=True)\n",
            "Loss: 22.48889923095703\n",
            "tensor([ 0.3033, -3.0705,  1.7532], requires_grad=True)\n",
            "Loss: 22.488889694213867\n",
            "tensor([ 0.3033, -3.0705,  1.7533], requires_grad=True)\n",
            "Loss: 22.488882064819336\n",
            "tensor([ 0.3033, -3.0705,  1.7533], requires_grad=True)\n",
            "Loss: 22.488872528076172\n",
            "tensor([ 0.3033, -3.0705,  1.7533], requires_grad=True)\n",
            "Loss: 22.488862991333008\n",
            "tensor([ 0.3033, -3.0705,  1.7533], requires_grad=True)\n",
            "Loss: 22.488855361938477\n",
            "tensor([ 0.3033, -3.0705,  1.7534], requires_grad=True)\n",
            "Loss: 22.488847732543945\n",
            "tensor([ 0.3033, -3.0705,  1.7534], requires_grad=True)\n",
            "Loss: 22.48883819580078\n",
            "tensor([ 0.3033, -3.0705,  1.7534], requires_grad=True)\n",
            "Loss: 22.48883056640625\n",
            "tensor([ 0.3033, -3.0705,  1.7535], requires_grad=True)\n",
            "Loss: 22.488821029663086\n",
            "tensor([ 0.3033, -3.0705,  1.7535], requires_grad=True)\n",
            "Loss: 22.488811492919922\n",
            "tensor([ 0.3033, -3.0706,  1.7535], requires_grad=True)\n",
            "Loss: 22.488801956176758\n",
            "tensor([ 0.3033, -3.0706,  1.7535], requires_grad=True)\n",
            "Loss: 22.48879623413086\n",
            "tensor([ 0.3033, -3.0706,  1.7536], requires_grad=True)\n",
            "Loss: 22.488786697387695\n",
            "tensor([ 0.3033, -3.0706,  1.7536], requires_grad=True)\n",
            "Loss: 22.48877716064453\n",
            "tensor([ 0.3033, -3.0706,  1.7536], requires_grad=True)\n",
            "Loss: 22.48876953125\n",
            "tensor([ 0.3033, -3.0706,  1.7537], requires_grad=True)\n",
            "Loss: 22.488759994506836\n",
            "tensor([ 0.3033, -3.0706,  1.7537], requires_grad=True)\n",
            "Loss: 22.488752365112305\n",
            "tensor([ 0.3033, -3.0706,  1.7537], requires_grad=True)\n",
            "Loss: 22.48874282836914\n",
            "tensor([ 0.3033, -3.0706,  1.7537], requires_grad=True)\n",
            "Loss: 22.48873519897461\n",
            "tensor([ 0.3033, -3.0706,  1.7538], requires_grad=True)\n",
            "Loss: 22.488727569580078\n",
            "tensor([ 0.3033, -3.0706,  1.7538], requires_grad=True)\n",
            "Loss: 22.488718032836914\n",
            "tensor([ 0.3033, -3.0706,  1.7538], requires_grad=True)\n",
            "Loss: 22.488710403442383\n",
            "tensor([ 0.3033, -3.0706,  1.7539], requires_grad=True)\n",
            "Loss: 22.48870086669922\n",
            "tensor([ 0.3033, -3.0706,  1.7539], requires_grad=True)\n",
            "Loss: 22.488693237304688\n",
            "tensor([ 0.3033, -3.0706,  1.7539], requires_grad=True)\n",
            "Loss: 22.48868179321289\n",
            "tensor([ 0.3033, -3.0707,  1.7539], requires_grad=True)\n",
            "Loss: 22.488676071166992\n",
            "tensor([ 0.3033, -3.0707,  1.7540], requires_grad=True)\n",
            "Loss: 22.488666534423828\n",
            "tensor([ 0.3033, -3.0707,  1.7540], requires_grad=True)\n",
            "Loss: 22.488658905029297\n",
            "tensor([ 0.3033, -3.0707,  1.7540], requires_grad=True)\n",
            "Loss: 22.488649368286133\n",
            "tensor([ 0.3033, -3.0707,  1.7541], requires_grad=True)\n",
            "Loss: 22.4886417388916\n",
            "tensor([ 0.3033, -3.0707,  1.7541], requires_grad=True)\n",
            "Loss: 22.488632202148438\n",
            "tensor([ 0.3033, -3.0707,  1.7541], requires_grad=True)\n",
            "Loss: 22.488622665405273\n",
            "tensor([ 0.3033, -3.0707,  1.7541], requires_grad=True)\n",
            "Loss: 22.488615036010742\n",
            "tensor([ 0.3033, -3.0707,  1.7542], requires_grad=True)\n",
            "Loss: 22.488605499267578\n",
            "tensor([ 0.3033, -3.0707,  1.7542], requires_grad=True)\n",
            "Loss: 22.48859977722168\n",
            "tensor([ 0.3033, -3.0707,  1.7542], requires_grad=True)\n",
            "Loss: 22.488588333129883\n",
            "tensor([ 0.3033, -3.0707,  1.7543], requires_grad=True)\n",
            "Loss: 22.48857879638672\n",
            "tensor([ 0.3033, -3.0707,  1.7543], requires_grad=True)\n",
            "Loss: 22.48857307434082\n",
            "tensor([ 0.3033, -3.0707,  1.7543], requires_grad=True)\n",
            "Loss: 22.488563537597656\n",
            "tensor([ 0.3033, -3.0708,  1.7543], requires_grad=True)\n",
            "Loss: 22.488554000854492\n",
            "tensor([ 0.3033, -3.0708,  1.7544], requires_grad=True)\n",
            "Loss: 22.48854637145996\n",
            "tensor([ 0.3033, -3.0708,  1.7544], requires_grad=True)\n",
            "Loss: 22.488536834716797\n",
            "tensor([ 0.3033, -3.0708,  1.7544], requires_grad=True)\n",
            "Loss: 22.488529205322266\n",
            "tensor([ 0.3033, -3.0708,  1.7545], requires_grad=True)\n",
            "Loss: 22.4885196685791\n",
            "tensor([ 0.3033, -3.0708,  1.7545], requires_grad=True)\n",
            "Loss: 22.488510131835938\n",
            "tensor([ 0.3033, -3.0708,  1.7545], requires_grad=True)\n",
            "Loss: 22.48850440979004\n",
            "tensor([ 0.3033, -3.0708,  1.7545], requires_grad=True)\n",
            "Loss: 22.488494873046875\n",
            "tensor([ 0.3033, -3.0708,  1.7546], requires_grad=True)\n",
            "Loss: 22.48848533630371\n",
            "tensor([ 0.3033, -3.0708,  1.7546], requires_grad=True)\n",
            "Loss: 22.48847770690918\n",
            "tensor([ 0.3033, -3.0708,  1.7546], requires_grad=True)\n",
            "Loss: 22.48847007751465\n",
            "tensor([ 0.3033, -3.0708,  1.7547], requires_grad=True)\n",
            "Loss: 22.488460540771484\n",
            "tensor([ 0.3033, -3.0708,  1.7547], requires_grad=True)\n",
            "Loss: 22.48845100402832\n",
            "tensor([ 0.3033, -3.0708,  1.7547], requires_grad=True)\n",
            "Loss: 22.48844337463379\n",
            "tensor([ 0.3033, -3.0708,  1.7547], requires_grad=True)\n",
            "Loss: 22.488435745239258\n",
            "tensor([ 0.3033, -3.0709,  1.7548], requires_grad=True)\n",
            "Loss: 22.488426208496094\n",
            "tensor([ 0.3033, -3.0709,  1.7548], requires_grad=True)\n",
            "Loss: 22.488414764404297\n",
            "tensor([ 0.3033, -3.0709,  1.7548], requires_grad=True)\n",
            "Loss: 22.4884090423584\n",
            "tensor([ 0.3033, -3.0709,  1.7549], requires_grad=True)\n",
            "Loss: 22.488399505615234\n",
            "tensor([ 0.3033, -3.0709,  1.7549], requires_grad=True)\n",
            "Loss: 22.488391876220703\n",
            "tensor([ 0.3033, -3.0709,  1.7549], requires_grad=True)\n",
            "Loss: 22.488384246826172\n",
            "tensor([ 0.3033, -3.0709,  1.7549], requires_grad=True)\n",
            "Loss: 22.488374710083008\n",
            "tensor([ 0.3033, -3.0709,  1.7550], requires_grad=True)\n",
            "Loss: 22.488365173339844\n",
            "tensor([ 0.3033, -3.0709,  1.7550], requires_grad=True)\n",
            "Loss: 22.48835563659668\n",
            "tensor([ 0.3033, -3.0709,  1.7550], requires_grad=True)\n",
            "Loss: 22.48834800720215\n",
            "tensor([ 0.3033, -3.0709,  1.7551], requires_grad=True)\n",
            "Loss: 22.488340377807617\n",
            "tensor([ 0.3033, -3.0709,  1.7551], requires_grad=True)\n",
            "Loss: 22.488332748413086\n",
            "tensor([ 0.3033, -3.0709,  1.7551], requires_grad=True)\n",
            "Loss: 22.488323211669922\n",
            "tensor([ 0.3033, -3.0709,  1.7551], requires_grad=True)\n",
            "Loss: 22.48831558227539\n",
            "tensor([ 0.3033, -3.0710,  1.7552], requires_grad=True)\n",
            "Loss: 22.488304138183594\n",
            "tensor([ 0.3033, -3.0710,  1.7552], requires_grad=True)\n",
            "Loss: 22.488296508789062\n",
            "tensor([ 0.3033, -3.0710,  1.7552], requires_grad=True)\n",
            "Loss: 22.4882869720459\n",
            "tensor([ 0.3033, -3.0710,  1.7553], requires_grad=True)\n",
            "Loss: 22.48828125\n",
            "tensor([ 0.3033, -3.0710,  1.7553], requires_grad=True)\n",
            "Loss: 22.488269805908203\n",
            "tensor([ 0.3033, -3.0710,  1.7553], requires_grad=True)\n",
            "Loss: 22.488264083862305\n",
            "tensor([ 0.3033, -3.0710,  1.7553], requires_grad=True)\n",
            "Loss: 22.48825454711914\n",
            "tensor([ 0.3033, -3.0710,  1.7554], requires_grad=True)\n",
            "Loss: 22.488245010375977\n",
            "tensor([ 0.3033, -3.0710,  1.7554], requires_grad=True)\n",
            "Loss: 22.488235473632812\n",
            "tensor([ 0.3033, -3.0710,  1.7554], requires_grad=True)\n",
            "Loss: 22.48822784423828\n",
            "tensor([ 0.3033, -3.0710,  1.7555], requires_grad=True)\n",
            "Loss: 22.48822021484375\n",
            "tensor([ 0.3033, -3.0710,  1.7555], requires_grad=True)\n",
            "Loss: 22.488210678100586\n",
            "tensor([ 0.3033, -3.0710,  1.7555], requires_grad=True)\n",
            "Loss: 22.488203048706055\n",
            "tensor([ 0.3033, -3.0710,  1.7555], requires_grad=True)\n",
            "Loss: 22.48819351196289\n",
            "tensor([ 0.3033, -3.0710,  1.7556], requires_grad=True)\n",
            "Loss: 22.48818588256836\n",
            "tensor([ 0.3033, -3.0711,  1.7556], requires_grad=True)\n",
            "Loss: 22.488176345825195\n",
            "tensor([ 0.3033, -3.0711,  1.7556], requires_grad=True)\n",
            "Loss: 22.48816680908203\n",
            "tensor([ 0.3033, -3.0711,  1.7557], requires_grad=True)\n",
            "Loss: 22.4881591796875\n",
            "tensor([ 0.3033, -3.0711,  1.7557], requires_grad=True)\n",
            "Loss: 22.48815155029297\n",
            "tensor([ 0.3033, -3.0711,  1.7557], requires_grad=True)\n",
            "Loss: 22.488140106201172\n",
            "tensor([ 0.3033, -3.0711,  1.7557], requires_grad=True)\n",
            "Loss: 22.488134384155273\n",
            "tensor([ 0.3033, -3.0711,  1.7558], requires_grad=True)\n",
            "Loss: 22.48812484741211\n",
            "tensor([ 0.3033, -3.0711,  1.7558], requires_grad=True)\n",
            "Loss: 22.488117218017578\n",
            "tensor([ 0.3033, -3.0711,  1.7558], requires_grad=True)\n",
            "Loss: 22.488107681274414\n",
            "tensor([ 0.3033, -3.0711,  1.7559], requires_grad=True)\n",
            "Loss: 22.488100051879883\n",
            "tensor([ 0.3033, -3.0711,  1.7559], requires_grad=True)\n",
            "Loss: 22.48809242248535\n",
            "tensor([ 0.3033, -3.0711,  1.7559], requires_grad=True)\n",
            "Loss: 22.488080978393555\n",
            "tensor([ 0.3033, -3.0711,  1.7559], requires_grad=True)\n",
            "Loss: 22.488075256347656\n",
            "tensor([ 0.3033, -3.0711,  1.7560], requires_grad=True)\n",
            "Loss: 22.48806381225586\n",
            "tensor([ 0.3033, -3.0712,  1.7560], requires_grad=True)\n",
            "Loss: 22.488056182861328\n",
            "tensor([ 0.3033, -3.0712,  1.7560], requires_grad=True)\n",
            "Loss: 22.488046646118164\n",
            "tensor([ 0.3033, -3.0712,  1.7561], requires_grad=True)\n",
            "Loss: 22.488039016723633\n",
            "tensor([ 0.3033, -3.0712,  1.7561], requires_grad=True)\n",
            "Loss: 22.48802947998047\n",
            "tensor([ 0.3033, -3.0712,  1.7561], requires_grad=True)\n",
            "Loss: 22.488021850585938\n",
            "tensor([ 0.3033, -3.0712,  1.7561], requires_grad=True)\n",
            "Loss: 22.488014221191406\n",
            "tensor([ 0.3033, -3.0712,  1.7562], requires_grad=True)\n",
            "Loss: 22.488004684448242\n",
            "tensor([ 0.3033, -3.0712,  1.7562], requires_grad=True)\n",
            "Loss: 22.48799705505371\n",
            "tensor([ 0.3033, -3.0712,  1.7562], requires_grad=True)\n",
            "Loss: 22.487987518310547\n",
            "tensor([ 0.3033, -3.0712,  1.7563], requires_grad=True)\n",
            "Loss: 22.487977981567383\n",
            "tensor([ 0.3033, -3.0712,  1.7563], requires_grad=True)\n",
            "Loss: 22.48797035217285\n",
            "tensor([ 0.3033, -3.0712,  1.7563], requires_grad=True)\n",
            "Loss: 22.48796272277832\n",
            "tensor([ 0.3033, -3.0712,  1.7563], requires_grad=True)\n",
            "Loss: 22.487953186035156\n",
            "tensor([ 0.3033, -3.0712,  1.7564], requires_grad=True)\n",
            "Loss: 22.487945556640625\n",
            "tensor([ 0.3033, -3.0712,  1.7564], requires_grad=True)\n",
            "Loss: 22.48793601989746\n",
            "tensor([ 0.3033, -3.0713,  1.7564], requires_grad=True)\n",
            "Loss: 22.48792839050293\n",
            "tensor([ 0.3033, -3.0713,  1.7565], requires_grad=True)\n",
            "Loss: 22.4879207611084\n",
            "tensor([ 0.3033, -3.0713,  1.7565], requires_grad=True)\n",
            "Loss: 22.487911224365234\n",
            "tensor([ 0.3033, -3.0713,  1.7565], requires_grad=True)\n",
            "Loss: 22.48790168762207\n",
            "tensor([ 0.3033, -3.0713,  1.7565], requires_grad=True)\n",
            "Loss: 22.48789405822754\n",
            "tensor([ 0.3033, -3.0713,  1.7566], requires_grad=True)\n",
            "Loss: 22.487884521484375\n",
            "tensor([ 0.3033, -3.0713,  1.7566], requires_grad=True)\n",
            "Loss: 22.48787498474121\n",
            "tensor([ 0.3033, -3.0713,  1.7566], requires_grad=True)\n",
            "Loss: 22.48786735534668\n",
            "tensor([ 0.3033, -3.0713,  1.7567], requires_grad=True)\n",
            "Loss: 22.487857818603516\n",
            "tensor([ 0.3033, -3.0713,  1.7567], requires_grad=True)\n",
            "Loss: 22.487852096557617\n",
            "tensor([ 0.3033, -3.0713,  1.7567], requires_grad=True)\n",
            "Loss: 22.487842559814453\n",
            "tensor([ 0.3033, -3.0713,  1.7567], requires_grad=True)\n",
            "Loss: 22.48783302307129\n",
            "tensor([ 0.3033, -3.0713,  1.7568], requires_grad=True)\n",
            "Loss: 22.487825393676758\n",
            "tensor([ 0.3033, -3.0713,  1.7568], requires_grad=True)\n",
            "Loss: 22.487815856933594\n",
            "tensor([ 0.3033, -3.0714,  1.7568], requires_grad=True)\n",
            "Loss: 22.487808227539062\n",
            "tensor([ 0.3033, -3.0714,  1.7569], requires_grad=True)\n",
            "Loss: 22.4877986907959\n",
            "tensor([ 0.3033, -3.0714,  1.7569], requires_grad=True)\n",
            "Loss: 22.487791061401367\n",
            "tensor([ 0.3033, -3.0714,  1.7569], requires_grad=True)\n",
            "Loss: 22.487781524658203\n",
            "tensor([ 0.3033, -3.0714,  1.7569], requires_grad=True)\n",
            "Loss: 22.48777198791504\n",
            "tensor([ 0.3033, -3.0714,  1.7570], requires_grad=True)\n",
            "Loss: 22.48776626586914\n",
            "tensor([ 0.3033, -3.0714,  1.7570], requires_grad=True)\n",
            "Loss: 22.487754821777344\n",
            "tensor([ 0.3033, -3.0714,  1.7570], requires_grad=True)\n",
            "Loss: 22.487747192382812\n",
            "tensor([ 0.3033, -3.0714,  1.7571], requires_grad=True)\n",
            "Loss: 22.48773765563965\n",
            "tensor([ 0.3033, -3.0714,  1.7571], requires_grad=True)\n",
            "Loss: 22.487730026245117\n",
            "tensor([ 0.3033, -3.0714,  1.7571], requires_grad=True)\n",
            "Loss: 22.487722396850586\n",
            "tensor([ 0.3033, -3.0714,  1.7571], requires_grad=True)\n",
            "Loss: 22.487712860107422\n",
            "tensor([ 0.3033, -3.0714,  1.7572], requires_grad=True)\n",
            "Loss: 22.487703323364258\n",
            "tensor([ 0.3033, -3.0714,  1.7572], requires_grad=True)\n",
            "Loss: 22.487695693969727\n",
            "tensor([ 0.3033, -3.0714,  1.7572], requires_grad=True)\n",
            "Loss: 22.487688064575195\n",
            "tensor([ 0.3033, -3.0715,  1.7573], requires_grad=True)\n",
            "Loss: 22.487680435180664\n",
            "tensor([ 0.3033, -3.0715,  1.7573], requires_grad=True)\n",
            "Loss: 22.487668991088867\n",
            "tensor([ 0.3033, -3.0715,  1.7573], requires_grad=True)\n",
            "Loss: 22.48766326904297\n",
            "tensor([ 0.3033, -3.0715,  1.7573], requires_grad=True)\n",
            "Loss: 22.487651824951172\n",
            "tensor([ 0.3033, -3.0715,  1.7574], requires_grad=True)\n",
            "Loss: 22.48764419555664\n",
            "tensor([ 0.3033, -3.0715,  1.7574], requires_grad=True)\n",
            "Loss: 22.48763656616211\n",
            "tensor([ 0.3033, -3.0715,  1.7574], requires_grad=True)\n",
            "Loss: 22.487627029418945\n",
            "tensor([ 0.3033, -3.0715,  1.7575], requires_grad=True)\n",
            "Loss: 22.48761749267578\n",
            "tensor([ 0.3033, -3.0715,  1.7575], requires_grad=True)\n",
            "Loss: 22.48760986328125\n",
            "tensor([ 0.3033, -3.0715,  1.7575], requires_grad=True)\n",
            "Loss: 22.48760223388672\n",
            "tensor([ 0.3033, -3.0715,  1.7575], requires_grad=True)\n",
            "Loss: 22.487592697143555\n",
            "tensor([ 0.3033, -3.0715,  1.7576], requires_grad=True)\n",
            "Loss: 22.487585067749023\n",
            "tensor([ 0.3033, -3.0715,  1.7576], requires_grad=True)\n",
            "Loss: 22.487573623657227\n",
            "tensor([ 0.3033, -3.0715,  1.7576], requires_grad=True)\n",
            "Loss: 22.487567901611328\n",
            "tensor([ 0.3033, -3.0716,  1.7577], requires_grad=True)\n",
            "Loss: 22.487560272216797\n",
            "tensor([ 0.3033, -3.0716,  1.7577], requires_grad=True)\n",
            "Loss: 22.487550735473633\n",
            "tensor([ 0.3033, -3.0716,  1.7577], requires_grad=True)\n",
            "Loss: 22.48754119873047\n",
            "tensor([ 0.3033, -3.0716,  1.7577], requires_grad=True)\n",
            "Loss: 22.487531661987305\n",
            "tensor([ 0.3033, -3.0716,  1.7578], requires_grad=True)\n",
            "Loss: 22.487524032592773\n",
            "tensor([ 0.3033, -3.0716,  1.7578], requires_grad=True)\n",
            "Loss: 22.487516403198242\n",
            "tensor([ 0.3033, -3.0716,  1.7578], requires_grad=True)\n",
            "Loss: 22.487506866455078\n",
            "tensor([ 0.3033, -3.0716,  1.7578], requires_grad=True)\n",
            "Loss: 22.487499237060547\n",
            "tensor([ 0.3033, -3.0716,  1.7579], requires_grad=True)\n",
            "Loss: 22.487489700317383\n",
            "tensor([ 0.3033, -3.0716,  1.7579], requires_grad=True)\n",
            "Loss: 22.48748016357422\n",
            "tensor([ 0.3033, -3.0716,  1.7579], requires_grad=True)\n",
            "Loss: 22.48747444152832\n",
            "tensor([ 0.3033, -3.0716,  1.7580], requires_grad=True)\n",
            "Loss: 22.487462997436523\n",
            "tensor([ 0.3033, -3.0716,  1.7580], requires_grad=True)\n",
            "Loss: 22.487455368041992\n",
            "tensor([ 0.3033, -3.0716,  1.7580], requires_grad=True)\n",
            "Loss: 22.487445831298828\n",
            "tensor([ 0.3033, -3.0717,  1.7580], requires_grad=True)\n",
            "Loss: 22.487438201904297\n",
            "tensor([ 0.3033, -3.0717,  1.7581], requires_grad=True)\n",
            "Loss: 22.487428665161133\n",
            "tensor([ 0.3033, -3.0717,  1.7581], requires_grad=True)\n",
            "Loss: 22.4874210357666\n",
            "tensor([ 0.3033, -3.0717,  1.7581], requires_grad=True)\n",
            "Loss: 22.487411499023438\n",
            "tensor([ 0.3033, -3.0717,  1.7582], requires_grad=True)\n",
            "Loss: 22.487403869628906\n",
            "tensor([ 0.3033, -3.0717,  1.7582], requires_grad=True)\n",
            "Loss: 22.487396240234375\n",
            "tensor([ 0.3033, -3.0717,  1.7582], requires_grad=True)\n",
            "Loss: 22.48738670349121\n",
            "tensor([ 0.3033, -3.0717,  1.7582], requires_grad=True)\n",
            "Loss: 22.48737907409668\n",
            "tensor([ 0.3033, -3.0717,  1.7583], requires_grad=True)\n",
            "Loss: 22.487369537353516\n",
            "tensor([ 0.3033, -3.0717,  1.7583], requires_grad=True)\n",
            "Loss: 22.487361907958984\n",
            "tensor([ 0.3033, -3.0717,  1.7583], requires_grad=True)\n",
            "Loss: 22.48735237121582\n",
            "tensor([ 0.3033, -3.0717,  1.7584], requires_grad=True)\n",
            "Loss: 22.48734474182129\n",
            "tensor([ 0.3033, -3.0717,  1.7584], requires_grad=True)\n",
            "Loss: 22.487335205078125\n",
            "tensor([ 0.3033, -3.0717,  1.7584], requires_grad=True)\n",
            "Loss: 22.48732566833496\n",
            "tensor([ 0.3033, -3.0717,  1.7584], requires_grad=True)\n",
            "Loss: 22.487316131591797\n",
            "tensor([ 0.3033, -3.0718,  1.7585], requires_grad=True)\n",
            "Loss: 22.487308502197266\n",
            "tensor([ 0.3033, -3.0718,  1.7585], requires_grad=True)\n",
            "Loss: 22.487300872802734\n",
            "tensor([ 0.3033, -3.0718,  1.7585], requires_grad=True)\n",
            "Loss: 22.48729133605957\n",
            "tensor([ 0.3033, -3.0718,  1.7586], requires_grad=True)\n",
            "Loss: 22.487285614013672\n",
            "tensor([ 0.3033, -3.0718,  1.7586], requires_grad=True)\n",
            "Loss: 22.487274169921875\n",
            "tensor([ 0.3033, -3.0718,  1.7586], requires_grad=True)\n",
            "Loss: 22.487266540527344\n",
            "tensor([ 0.3033, -3.0718,  1.7586], requires_grad=True)\n",
            "Loss: 22.48725700378418\n",
            "tensor([ 0.3033, -3.0718,  1.7587], requires_grad=True)\n",
            "Loss: 22.48724937438965\n",
            "tensor([ 0.3033, -3.0718,  1.7587], requires_grad=True)\n",
            "Loss: 22.487239837646484\n",
            "tensor([ 0.3033, -3.0718,  1.7587], requires_grad=True)\n",
            "Loss: 22.487232208251953\n",
            "tensor([ 0.3033, -3.0718,  1.7588], requires_grad=True)\n",
            "Loss: 22.48722267150879\n",
            "tensor([ 0.3033, -3.0718,  1.7588], requires_grad=True)\n",
            "Loss: 22.487215042114258\n",
            "tensor([ 0.3033, -3.0718,  1.7588], requires_grad=True)\n",
            "Loss: 22.487205505371094\n",
            "tensor([ 0.3033, -3.0718,  1.7588], requires_grad=True)\n",
            "Loss: 22.487197875976562\n",
            "tensor([ 0.3033, -3.0719,  1.7589], requires_grad=True)\n",
            "Loss: 22.4871883392334\n",
            "tensor([ 0.3033, -3.0719,  1.7589], requires_grad=True)\n",
            "Loss: 22.487180709838867\n",
            "tensor([ 0.3033, -3.0719,  1.7589], requires_grad=True)\n",
            "Loss: 22.487173080444336\n",
            "tensor([ 0.3033, -3.0719,  1.7590], requires_grad=True)\n",
            "Loss: 22.487163543701172\n",
            "tensor([ 0.3033, -3.0719,  1.7590], requires_grad=True)\n",
            "Loss: 22.48715591430664\n",
            "tensor([ 0.3033, -3.0719,  1.7590], requires_grad=True)\n",
            "Loss: 22.487146377563477\n",
            "tensor([ 0.3033, -3.0719,  1.7590], requires_grad=True)\n",
            "Loss: 22.487136840820312\n",
            "tensor([ 0.3033, -3.0719,  1.7591], requires_grad=True)\n",
            "Loss: 22.48712921142578\n",
            "tensor([ 0.3033, -3.0719,  1.7591], requires_grad=True)\n",
            "Loss: 22.487119674682617\n",
            "tensor([ 0.3033, -3.0719,  1.7591], requires_grad=True)\n",
            "Loss: 22.487112045288086\n",
            "tensor([ 0.3033, -3.0719,  1.7592], requires_grad=True)\n",
            "Loss: 22.487104415893555\n",
            "tensor([ 0.3033, -3.0719,  1.7592], requires_grad=True)\n",
            "Loss: 22.48709487915039\n",
            "tensor([ 0.3033, -3.0719,  1.7592], requires_grad=True)\n",
            "Loss: 22.487085342407227\n",
            "tensor([ 0.3033, -3.0719,  1.7592], requires_grad=True)\n",
            "Loss: 22.487075805664062\n",
            "tensor([ 0.3033, -3.0719,  1.7593], requires_grad=True)\n",
            "Loss: 22.48706817626953\n",
            "tensor([ 0.3033, -3.0720,  1.7593], requires_grad=True)\n",
            "Loss: 22.487060546875\n",
            "tensor([ 0.3033, -3.0720,  1.7593], requires_grad=True)\n",
            "Loss: 22.487051010131836\n",
            "tensor([ 0.3033, -3.0720,  1.7594], requires_grad=True)\n",
            "Loss: 22.487043380737305\n",
            "tensor([ 0.3033, -3.0720,  1.7594], requires_grad=True)\n",
            "Loss: 22.48703384399414\n",
            "tensor([ 0.3033, -3.0720,  1.7594], requires_grad=True)\n",
            "Loss: 22.487024307250977\n",
            "tensor([ 0.3033, -3.0720,  1.7594], requires_grad=True)\n",
            "Loss: 22.487016677856445\n",
            "tensor([ 0.3033, -3.0720,  1.7595], requires_grad=True)\n",
            "Loss: 22.487009048461914\n",
            "tensor([ 0.3033, -3.0720,  1.7595], requires_grad=True)\n",
            "Loss: 22.486997604370117\n",
            "tensor([ 0.3033, -3.0720,  1.7595], requires_grad=True)\n",
            "Loss: 22.48699378967285\n",
            "tensor([ 0.3033, -3.0720,  1.7596], requires_grad=True)\n",
            "Loss: 22.486984252929688\n",
            "tensor([ 0.3033, -3.0720,  1.7596], requires_grad=True)\n",
            "Loss: 22.486974716186523\n",
            "tensor([ 0.3033, -3.0720,  1.7596], requires_grad=True)\n",
            "Loss: 22.48696517944336\n",
            "tensor([ 0.3033, -3.0720,  1.7596], requires_grad=True)\n",
            "Loss: 22.486955642700195\n",
            "tensor([ 0.3033, -3.0720,  1.7597], requires_grad=True)\n",
            "Loss: 22.486948013305664\n",
            "tensor([ 0.3033, -3.0721,  1.7597], requires_grad=True)\n",
            "Loss: 22.4869384765625\n",
            "tensor([ 0.3033, -3.0721,  1.7597], requires_grad=True)\n",
            "Loss: 22.48693084716797\n",
            "tensor([ 0.3033, -3.0721,  1.7598], requires_grad=True)\n",
            "Loss: 22.486923217773438\n",
            "tensor([ 0.3033, -3.0721,  1.7598], requires_grad=True)\n",
            "Loss: 22.486913681030273\n",
            "tensor([ 0.3033, -3.0721,  1.7598], requires_grad=True)\n",
            "Loss: 22.486906051635742\n",
            "tensor([ 0.3033, -3.0721,  1.7598], requires_grad=True)\n",
            "Loss: 22.486896514892578\n",
            "tensor([ 0.3033, -3.0721,  1.7599], requires_grad=True)\n",
            "Loss: 22.486888885498047\n",
            "tensor([ 0.3033, -3.0721,  1.7599], requires_grad=True)\n",
            "Loss: 22.486879348754883\n",
            "tensor([ 0.3033, -3.0721,  1.7599], requires_grad=True)\n",
            "Loss: 22.48687171936035\n",
            "tensor([ 0.3033, -3.0721,  1.7600], requires_grad=True)\n",
            "Loss: 22.486862182617188\n",
            "tensor([ 0.3033, -3.0721,  1.7600], requires_grad=True)\n",
            "Loss: 22.486854553222656\n",
            "tensor([ 0.3033, -3.0721,  1.7600], requires_grad=True)\n",
            "Loss: 22.486845016479492\n",
            "tensor([ 0.3033, -3.0721,  1.7600], requires_grad=True)\n",
            "Loss: 22.48683738708496\n",
            "tensor([ 0.3033, -3.0721,  1.7601], requires_grad=True)\n",
            "Loss: 22.48682975769043\n",
            "tensor([ 0.3033, -3.0721,  1.7601], requires_grad=True)\n",
            "Loss: 22.486820220947266\n",
            "tensor([ 0.3033, -3.0722,  1.7601], requires_grad=True)\n",
            "Loss: 22.4868106842041\n",
            "tensor([ 0.3033, -3.0722,  1.7602], requires_grad=True)\n",
            "Loss: 22.486801147460938\n",
            "tensor([ 0.3033, -3.0722,  1.7602], requires_grad=True)\n",
            "Loss: 22.486793518066406\n",
            "tensor([ 0.3033, -3.0722,  1.7602], requires_grad=True)\n",
            "Loss: 22.486783981323242\n",
            "tensor([ 0.3033, -3.0722,  1.7602], requires_grad=True)\n",
            "Loss: 22.48677635192871\n",
            "tensor([ 0.3033, -3.0722,  1.7603], requires_grad=True)\n",
            "Loss: 22.486766815185547\n",
            "tensor([ 0.3033, -3.0722,  1.7603], requires_grad=True)\n",
            "Loss: 22.48676109313965\n",
            "tensor([ 0.3033, -3.0722,  1.7603], requires_grad=True)\n",
            "Loss: 22.486751556396484\n",
            "tensor([ 0.3033, -3.0722,  1.7604], requires_grad=True)\n",
            "Loss: 22.48674201965332\n",
            "tensor([ 0.3033, -3.0722,  1.7604], requires_grad=True)\n",
            "Loss: 22.48673439025879\n",
            "tensor([ 0.3034, -3.0722,  1.7604], requires_grad=True)\n",
            "Loss: 22.486724853515625\n",
            "tensor([ 0.3034, -3.0722,  1.7604], requires_grad=True)\n",
            "Loss: 22.486717224121094\n",
            "tensor([ 0.3034, -3.0722,  1.7605], requires_grad=True)\n",
            "Loss: 22.486709594726562\n",
            "tensor([ 0.3034, -3.0722,  1.7605], requires_grad=True)\n",
            "Loss: 22.4867000579834\n",
            "tensor([ 0.3034, -3.0723,  1.7605], requires_grad=True)\n",
            "Loss: 22.486692428588867\n",
            "tensor([ 0.3034, -3.0723,  1.7606], requires_grad=True)\n",
            "Loss: 22.486682891845703\n",
            "tensor([ 0.3034, -3.0723,  1.7606], requires_grad=True)\n",
            "Loss: 22.48667335510254\n",
            "tensor([ 0.3034, -3.0723,  1.7606], requires_grad=True)\n",
            "Loss: 22.486663818359375\n",
            "tensor([ 0.3034, -3.0723,  1.7606], requires_grad=True)\n",
            "Loss: 22.486656188964844\n",
            "tensor([ 0.3034, -3.0723,  1.7607], requires_grad=True)\n",
            "Loss: 22.486650466918945\n",
            "tensor([ 0.3034, -3.0723,  1.7607], requires_grad=True)\n",
            "Loss: 22.486637115478516\n",
            "tensor([ 0.3034, -3.0723,  1.7607], requires_grad=True)\n",
            "Loss: 22.486631393432617\n",
            "tensor([ 0.3034, -3.0723,  1.7608], requires_grad=True)\n",
            "Loss: 22.486621856689453\n",
            "tensor([ 0.3034, -3.0723,  1.7608], requires_grad=True)\n",
            "Loss: 22.48661231994629\n",
            "tensor([ 0.3034, -3.0723,  1.7608], requires_grad=True)\n",
            "Loss: 22.486604690551758\n",
            "tensor([ 0.3034, -3.0723,  1.7608], requires_grad=True)\n",
            "Loss: 22.486597061157227\n",
            "tensor([ 0.3034, -3.0723,  1.7609], requires_grad=True)\n",
            "Loss: 22.486587524414062\n",
            "tensor([ 0.3034, -3.0723,  1.7609], requires_grad=True)\n",
            "Loss: 22.48657989501953\n",
            "tensor([ 0.3034, -3.0723,  1.7609], requires_grad=True)\n",
            "Loss: 22.486572265625\n",
            "tensor([ 0.3034, -3.0724,  1.7610], requires_grad=True)\n",
            "Loss: 22.486562728881836\n",
            "tensor([ 0.3034, -3.0724,  1.7610], requires_grad=True)\n",
            "Loss: 22.486555099487305\n",
            "tensor([ 0.3034, -3.0724,  1.7610], requires_grad=True)\n",
            "Loss: 22.486543655395508\n",
            "tensor([ 0.3034, -3.0724,  1.7610], requires_grad=True)\n",
            "Loss: 22.486536026000977\n",
            "tensor([ 0.3034, -3.0724,  1.7611], requires_grad=True)\n",
            "Loss: 22.486528396606445\n",
            "tensor([ 0.3034, -3.0724,  1.7611], requires_grad=True)\n",
            "Loss: 22.48651885986328\n",
            "tensor([ 0.3034, -3.0724,  1.7611], requires_grad=True)\n",
            "Loss: 22.48651123046875\n",
            "tensor([ 0.3034, -3.0724,  1.7612], requires_grad=True)\n",
            "Loss: 22.486501693725586\n",
            "tensor([ 0.3034, -3.0724,  1.7612], requires_grad=True)\n",
            "Loss: 22.486494064331055\n",
            "tensor([ 0.3034, -3.0724,  1.7612], requires_grad=True)\n",
            "Loss: 22.48648452758789\n",
            "tensor([ 0.3034, -3.0724,  1.7612], requires_grad=True)\n",
            "Loss: 22.486474990844727\n",
            "tensor([ 0.3034, -3.0724,  1.7613], requires_grad=True)\n",
            "Loss: 22.486469268798828\n",
            "tensor([ 0.3034, -3.0724,  1.7613], requires_grad=True)\n",
            "Loss: 22.486459732055664\n",
            "tensor([ 0.3034, -3.0724,  1.7613], requires_grad=True)\n",
            "Loss: 22.486452102661133\n",
            "tensor([ 0.3034, -3.0725,  1.7614], requires_grad=True)\n",
            "Loss: 22.48644256591797\n",
            "tensor([ 0.3034, -3.0725,  1.7614], requires_grad=True)\n",
            "Loss: 22.486431121826172\n",
            "tensor([ 0.3034, -3.0725,  1.7614], requires_grad=True)\n",
            "Loss: 22.48642349243164\n",
            "tensor([ 0.3034, -3.0725,  1.7614], requires_grad=True)\n",
            "Loss: 22.48641586303711\n",
            "tensor([ 0.3034, -3.0725,  1.7615], requires_grad=True)\n",
            "Loss: 22.486408233642578\n",
            "tensor([ 0.3034, -3.0725,  1.7615], requires_grad=True)\n",
            "Loss: 22.486398696899414\n",
            "tensor([ 0.3034, -3.0725,  1.7615], requires_grad=True)\n",
            "Loss: 22.48638916015625\n",
            "tensor([ 0.3034, -3.0725,  1.7616], requires_grad=True)\n",
            "Loss: 22.48638153076172\n",
            "tensor([ 0.3034, -3.0725,  1.7616], requires_grad=True)\n",
            "Loss: 22.486373901367188\n",
            "tensor([ 0.3034, -3.0725,  1.7616], requires_grad=True)\n",
            "Loss: 22.486364364624023\n",
            "tensor([ 0.3034, -3.0725,  1.7616], requires_grad=True)\n",
            "Loss: 22.486356735229492\n",
            "tensor([ 0.3034, -3.0725,  1.7617], requires_grad=True)\n",
            "Loss: 22.486347198486328\n",
            "tensor([ 0.3034, -3.0725,  1.7617], requires_grad=True)\n",
            "Loss: 22.486339569091797\n",
            "tensor([ 0.3034, -3.0725,  1.7617], requires_grad=True)\n",
            "Loss: 22.486330032348633\n",
            "tensor([ 0.3034, -3.0725,  1.7618], requires_grad=True)\n",
            "Loss: 22.4863224029541\n",
            "tensor([ 0.3034, -3.0726,  1.7618], requires_grad=True)\n",
            "Loss: 22.486312866210938\n",
            "tensor([ 0.3034, -3.0726,  1.7618], requires_grad=True)\n",
            "Loss: 22.486303329467773\n",
            "tensor([ 0.3034, -3.0726,  1.7618], requires_grad=True)\n",
            "Loss: 22.486295700073242\n",
            "tensor([ 0.3034, -3.0726,  1.7619], requires_grad=True)\n",
            "Loss: 22.486286163330078\n",
            "tensor([ 0.3034, -3.0726,  1.7619], requires_grad=True)\n",
            "Loss: 22.486278533935547\n",
            "tensor([ 0.3034, -3.0726,  1.7619], requires_grad=True)\n",
            "Loss: 22.486270904541016\n",
            "tensor([ 0.3034, -3.0726,  1.7620], requires_grad=True)\n",
            "Loss: 22.48626136779785\n",
            "tensor([ 0.3034, -3.0726,  1.7620], requires_grad=True)\n",
            "Loss: 22.486251831054688\n",
            "tensor([ 0.3034, -3.0726,  1.7620], requires_grad=True)\n",
            "Loss: 22.48624610900879\n",
            "tensor([ 0.3034, -3.0726,  1.7620], requires_grad=True)\n",
            "Loss: 22.486236572265625\n",
            "tensor([ 0.3034, -3.0726,  1.7621], requires_grad=True)\n",
            "Loss: 22.48622703552246\n",
            "tensor([ 0.3034, -3.0726,  1.7621], requires_grad=True)\n",
            "Loss: 22.486217498779297\n",
            "tensor([ 0.3034, -3.0726,  1.7621], requires_grad=True)\n",
            "Loss: 22.486209869384766\n",
            "tensor([ 0.3034, -3.0726,  1.7622], requires_grad=True)\n",
            "Loss: 22.486202239990234\n",
            "tensor([ 0.3034, -3.0727,  1.7622], requires_grad=True)\n",
            "Loss: 22.486194610595703\n",
            "tensor([ 0.3034, -3.0727,  1.7622], requires_grad=True)\n",
            "Loss: 22.48618507385254\n",
            "tensor([ 0.3034, -3.0727,  1.7622], requires_grad=True)\n",
            "Loss: 22.486175537109375\n",
            "tensor([ 0.3034, -3.0727,  1.7623], requires_grad=True)\n",
            "Loss: 22.486167907714844\n",
            "tensor([ 0.3034, -3.0727,  1.7623], requires_grad=True)\n",
            "Loss: 22.48615837097168\n",
            "tensor([ 0.3034, -3.0727,  1.7623], requires_grad=True)\n",
            "Loss: 22.486148834228516\n",
            "tensor([ 0.3034, -3.0727,  1.7624], requires_grad=True)\n",
            "Loss: 22.486141204833984\n",
            "tensor([ 0.3034, -3.0727,  1.7624], requires_grad=True)\n",
            "Loss: 22.486133575439453\n",
            "tensor([ 0.3034, -3.0727,  1.7624], requires_grad=True)\n",
            "Loss: 22.48612403869629\n",
            "tensor([ 0.3034, -3.0727,  1.7624], requires_grad=True)\n",
            "Loss: 22.486116409301758\n",
            "tensor([ 0.3034, -3.0727,  1.7625], requires_grad=True)\n",
            "Loss: 22.486106872558594\n",
            "tensor([ 0.3034, -3.0727,  1.7625], requires_grad=True)\n",
            "Loss: 22.486099243164062\n",
            "tensor([ 0.3034, -3.0727,  1.7625], requires_grad=True)\n",
            "Loss: 22.4860897064209\n",
            "tensor([ 0.3034, -3.0727,  1.7626], requires_grad=True)\n",
            "Loss: 22.486082077026367\n",
            "tensor([ 0.3034, -3.0727,  1.7626], requires_grad=True)\n",
            "Loss: 22.48607063293457\n",
            "tensor([ 0.3034, -3.0728,  1.7626], requires_grad=True)\n",
            "Loss: 22.48606300354004\n",
            "tensor([ 0.3034, -3.0728,  1.7626], requires_grad=True)\n",
            "Loss: 22.486055374145508\n",
            "tensor([ 0.3034, -3.0728,  1.7627], requires_grad=True)\n",
            "Loss: 22.486047744750977\n",
            "tensor([ 0.3034, -3.0728,  1.7627], requires_grad=True)\n",
            "Loss: 22.486038208007812\n",
            "tensor([ 0.3034, -3.0728,  1.7627], requires_grad=True)\n",
            "Loss: 22.48602867126465\n",
            "tensor([ 0.3034, -3.0728,  1.7628], requires_grad=True)\n",
            "Loss: 22.486021041870117\n",
            "tensor([ 0.3034, -3.0728,  1.7628], requires_grad=True)\n",
            "Loss: 22.486013412475586\n",
            "tensor([ 0.3034, -3.0728,  1.7628], requires_grad=True)\n",
            "Loss: 22.486003875732422\n",
            "tensor([ 0.3034, -3.0728,  1.7628], requires_grad=True)\n",
            "Loss: 22.48599624633789\n",
            "tensor([ 0.3034, -3.0728,  1.7629], requires_grad=True)\n",
            "Loss: 22.485986709594727\n",
            "tensor([ 0.3034, -3.0728,  1.7629], requires_grad=True)\n",
            "Loss: 22.485977172851562\n",
            "tensor([ 0.3034, -3.0728,  1.7629], requires_grad=True)\n",
            "Loss: 22.48596954345703\n",
            "tensor([ 0.3034, -3.0728,  1.7629], requires_grad=True)\n",
            "Loss: 22.485960006713867\n",
            "tensor([ 0.3034, -3.0728,  1.7630], requires_grad=True)\n",
            "Loss: 22.48595428466797\n",
            "tensor([ 0.3034, -3.0729,  1.7630], requires_grad=True)\n",
            "Loss: 22.485942840576172\n",
            "tensor([ 0.3034, -3.0729,  1.7630], requires_grad=True)\n",
            "Loss: 22.48593521118164\n",
            "tensor([ 0.3034, -3.0729,  1.7631], requires_grad=True)\n",
            "Loss: 22.485925674438477\n",
            "tensor([ 0.3034, -3.0729,  1.7631], requires_grad=True)\n",
            "Loss: 22.485919952392578\n",
            "tensor([ 0.3034, -3.0729,  1.7631], requires_grad=True)\n",
            "Loss: 22.48590850830078\n",
            "tensor([ 0.3034, -3.0729,  1.7631], requires_grad=True)\n",
            "Loss: 22.48590087890625\n",
            "tensor([ 0.3034, -3.0729,  1.7632], requires_grad=True)\n",
            "Loss: 22.48589324951172\n",
            "tensor([ 0.3034, -3.0729,  1.7632], requires_grad=True)\n",
            "Loss: 22.485883712768555\n",
            "tensor([ 0.3034, -3.0729,  1.7632], requires_grad=True)\n",
            "Loss: 22.485876083374023\n",
            "tensor([ 0.3034, -3.0729,  1.7633], requires_grad=True)\n",
            "Loss: 22.48586654663086\n",
            "tensor([ 0.3034, -3.0729,  1.7633], requires_grad=True)\n",
            "Loss: 22.485858917236328\n",
            "tensor([ 0.3034, -3.0729,  1.7633], requires_grad=True)\n",
            "Loss: 22.485849380493164\n",
            "tensor([ 0.3034, -3.0729,  1.7633], requires_grad=True)\n",
            "Loss: 22.48583984375\n",
            "tensor([ 0.3034, -3.0729,  1.7634], requires_grad=True)\n",
            "Loss: 22.48583221435547\n",
            "tensor([ 0.3034, -3.0730,  1.7634], requires_grad=True)\n",
            "Loss: 22.485824584960938\n",
            "tensor([ 0.3034, -3.0730,  1.7634], requires_grad=True)\n",
            "Loss: 22.48581314086914\n",
            "tensor([ 0.3034, -3.0730,  1.7635], requires_grad=True)\n",
            "Loss: 22.485807418823242\n",
            "tensor([ 0.3034, -3.0730,  1.7635], requires_grad=True)\n",
            "Loss: 22.485795974731445\n",
            "tensor([ 0.3034, -3.0730,  1.7635], requires_grad=True)\n",
            "Loss: 22.485790252685547\n",
            "tensor([ 0.3034, -3.0730,  1.7635], requires_grad=True)\n",
            "Loss: 22.48577880859375\n",
            "tensor([ 0.3034, -3.0730,  1.7636], requires_grad=True)\n",
            "Loss: 22.48577117919922\n",
            "tensor([ 0.3034, -3.0730,  1.7636], requires_grad=True)\n",
            "Loss: 22.485763549804688\n",
            "tensor([ 0.3034, -3.0730,  1.7636], requires_grad=True)\n",
            "Loss: 22.485754013061523\n",
            "tensor([ 0.3034, -3.0730,  1.7637], requires_grad=True)\n",
            "Loss: 22.485746383666992\n",
            "tensor([ 0.3034, -3.0730,  1.7637], requires_grad=True)\n",
            "Loss: 22.485736846923828\n",
            "tensor([ 0.3034, -3.0730,  1.7637], requires_grad=True)\n",
            "Loss: 22.48573112487793\n",
            "tensor([ 0.3034, -3.0730,  1.7637], requires_grad=True)\n",
            "Loss: 22.485721588134766\n",
            "tensor([ 0.3034, -3.0730,  1.7638], requires_grad=True)\n",
            "Loss: 22.4857120513916\n",
            "tensor([ 0.3034, -3.0730,  1.7638], requires_grad=True)\n",
            "Loss: 22.485702514648438\n",
            "tensor([ 0.3034, -3.0731,  1.7638], requires_grad=True)\n",
            "Loss: 22.485694885253906\n",
            "tensor([ 0.3034, -3.0731,  1.7639], requires_grad=True)\n",
            "Loss: 22.485685348510742\n",
            "tensor([ 0.3034, -3.0731,  1.7639], requires_grad=True)\n",
            "Loss: 22.48567771911621\n",
            "tensor([ 0.3034, -3.0731,  1.7639], requires_grad=True)\n",
            "Loss: 22.485668182373047\n",
            "tensor([ 0.3034, -3.0731,  1.7639], requires_grad=True)\n",
            "Loss: 22.485660552978516\n",
            "tensor([ 0.3034, -3.0731,  1.7640], requires_grad=True)\n",
            "Loss: 22.485652923583984\n",
            "tensor([ 0.3034, -3.0731,  1.7640], requires_grad=True)\n",
            "Loss: 22.48564338684082\n",
            "tensor([ 0.3034, -3.0731,  1.7640], requires_grad=True)\n",
            "Loss: 22.485633850097656\n",
            "tensor([ 0.3034, -3.0731,  1.7641], requires_grad=True)\n",
            "Loss: 22.485626220703125\n",
            "tensor([ 0.3034, -3.0731,  1.7641], requires_grad=True)\n",
            "Loss: 22.485618591308594\n",
            "tensor([ 0.3034, -3.0731,  1.7641], requires_grad=True)\n",
            "Loss: 22.485607147216797\n",
            "tensor([ 0.3034, -3.0731,  1.7641], requires_grad=True)\n",
            "Loss: 22.485599517822266\n",
            "tensor([ 0.3034, -3.0731,  1.7642], requires_grad=True)\n",
            "Loss: 22.485593795776367\n",
            "tensor([ 0.3034, -3.0731,  1.7642], requires_grad=True)\n",
            "Loss: 22.48558235168457\n",
            "tensor([ 0.3034, -3.0732,  1.7642], requires_grad=True)\n",
            "Loss: 22.48557472229004\n",
            "tensor([ 0.3034, -3.0732,  1.7643], requires_grad=True)\n",
            "Loss: 22.485565185546875\n",
            "tensor([ 0.3034, -3.0732,  1.7643], requires_grad=True)\n",
            "Loss: 22.48555564880371\n",
            "tensor([ 0.3034, -3.0732,  1.7643], requires_grad=True)\n",
            "Loss: 22.485549926757812\n",
            "tensor([ 0.3034, -3.0732,  1.7643], requires_grad=True)\n",
            "Loss: 22.48554039001465\n",
            "tensor([ 0.3034, -3.0732,  1.7644], requires_grad=True)\n",
            "Loss: 22.485530853271484\n",
            "tensor([ 0.3034, -3.0732,  1.7644], requires_grad=True)\n",
            "Loss: 22.485523223876953\n",
            "tensor([ 0.3034, -3.0732,  1.7644], requires_grad=True)\n",
            "Loss: 22.485511779785156\n",
            "tensor([ 0.3034, -3.0732,  1.7645], requires_grad=True)\n",
            "Loss: 22.485506057739258\n",
            "tensor([ 0.3034, -3.0732,  1.7645], requires_grad=True)\n",
            "Loss: 22.485496520996094\n",
            "tensor([ 0.3034, -3.0732,  1.7645], requires_grad=True)\n",
            "Loss: 22.485488891601562\n",
            "tensor([ 0.3034, -3.0732,  1.7645], requires_grad=True)\n",
            "Loss: 22.4854793548584\n",
            "tensor([ 0.3034, -3.0732,  1.7646], requires_grad=True)\n",
            "Loss: 22.485471725463867\n",
            "tensor([ 0.3034, -3.0732,  1.7646], requires_grad=True)\n",
            "Loss: 22.485462188720703\n",
            "tensor([ 0.3034, -3.0732,  1.7646], requires_grad=True)\n",
            "Loss: 22.485454559326172\n",
            "tensor([ 0.3034, -3.0733,  1.7647], requires_grad=True)\n",
            "Loss: 22.485445022583008\n",
            "tensor([ 0.3034, -3.0733,  1.7647], requires_grad=True)\n",
            "Loss: 22.485437393188477\n",
            "tensor([ 0.3034, -3.0733,  1.7647], requires_grad=True)\n",
            "Loss: 22.485427856445312\n",
            "tensor([ 0.3034, -3.0733,  1.7647], requires_grad=True)\n",
            "Loss: 22.48542022705078\n",
            "tensor([ 0.3034, -3.0733,  1.7648], requires_grad=True)\n",
            "Loss: 22.485410690307617\n",
            "tensor([ 0.3034, -3.0733,  1.7648], requires_grad=True)\n",
            "Loss: 22.485403060913086\n",
            "tensor([ 0.3034, -3.0733,  1.7648], requires_grad=True)\n",
            "Loss: 22.485393524169922\n",
            "tensor([ 0.3034, -3.0733,  1.7649], requires_grad=True)\n",
            "Loss: 22.48538589477539\n",
            "tensor([ 0.3034, -3.0733,  1.7649], requires_grad=True)\n",
            "Loss: 22.485376358032227\n",
            "tensor([ 0.3034, -3.0733,  1.7649], requires_grad=True)\n",
            "Loss: 22.485368728637695\n",
            "tensor([ 0.3034, -3.0733,  1.7649], requires_grad=True)\n",
            "Loss: 22.485361099243164\n",
            "tensor([ 0.3034, -3.0733,  1.7650], requires_grad=True)\n",
            "Loss: 22.485349655151367\n",
            "tensor([ 0.3034, -3.0733,  1.7650], requires_grad=True)\n",
            "Loss: 22.48534393310547\n",
            "tensor([ 0.3034, -3.0733,  1.7650], requires_grad=True)\n",
            "Loss: 22.485334396362305\n",
            "tensor([ 0.3034, -3.0734,  1.7651], requires_grad=True)\n",
            "Loss: 22.48532485961914\n",
            "tensor([ 0.3034, -3.0734,  1.7651], requires_grad=True)\n",
            "Loss: 22.485315322875977\n",
            "tensor([ 0.3034, -3.0734,  1.7651], requires_grad=True)\n",
            "Loss: 22.485307693481445\n",
            "tensor([ 0.3034, -3.0734,  1.7651], requires_grad=True)\n",
            "Loss: 22.485300064086914\n",
            "tensor([ 0.3034, -3.0734,  1.7652], requires_grad=True)\n",
            "Loss: 22.48529052734375\n",
            "tensor([ 0.3034, -3.0734,  1.7652], requires_grad=True)\n",
            "Loss: 22.48528289794922\n",
            "tensor([ 0.3034, -3.0734,  1.7652], requires_grad=True)\n",
            "Loss: 22.485273361206055\n",
            "tensor([ 0.3034, -3.0734,  1.7653], requires_grad=True)\n",
            "Loss: 22.48526382446289\n",
            "tensor([ 0.3034, -3.0734,  1.7653], requires_grad=True)\n",
            "Loss: 22.485258102416992\n",
            "tensor([ 0.3034, -3.0734,  1.7653], requires_grad=True)\n",
            "Loss: 22.485248565673828\n",
            "tensor([ 0.3034, -3.0734,  1.7653], requires_grad=True)\n",
            "Loss: 22.485239028930664\n",
            "tensor([ 0.3034, -3.0734,  1.7654], requires_grad=True)\n",
            "Loss: 22.4852294921875\n",
            "tensor([ 0.3034, -3.0734,  1.7654], requires_grad=True)\n",
            "Loss: 22.4852237701416\n",
            "tensor([ 0.3034, -3.0734,  1.7654], requires_grad=True)\n",
            "Loss: 22.485214233398438\n",
            "tensor([ 0.3034, -3.0734,  1.7655], requires_grad=True)\n",
            "Loss: 22.485204696655273\n",
            "tensor([ 0.3034, -3.0735,  1.7655], requires_grad=True)\n",
            "Loss: 22.485197067260742\n",
            "tensor([ 0.3034, -3.0735,  1.7655], requires_grad=True)\n",
            "Loss: 22.485187530517578\n",
            "tensor([ 0.3034, -3.0735,  1.7655], requires_grad=True)\n",
            "Loss: 22.485179901123047\n",
            "tensor([ 0.3034, -3.0735,  1.7656], requires_grad=True)\n",
            "Loss: 22.485170364379883\n",
            "tensor([ 0.3034, -3.0735,  1.7656], requires_grad=True)\n",
            "Loss: 22.48516273498535\n",
            "tensor([ 0.3034, -3.0735,  1.7656], requires_grad=True)\n",
            "Loss: 22.485153198242188\n",
            "tensor([ 0.3034, -3.0735,  1.7657], requires_grad=True)\n",
            "Loss: 22.485145568847656\n",
            "tensor([ 0.3034, -3.0735,  1.7657], requires_grad=True)\n",
            "Loss: 22.485137939453125\n",
            "tensor([ 0.3034, -3.0735,  1.7657], requires_grad=True)\n",
            "Loss: 22.48512840270996\n",
            "tensor([ 0.3034, -3.0735,  1.7657], requires_grad=True)\n",
            "Loss: 22.485116958618164\n",
            "tensor([ 0.3034, -3.0735,  1.7658], requires_grad=True)\n",
            "Loss: 22.485111236572266\n",
            "tensor([ 0.3034, -3.0735,  1.7658], requires_grad=True)\n",
            "Loss: 22.4851016998291\n",
            "tensor([ 0.3034, -3.0735,  1.7658], requires_grad=True)\n",
            "Loss: 22.485095977783203\n",
            "tensor([ 0.3034, -3.0735,  1.7659], requires_grad=True)\n",
            "Loss: 22.48508644104004\n",
            "tensor([ 0.3034, -3.0736,  1.7659], requires_grad=True)\n",
            "Loss: 22.485076904296875\n",
            "tensor([ 0.3034, -3.0736,  1.7659], requires_grad=True)\n",
            "Loss: 22.48506736755371\n",
            "tensor([ 0.3034, -3.0736,  1.7659], requires_grad=True)\n",
            "Loss: 22.485057830810547\n",
            "tensor([ 0.3034, -3.0736,  1.7660], requires_grad=True)\n",
            "Loss: 22.485050201416016\n",
            "tensor([ 0.3034, -3.0736,  1.7660], requires_grad=True)\n",
            "Loss: 22.485042572021484\n",
            "tensor([ 0.3034, -3.0736,  1.7660], requires_grad=True)\n",
            "Loss: 22.485034942626953\n",
            "tensor([ 0.3034, -3.0736,  1.7661], requires_grad=True)\n",
            "Loss: 22.485023498535156\n",
            "tensor([ 0.3034, -3.0736,  1.7661], requires_grad=True)\n",
            "Loss: 22.485017776489258\n",
            "tensor([ 0.3034, -3.0736,  1.7661], requires_grad=True)\n",
            "Loss: 22.48500633239746\n",
            "tensor([ 0.3034, -3.0736,  1.7661], requires_grad=True)\n",
            "Loss: 22.485000610351562\n",
            "tensor([ 0.3034, -3.0736,  1.7662], requires_grad=True)\n",
            "Loss: 22.484989166259766\n",
            "tensor([ 0.3034, -3.0736,  1.7662], requires_grad=True)\n",
            "Loss: 22.484981536865234\n",
            "tensor([ 0.3034, -3.0736,  1.7662], requires_grad=True)\n",
            "Loss: 22.48497200012207\n",
            "tensor([ 0.3034, -3.0736,  1.7663], requires_grad=True)\n",
            "Loss: 22.48496437072754\n",
            "tensor([ 0.3034, -3.0736,  1.7663], requires_grad=True)\n",
            "Loss: 22.484956741333008\n",
            "tensor([ 0.3034, -3.0737,  1.7663], requires_grad=True)\n",
            "Loss: 22.484947204589844\n",
            "tensor([ 0.3034, -3.0737,  1.7663], requires_grad=True)\n",
            "Loss: 22.48493766784668\n",
            "tensor([ 0.3034, -3.0737,  1.7664], requires_grad=True)\n",
            "Loss: 22.48493003845215\n",
            "tensor([ 0.3034, -3.0737,  1.7664], requires_grad=True)\n",
            "Loss: 22.484922409057617\n",
            "tensor([ 0.3034, -3.0737,  1.7664], requires_grad=True)\n",
            "Loss: 22.484912872314453\n",
            "tensor([ 0.3034, -3.0737,  1.7665], requires_grad=True)\n",
            "Loss: 22.484905242919922\n",
            "tensor([ 0.3034, -3.0737,  1.7665], requires_grad=True)\n",
            "Loss: 22.484895706176758\n",
            "tensor([ 0.3034, -3.0737,  1.7665], requires_grad=True)\n",
            "Loss: 22.484888076782227\n",
            "tensor([ 0.3034, -3.0737,  1.7665], requires_grad=True)\n",
            "Loss: 22.484878540039062\n",
            "tensor([ 0.3034, -3.0737,  1.7666], requires_grad=True)\n",
            "Loss: 22.4848690032959\n",
            "tensor([ 0.3034, -3.0737,  1.7666], requires_grad=True)\n",
            "Loss: 22.484861373901367\n",
            "tensor([ 0.3034, -3.0737,  1.7666], requires_grad=True)\n",
            "Loss: 22.484853744506836\n",
            "tensor([ 0.3034, -3.0737,  1.7667], requires_grad=True)\n",
            "Loss: 22.484844207763672\n",
            "tensor([ 0.3034, -3.0737,  1.7667], requires_grad=True)\n",
            "Loss: 22.48483657836914\n",
            "tensor([ 0.3034, -3.0738,  1.7667], requires_grad=True)\n",
            "Loss: 22.484827041625977\n",
            "tensor([ 0.3034, -3.0738,  1.7667], requires_grad=True)\n",
            "Loss: 22.484819412231445\n",
            "tensor([ 0.3034, -3.0738,  1.7668], requires_grad=True)\n",
            "Loss: 22.48480987548828\n",
            "tensor([ 0.3034, -3.0738,  1.7668], requires_grad=True)\n",
            "Loss: 22.48480224609375\n",
            "tensor([ 0.3034, -3.0738,  1.7668], requires_grad=True)\n",
            "Loss: 22.484792709350586\n",
            "tensor([ 0.3034, -3.0738,  1.7669], requires_grad=True)\n",
            "Loss: 22.484785079956055\n",
            "tensor([ 0.3034, -3.0738,  1.7669], requires_grad=True)\n",
            "Loss: 22.48477554321289\n",
            "tensor([ 0.3034, -3.0738,  1.7669], requires_grad=True)\n",
            "Loss: 22.48476791381836\n",
            "tensor([ 0.3034, -3.0738,  1.7669], requires_grad=True)\n",
            "Loss: 22.484758377075195\n",
            "tensor([ 0.3034, -3.0738,  1.7670], requires_grad=True)\n",
            "Loss: 22.484750747680664\n",
            "tensor([ 0.3034, -3.0738,  1.7670], requires_grad=True)\n",
            "Loss: 22.4847412109375\n",
            "tensor([ 0.3034, -3.0738,  1.7670], requires_grad=True)\n",
            "Loss: 22.484731674194336\n",
            "tensor([ 0.3034, -3.0738,  1.7671], requires_grad=True)\n",
            "Loss: 22.484725952148438\n",
            "tensor([ 0.3034, -3.0738,  1.7671], requires_grad=True)\n",
            "Loss: 22.484716415405273\n",
            "tensor([ 0.3034, -3.0738,  1.7671], requires_grad=True)\n",
            "Loss: 22.48470687866211\n",
            "tensor([ 0.3034, -3.0739,  1.7671], requires_grad=True)\n",
            "Loss: 22.484699249267578\n",
            "tensor([ 0.3034, -3.0739,  1.7672], requires_grad=True)\n",
            "Loss: 22.484689712524414\n",
            "tensor([ 0.3034, -3.0739,  1.7672], requires_grad=True)\n",
            "Loss: 22.48468017578125\n",
            "tensor([ 0.3034, -3.0739,  1.7672], requires_grad=True)\n",
            "Loss: 22.48467254638672\n",
            "tensor([ 0.3034, -3.0739,  1.7673], requires_grad=True)\n",
            "Loss: 22.484663009643555\n",
            "tensor([ 0.3034, -3.0739,  1.7673], requires_grad=True)\n",
            "Loss: 22.484655380249023\n",
            "tensor([ 0.3034, -3.0739,  1.7673], requires_grad=True)\n",
            "Loss: 22.484647750854492\n",
            "tensor([ 0.3034, -3.0739,  1.7673], requires_grad=True)\n",
            "Loss: 22.48464012145996\n",
            "tensor([ 0.3034, -3.0739,  1.7674], requires_grad=True)\n",
            "Loss: 22.484630584716797\n",
            "tensor([ 0.3034, -3.0739,  1.7674], requires_grad=True)\n",
            "Loss: 22.484621047973633\n",
            "tensor([ 0.3034, -3.0739,  1.7674], requires_grad=True)\n",
            "Loss: 22.48461151123047\n",
            "tensor([ 0.3034, -3.0739,  1.7675], requires_grad=True)\n",
            "Loss: 22.484601974487305\n",
            "tensor([ 0.3034, -3.0739,  1.7675], requires_grad=True)\n",
            "Loss: 22.484594345092773\n",
            "tensor([ 0.3034, -3.0739,  1.7675], requires_grad=True)\n",
            "Loss: 22.484586715698242\n",
            "tensor([ 0.3034, -3.0740,  1.7675], requires_grad=True)\n",
            "Loss: 22.484577178955078\n",
            "tensor([ 0.3034, -3.0740,  1.7676], requires_grad=True)\n",
            "Loss: 22.484569549560547\n",
            "tensor([ 0.3034, -3.0740,  1.7676], requires_grad=True)\n",
            "Loss: 22.484561920166016\n",
            "tensor([ 0.3034, -3.0740,  1.7676], requires_grad=True)\n",
            "Loss: 22.48455238342285\n",
            "tensor([ 0.3034, -3.0740,  1.7677], requires_grad=True)\n",
            "Loss: 22.48454475402832\n",
            "tensor([ 0.3034, -3.0740,  1.7677], requires_grad=True)\n",
            "Loss: 22.484535217285156\n",
            "tensor([ 0.3034, -3.0740,  1.7677], requires_grad=True)\n",
            "Loss: 22.484525680541992\n",
            "tensor([ 0.3034, -3.0740,  1.7677], requires_grad=True)\n",
            "Loss: 22.484519958496094\n",
            "tensor([ 0.3034, -3.0740,  1.7678], requires_grad=True)\n",
            "Loss: 22.48451042175293\n",
            "tensor([ 0.3034, -3.0740,  1.7678], requires_grad=True)\n",
            "Loss: 22.484500885009766\n",
            "tensor([ 0.3034, -3.0740,  1.7678], requires_grad=True)\n",
            "Loss: 22.484493255615234\n",
            "tensor([ 0.3034, -3.0740,  1.7678], requires_grad=True)\n",
            "Loss: 22.48448371887207\n",
            "tensor([ 0.3034, -3.0740,  1.7679], requires_grad=True)\n",
            "Loss: 22.48447608947754\n",
            "tensor([ 0.3034, -3.0740,  1.7679], requires_grad=True)\n",
            "Loss: 22.484466552734375\n",
            "tensor([ 0.3034, -3.0740,  1.7679], requires_grad=True)\n",
            "Loss: 22.484458923339844\n",
            "tensor([ 0.3034, -3.0741,  1.7680], requires_grad=True)\n",
            "Loss: 22.48444938659668\n",
            "tensor([ 0.3034, -3.0741,  1.7680], requires_grad=True)\n",
            "Loss: 22.484439849853516\n",
            "tensor([ 0.3034, -3.0741,  1.7680], requires_grad=True)\n",
            "Loss: 22.484434127807617\n",
            "tensor([ 0.3034, -3.0741,  1.7680], requires_grad=True)\n",
            "Loss: 22.484424591064453\n",
            "tensor([ 0.3034, -3.0741,  1.7681], requires_grad=True)\n",
            "Loss: 22.48441505432129\n",
            "tensor([ 0.3034, -3.0741,  1.7681], requires_grad=True)\n",
            "Loss: 22.484405517578125\n",
            "tensor([ 0.3034, -3.0741,  1.7681], requires_grad=True)\n",
            "Loss: 22.484397888183594\n",
            "tensor([ 0.3034, -3.0741,  1.7682], requires_grad=True)\n",
            "Loss: 22.48438835144043\n",
            "tensor([ 0.3034, -3.0741,  1.7682], requires_grad=True)\n",
            "Loss: 22.4843807220459\n",
            "tensor([ 0.3034, -3.0741,  1.7682], requires_grad=True)\n",
            "Loss: 22.484373092651367\n",
            "tensor([ 0.3034, -3.0741,  1.7682], requires_grad=True)\n",
            "Loss: 22.484365463256836\n",
            "tensor([ 0.3034, -3.0741,  1.7683], requires_grad=True)\n",
            "Loss: 22.484355926513672\n",
            "tensor([ 0.3034, -3.0741,  1.7683], requires_grad=True)\n",
            "Loss: 22.484346389770508\n",
            "tensor([ 0.3034, -3.0741,  1.7683], requires_grad=True)\n",
            "Loss: 22.484338760375977\n",
            "tensor([ 0.3034, -3.0742,  1.7684], requires_grad=True)\n",
            "Loss: 22.484329223632812\n",
            "tensor([ 0.3034, -3.0742,  1.7684], requires_grad=True)\n",
            "Loss: 22.48432159423828\n",
            "tensor([ 0.3034, -3.0742,  1.7684], requires_grad=True)\n",
            "Loss: 22.484312057495117\n",
            "tensor([ 0.3034, -3.0742,  1.7684], requires_grad=True)\n",
            "Loss: 22.484304428100586\n",
            "tensor([ 0.3034, -3.0742,  1.7685], requires_grad=True)\n",
            "Loss: 22.48429298400879\n",
            "tensor([ 0.3034, -3.0742,  1.7685], requires_grad=True)\n",
            "Loss: 22.484285354614258\n",
            "tensor([ 0.3034, -3.0742,  1.7685], requires_grad=True)\n",
            "Loss: 22.484277725219727\n",
            "tensor([ 0.3034, -3.0742,  1.7686], requires_grad=True)\n",
            "Loss: 22.484270095825195\n",
            "tensor([ 0.3034, -3.0742,  1.7686], requires_grad=True)\n",
            "Loss: 22.48426055908203\n",
            "tensor([ 0.3034, -3.0742,  1.7686], requires_grad=True)\n",
            "Loss: 22.4842529296875\n",
            "tensor([ 0.3034, -3.0742,  1.7686], requires_grad=True)\n",
            "Loss: 22.484243392944336\n",
            "tensor([ 0.3034, -3.0742,  1.7687], requires_grad=True)\n",
            "Loss: 22.484235763549805\n",
            "tensor([ 0.3034, -3.0742,  1.7687], requires_grad=True)\n",
            "Loss: 22.48422622680664\n",
            "tensor([ 0.3034, -3.0742,  1.7687], requires_grad=True)\n",
            "Loss: 22.48421859741211\n",
            "tensor([ 0.3034, -3.0742,  1.7688], requires_grad=True)\n",
            "Loss: 22.484210968017578\n",
            "tensor([ 0.3034, -3.0743,  1.7688], requires_grad=True)\n",
            "Loss: 22.48419952392578\n",
            "tensor([ 0.3034, -3.0743,  1.7688], requires_grad=True)\n",
            "Loss: 22.484193801879883\n",
            "tensor([ 0.3034, -3.0743,  1.7688], requires_grad=True)\n",
            "Loss: 22.48418426513672\n",
            "tensor([ 0.3034, -3.0743,  1.7689], requires_grad=True)\n",
            "Loss: 22.484174728393555\n",
            "tensor([ 0.3034, -3.0743,  1.7689], requires_grad=True)\n",
            "Loss: 22.484167098999023\n",
            "tensor([ 0.3034, -3.0743,  1.7689], requires_grad=True)\n",
            "Loss: 22.48415756225586\n",
            "tensor([ 0.3034, -3.0743,  1.7690], requires_grad=True)\n",
            "Loss: 22.484149932861328\n",
            "tensor([ 0.3034, -3.0743,  1.7690], requires_grad=True)\n",
            "Loss: 22.484140396118164\n",
            "tensor([ 0.3034, -3.0743,  1.7690], requires_grad=True)\n",
            "Loss: 22.484132766723633\n",
            "tensor([ 0.3034, -3.0743,  1.7690], requires_grad=True)\n",
            "Loss: 22.48412322998047\n",
            "tensor([ 0.3034, -3.0743,  1.7691], requires_grad=True)\n",
            "Loss: 22.484115600585938\n",
            "tensor([ 0.3034, -3.0743,  1.7691], requires_grad=True)\n",
            "Loss: 22.484106063842773\n",
            "tensor([ 0.3034, -3.0743,  1.7691], requires_grad=True)\n",
            "Loss: 22.484098434448242\n",
            "tensor([ 0.3034, -3.0743,  1.7692], requires_grad=True)\n",
            "Loss: 22.484088897705078\n",
            "tensor([ 0.3034, -3.0744,  1.7692], requires_grad=True)\n",
            "Loss: 22.484081268310547\n",
            "tensor([ 0.3034, -3.0744,  1.7692], requires_grad=True)\n",
            "Loss: 22.484071731567383\n",
            "tensor([ 0.3034, -3.0744,  1.7692], requires_grad=True)\n",
            "Loss: 22.48406410217285\n",
            "tensor([ 0.3034, -3.0744,  1.7693], requires_grad=True)\n",
            "Loss: 22.484054565429688\n",
            "tensor([ 0.3034, -3.0744,  1.7693], requires_grad=True)\n",
            "Loss: 22.484046936035156\n",
            "tensor([ 0.3034, -3.0744,  1.7693], requires_grad=True)\n",
            "Loss: 22.484037399291992\n",
            "tensor([ 0.3034, -3.0744,  1.7694], requires_grad=True)\n",
            "Loss: 22.484027862548828\n",
            "tensor([ 0.3034, -3.0744,  1.7694], requires_grad=True)\n",
            "Loss: 22.484020233154297\n",
            "tensor([ 0.3034, -3.0744,  1.7694], requires_grad=True)\n",
            "Loss: 22.484010696411133\n",
            "tensor([ 0.3034, -3.0744,  1.7694], requires_grad=True)\n",
            "Loss: 22.4840030670166\n",
            "tensor([ 0.3034, -3.0744,  1.7695], requires_grad=True)\n",
            "Loss: 22.483993530273438\n",
            "tensor([ 0.3034, -3.0744,  1.7695], requires_grad=True)\n",
            "Loss: 22.483985900878906\n",
            "tensor([ 0.3034, -3.0744,  1.7695], requires_grad=True)\n",
            "Loss: 22.483978271484375\n",
            "tensor([ 0.3034, -3.0744,  1.7696], requires_grad=True)\n",
            "Loss: 22.48396873474121\n",
            "tensor([ 0.3034, -3.0744,  1.7696], requires_grad=True)\n",
            "Loss: 22.48396110534668\n",
            "tensor([ 0.3034, -3.0745,  1.7696], requires_grad=True)\n",
            "Loss: 22.483951568603516\n",
            "tensor([ 0.3034, -3.0745,  1.7696], requires_grad=True)\n",
            "Loss: 22.483943939208984\n",
            "tensor([ 0.3034, -3.0745,  1.7697], requires_grad=True)\n",
            "Loss: 22.483936309814453\n",
            "tensor([ 0.3034, -3.0745,  1.7697], requires_grad=True)\n",
            "Loss: 22.48392677307129\n",
            "tensor([ 0.3034, -3.0745,  1.7697], requires_grad=True)\n",
            "Loss: 22.483917236328125\n",
            "tensor([ 0.3034, -3.0745,  1.7698], requires_grad=True)\n",
            "Loss: 22.483909606933594\n",
            "tensor([ 0.3034, -3.0745,  1.7698], requires_grad=True)\n",
            "Loss: 22.483901977539062\n",
            "tensor([ 0.3034, -3.0745,  1.7698], requires_grad=True)\n",
            "Loss: 22.483890533447266\n",
            "tensor([ 0.3034, -3.0745,  1.7698], requires_grad=True)\n",
            "Loss: 22.483882904052734\n",
            "tensor([ 0.3034, -3.0745,  1.7699], requires_grad=True)\n",
            "Loss: 22.483875274658203\n",
            "tensor([ 0.3034, -3.0745,  1.7699], requires_grad=True)\n",
            "Loss: 22.483867645263672\n",
            "tensor([ 0.3034, -3.0745,  1.7699], requires_grad=True)\n",
            "Loss: 22.483858108520508\n",
            "tensor([ 0.3034, -3.0745,  1.7700], requires_grad=True)\n",
            "Loss: 22.483848571777344\n",
            "tensor([ 0.3034, -3.0745,  1.7700], requires_grad=True)\n",
            "Loss: 22.483840942382812\n",
            "tensor([ 0.3034, -3.0745,  1.7700], requires_grad=True)\n",
            "Loss: 22.48383331298828\n",
            "tensor([ 0.3034, -3.0746,  1.7700], requires_grad=True)\n",
            "Loss: 22.483823776245117\n",
            "tensor([ 0.3034, -3.0746,  1.7701], requires_grad=True)\n",
            "Loss: 22.48381233215332\n",
            "tensor([ 0.3034, -3.0746,  1.7701], requires_grad=True)\n",
            "Loss: 22.483808517456055\n",
            "tensor([ 0.3034, -3.0746,  1.7701], requires_grad=True)\n",
            "Loss: 22.48379898071289\n",
            "tensor([ 0.3034, -3.0746,  1.7702], requires_grad=True)\n",
            "Loss: 22.48379135131836\n",
            "tensor([ 0.3034, -3.0746,  1.7702], requires_grad=True)\n",
            "Loss: 22.483781814575195\n",
            "tensor([ 0.3034, -3.0746,  1.7702], requires_grad=True)\n",
            "Loss: 22.48377227783203\n",
            "tensor([ 0.3034, -3.0746,  1.7702], requires_grad=True)\n",
            "Loss: 22.483762741088867\n",
            "tensor([ 0.3034, -3.0746,  1.7703], requires_grad=True)\n",
            "Loss: 22.483755111694336\n",
            "tensor([ 0.3034, -3.0746,  1.7703], requires_grad=True)\n",
            "Loss: 22.48374366760254\n",
            "tensor([ 0.3034, -3.0746,  1.7703], requires_grad=True)\n",
            "Loss: 22.483739852905273\n",
            "tensor([ 0.3034, -3.0746,  1.7704], requires_grad=True)\n",
            "Loss: 22.48373031616211\n",
            "tensor([ 0.3034, -3.0746,  1.7704], requires_grad=True)\n",
            "Loss: 22.483720779418945\n",
            "tensor([ 0.3034, -3.0746,  1.7704], requires_grad=True)\n",
            "Loss: 22.48371124267578\n",
            "tensor([ 0.3034, -3.0746,  1.7704], requires_grad=True)\n",
            "Loss: 22.48370361328125\n",
            "tensor([ 0.3034, -3.0747,  1.7705], requires_grad=True)\n",
            "Loss: 22.483694076538086\n",
            "tensor([ 0.3034, -3.0747,  1.7705], requires_grad=True)\n",
            "Loss: 22.483684539794922\n",
            "tensor([ 0.3034, -3.0747,  1.7705], requires_grad=True)\n",
            "Loss: 22.483678817749023\n",
            "tensor([ 0.3034, -3.0747,  1.7706], requires_grad=True)\n",
            "Loss: 22.48366928100586\n",
            "tensor([ 0.3034, -3.0747,  1.7706], requires_grad=True)\n",
            "Loss: 22.483661651611328\n",
            "tensor([ 0.3034, -3.0747,  1.7706], requires_grad=True)\n",
            "Loss: 22.483652114868164\n",
            "tensor([ 0.3034, -3.0747,  1.7706], requires_grad=True)\n",
            "Loss: 22.483644485473633\n",
            "tensor([ 0.3034, -3.0747,  1.7707], requires_grad=True)\n",
            "Loss: 22.48363494873047\n",
            "tensor([ 0.3034, -3.0747,  1.7707], requires_grad=True)\n",
            "Loss: 22.483627319335938\n",
            "tensor([ 0.3034, -3.0747,  1.7707], requires_grad=True)\n",
            "Loss: 22.483617782592773\n",
            "tensor([ 0.3034, -3.0747,  1.7708], requires_grad=True)\n",
            "Loss: 22.483610153198242\n",
            "tensor([ 0.3034, -3.0747,  1.7708], requires_grad=True)\n",
            "Loss: 22.48360252380371\n",
            "tensor([ 0.3034, -3.0747,  1.7708], requires_grad=True)\n",
            "Loss: 22.483592987060547\n",
            "tensor([ 0.3034, -3.0747,  1.7708], requires_grad=True)\n",
            "Loss: 22.483583450317383\n",
            "tensor([ 0.3034, -3.0747,  1.7709], requires_grad=True)\n",
            "Loss: 22.48357582092285\n",
            "tensor([ 0.3034, -3.0748,  1.7709], requires_grad=True)\n",
            "Loss: 22.48356819152832\n",
            "tensor([ 0.3034, -3.0748,  1.7709], requires_grad=True)\n",
            "Loss: 22.483556747436523\n",
            "tensor([ 0.3034, -3.0748,  1.7710], requires_grad=True)\n",
            "Loss: 22.483549118041992\n",
            "tensor([ 0.3034, -3.0748,  1.7710], requires_grad=True)\n",
            "Loss: 22.483539581298828\n",
            "tensor([ 0.3034, -3.0748,  1.7710], requires_grad=True)\n",
            "Loss: 22.483531951904297\n",
            "tensor([ 0.3034, -3.0748,  1.7710], requires_grad=True)\n",
            "Loss: 22.483522415161133\n",
            "tensor([ 0.3034, -3.0748,  1.7711], requires_grad=True)\n",
            "Loss: 22.48351287841797\n",
            "tensor([ 0.3034, -3.0748,  1.7711], requires_grad=True)\n",
            "Loss: 22.48350715637207\n",
            "tensor([ 0.3034, -3.0748,  1.7711], requires_grad=True)\n",
            "Loss: 22.483497619628906\n",
            "tensor([ 0.3034, -3.0748,  1.7712], requires_grad=True)\n",
            "Loss: 22.483488082885742\n",
            "tensor([ 0.3034, -3.0748,  1.7712], requires_grad=True)\n",
            "Loss: 22.48348045349121\n",
            "tensor([ 0.3034, -3.0748,  1.7712], requires_grad=True)\n",
            "Loss: 22.48347282409668\n",
            "tensor([ 0.3034, -3.0748,  1.7712], requires_grad=True)\n",
            "Loss: 22.483463287353516\n",
            "tensor([ 0.3034, -3.0748,  1.7713], requires_grad=True)\n",
            "Loss: 22.483455657958984\n",
            "tensor([ 0.3034, -3.0748,  1.7713], requires_grad=True)\n",
            "Loss: 22.48344612121582\n",
            "tensor([ 0.3034, -3.0749,  1.7713], requires_grad=True)\n",
            "Loss: 22.48343849182129\n",
            "tensor([ 0.3034, -3.0749,  1.7714], requires_grad=True)\n",
            "Loss: 22.483428955078125\n",
            "tensor([ 0.3034, -3.0749,  1.7714], requires_grad=True)\n",
            "Loss: 22.483421325683594\n",
            "tensor([ 0.3034, -3.0749,  1.7714], requires_grad=True)\n",
            "Loss: 22.48341178894043\n",
            "tensor([ 0.3034, -3.0749,  1.7714], requires_grad=True)\n",
            "Loss: 22.4834041595459\n",
            "tensor([ 0.3034, -3.0749,  1.7715], requires_grad=True)\n",
            "Loss: 22.483396530151367\n",
            "tensor([ 0.3034, -3.0749,  1.7715], requires_grad=True)\n",
            "Loss: 22.483386993408203\n",
            "tensor([ 0.3034, -3.0749,  1.7715], requires_grad=True)\n",
            "Loss: 22.483379364013672\n",
            "tensor([ 0.3034, -3.0749,  1.7716], requires_grad=True)\n",
            "Loss: 22.483369827270508\n",
            "tensor([ 0.3034, -3.0749,  1.7716], requires_grad=True)\n",
            "Loss: 22.483360290527344\n",
            "tensor([ 0.3034, -3.0749,  1.7716], requires_grad=True)\n",
            "Loss: 22.483352661132812\n",
            "tensor([ 0.3034, -3.0749,  1.7716], requires_grad=True)\n",
            "Loss: 22.48334503173828\n",
            "tensor([ 0.3034, -3.0749,  1.7717], requires_grad=True)\n",
            "Loss: 22.483335494995117\n",
            "tensor([ 0.3034, -3.0749,  1.7717], requires_grad=True)\n",
            "Loss: 22.483325958251953\n",
            "tensor([ 0.3034, -3.0749,  1.7717], requires_grad=True)\n",
            "Loss: 22.48331642150879\n",
            "tensor([ 0.3034, -3.0750,  1.7718], requires_grad=True)\n",
            "Loss: 22.483308792114258\n",
            "tensor([ 0.3034, -3.0750,  1.7718], requires_grad=True)\n",
            "Loss: 22.483301162719727\n",
            "tensor([ 0.3034, -3.0750,  1.7718], requires_grad=True)\n",
            "Loss: 22.483291625976562\n",
            "tensor([ 0.3034, -3.0750,  1.7718], requires_grad=True)\n",
            "Loss: 22.48328399658203\n",
            "tensor([ 0.3034, -3.0750,  1.7719], requires_grad=True)\n",
            "Loss: 22.4832763671875\n",
            "tensor([ 0.3034, -3.0750,  1.7719], requires_grad=True)\n",
            "Loss: 22.483266830444336\n",
            "tensor([ 0.3034, -3.0750,  1.7719], requires_grad=True)\n",
            "Loss: 22.483259201049805\n",
            "tensor([ 0.3034, -3.0750,  1.7720], requires_grad=True)\n",
            "Loss: 22.48324966430664\n",
            "tensor([ 0.3034, -3.0750,  1.7720], requires_grad=True)\n",
            "Loss: 22.483240127563477\n",
            "tensor([ 0.3034, -3.0750,  1.7720], requires_grad=True)\n",
            "Loss: 22.483232498168945\n",
            "tensor([ 0.3034, -3.0750,  1.7720], requires_grad=True)\n",
            "Loss: 22.48322296142578\n",
            "tensor([ 0.3034, -3.0750,  1.7721], requires_grad=True)\n",
            "Loss: 22.48321533203125\n",
            "tensor([ 0.3034, -3.0750,  1.7721], requires_grad=True)\n",
            "Loss: 22.48320770263672\n",
            "tensor([ 0.3034, -3.0750,  1.7721], requires_grad=True)\n",
            "Loss: 22.483198165893555\n",
            "tensor([ 0.3034, -3.0750,  1.7722], requires_grad=True)\n",
            "Loss: 22.483190536499023\n",
            "tensor([ 0.3034, -3.0751,  1.7722], requires_grad=True)\n",
            "Loss: 22.483179092407227\n",
            "tensor([ 0.3034, -3.0751,  1.7722], requires_grad=True)\n",
            "Loss: 22.483173370361328\n",
            "tensor([ 0.3034, -3.0751,  1.7722], requires_grad=True)\n",
            "Loss: 22.48316192626953\n",
            "tensor([ 0.3034, -3.0751,  1.7723], requires_grad=True)\n",
            "Loss: 22.483154296875\n",
            "tensor([ 0.3034, -3.0751,  1.7723], requires_grad=True)\n",
            "Loss: 22.4831485748291\n",
            "tensor([ 0.3034, -3.0751,  1.7723], requires_grad=True)\n",
            "Loss: 22.483139038085938\n",
            "tensor([ 0.3034, -3.0751,  1.7724], requires_grad=True)\n",
            "Loss: 22.483131408691406\n",
            "tensor([ 0.3034, -3.0751,  1.7724], requires_grad=True)\n",
            "Loss: 22.48311996459961\n",
            "tensor([ 0.3034, -3.0751,  1.7724], requires_grad=True)\n",
            "Loss: 22.483112335205078\n",
            "tensor([ 0.3034, -3.0751,  1.7724], requires_grad=True)\n",
            "Loss: 22.483104705810547\n",
            "tensor([ 0.3034, -3.0751,  1.7725], requires_grad=True)\n",
            "Loss: 22.483097076416016\n",
            "tensor([ 0.3035, -3.0751,  1.7725], requires_grad=True)\n",
            "Loss: 22.48308563232422\n",
            "tensor([ 0.3035, -3.0751,  1.7725], requires_grad=True)\n",
            "Loss: 22.483078002929688\n",
            "tensor([ 0.3035, -3.0751,  1.7726], requires_grad=True)\n",
            "Loss: 22.483068466186523\n",
            "tensor([ 0.3035, -3.0751,  1.7726], requires_grad=True)\n",
            "Loss: 22.48305892944336\n",
            "tensor([ 0.3035, -3.0752,  1.7726], requires_grad=True)\n",
            "Loss: 22.48305320739746\n",
            "tensor([ 0.3035, -3.0752,  1.7726], requires_grad=True)\n",
            "Loss: 22.483043670654297\n",
            "tensor([ 0.3035, -3.0752,  1.7727], requires_grad=True)\n",
            "Loss: 22.483036041259766\n",
            "tensor([ 0.3035, -3.0752,  1.7727], requires_grad=True)\n",
            "Loss: 22.4830265045166\n",
            "tensor([ 0.3035, -3.0752,  1.7727], requires_grad=True)\n",
            "Loss: 22.48301887512207\n",
            "tensor([ 0.3035, -3.0752,  1.7728], requires_grad=True)\n",
            "Loss: 22.48301124572754\n",
            "tensor([ 0.3035, -3.0752,  1.7728], requires_grad=True)\n",
            "Loss: 22.483001708984375\n",
            "tensor([ 0.3035, -3.0752,  1.7728], requires_grad=True)\n",
            "Loss: 22.482994079589844\n",
            "tensor([ 0.3035, -3.0752,  1.7728], requires_grad=True)\n",
            "Loss: 22.48298454284668\n",
            "tensor([ 0.3035, -3.0752,  1.7729], requires_grad=True)\n",
            "Loss: 22.482975006103516\n",
            "tensor([ 0.3035, -3.0752,  1.7729], requires_grad=True)\n",
            "Loss: 22.482967376708984\n",
            "tensor([ 0.3035, -3.0752,  1.7729], requires_grad=True)\n",
            "Loss: 22.48295783996582\n",
            "tensor([ 0.3035, -3.0752,  1.7729], requires_grad=True)\n",
            "Loss: 22.48295021057129\n",
            "tensor([ 0.3035, -3.0752,  1.7730], requires_grad=True)\n",
            "Loss: 22.482938766479492\n",
            "tensor([ 0.3035, -3.0752,  1.7730], requires_grad=True)\n",
            "Loss: 22.48293113708496\n",
            "tensor([ 0.3035, -3.0753,  1.7730], requires_grad=True)\n",
            "Loss: 22.48292350769043\n",
            "tensor([ 0.3035, -3.0753,  1.7731], requires_grad=True)\n",
            "Loss: 22.4829158782959\n",
            "tensor([ 0.3035, -3.0753,  1.7731], requires_grad=True)\n",
            "Loss: 22.482906341552734\n",
            "tensor([ 0.3035, -3.0753,  1.7731], requires_grad=True)\n",
            "Loss: 22.482898712158203\n",
            "tensor([ 0.3035, -3.0753,  1.7731], requires_grad=True)\n",
            "Loss: 22.482891082763672\n",
            "tensor([ 0.3035, -3.0753,  1.7732], requires_grad=True)\n",
            "Loss: 22.482881546020508\n",
            "tensor([ 0.3035, -3.0753,  1.7732], requires_grad=True)\n",
            "Loss: 22.482873916625977\n",
            "tensor([ 0.3035, -3.0753,  1.7732], requires_grad=True)\n",
            "Loss: 22.48286247253418\n",
            "tensor([ 0.3035, -3.0753,  1.7733], requires_grad=True)\n",
            "Loss: 22.48285484313965\n",
            "tensor([ 0.3035, -3.0753,  1.7733], requires_grad=True)\n",
            "Loss: 22.482847213745117\n",
            "tensor([ 0.3035, -3.0753,  1.7733], requires_grad=True)\n",
            "Loss: 22.482837677001953\n",
            "tensor([ 0.3035, -3.0753,  1.7733], requires_grad=True)\n",
            "Loss: 22.482831954956055\n",
            "tensor([ 0.3035, -3.0753,  1.7734], requires_grad=True)\n",
            "Loss: 22.482820510864258\n",
            "tensor([ 0.3035, -3.0753,  1.7734], requires_grad=True)\n",
            "Loss: 22.482812881469727\n",
            "tensor([ 0.3035, -3.0753,  1.7734], requires_grad=True)\n",
            "Loss: 22.482803344726562\n",
            "tensor([ 0.3035, -3.0754,  1.7735], requires_grad=True)\n",
            "Loss: 22.48279571533203\n",
            "tensor([ 0.3035, -3.0754,  1.7735], requires_grad=True)\n",
            "Loss: 22.482786178588867\n",
            "tensor([ 0.3035, -3.0754,  1.7735], requires_grad=True)\n",
            "Loss: 22.482776641845703\n",
            "tensor([ 0.3035, -3.0754,  1.7735], requires_grad=True)\n",
            "Loss: 22.482769012451172\n",
            "tensor([ 0.3035, -3.0754,  1.7736], requires_grad=True)\n",
            "Loss: 22.48276138305664\n",
            "tensor([ 0.3035, -3.0754,  1.7736], requires_grad=True)\n",
            "Loss: 22.48275375366211\n",
            "tensor([ 0.3035, -3.0754,  1.7736], requires_grad=True)\n",
            "Loss: 22.482742309570312\n",
            "tensor([ 0.3035, -3.0754,  1.7737], requires_grad=True)\n",
            "Loss: 22.482736587524414\n",
            "tensor([ 0.3035, -3.0754,  1.7737], requires_grad=True)\n",
            "Loss: 22.48272705078125\n",
            "tensor([ 0.3035, -3.0754,  1.7737], requires_grad=True)\n",
            "Loss: 22.48271942138672\n",
            "tensor([ 0.3035, -3.0754,  1.7737], requires_grad=True)\n",
            "Loss: 22.482707977294922\n",
            "tensor([ 0.3035, -3.0754,  1.7738], requires_grad=True)\n",
            "Loss: 22.482702255249023\n",
            "tensor([ 0.3035, -3.0754,  1.7738], requires_grad=True)\n",
            "Loss: 22.48269271850586\n",
            "tensor([ 0.3035, -3.0754,  1.7738], requires_grad=True)\n",
            "Loss: 22.482685089111328\n",
            "tensor([ 0.3035, -3.0754,  1.7739], requires_grad=True)\n",
            "Loss: 22.482675552368164\n",
            "tensor([ 0.3035, -3.0755,  1.7739], requires_grad=True)\n",
            "Loss: 22.482666015625\n",
            "tensor([ 0.3035, -3.0755,  1.7739], requires_grad=True)\n",
            "Loss: 22.48265838623047\n",
            "tensor([ 0.3035, -3.0755,  1.7739], requires_grad=True)\n",
            "Loss: 22.482650756835938\n",
            "tensor([ 0.3035, -3.0755,  1.7740], requires_grad=True)\n",
            "Loss: 22.482643127441406\n",
            "tensor([ 0.3035, -3.0755,  1.7740], requires_grad=True)\n",
            "Loss: 22.482633590698242\n",
            "tensor([ 0.3035, -3.0755,  1.7740], requires_grad=True)\n",
            "Loss: 22.482624053955078\n",
            "tensor([ 0.3035, -3.0755,  1.7741], requires_grad=True)\n",
            "Loss: 22.482616424560547\n",
            "tensor([ 0.3035, -3.0755,  1.7741], requires_grad=True)\n",
            "Loss: 22.482606887817383\n",
            "tensor([ 0.3035, -3.0755,  1.7741], requires_grad=True)\n",
            "Loss: 22.48259735107422\n",
            "tensor([ 0.3035, -3.0755,  1.7741], requires_grad=True)\n",
            "Loss: 22.482589721679688\n",
            "tensor([ 0.3035, -3.0755,  1.7742], requires_grad=True)\n",
            "Loss: 22.482580184936523\n",
            "tensor([ 0.3035, -3.0755,  1.7742], requires_grad=True)\n",
            "Loss: 22.482572555541992\n",
            "tensor([ 0.3035, -3.0755,  1.7742], requires_grad=True)\n",
            "Loss: 22.48256492614746\n",
            "tensor([ 0.3035, -3.0755,  1.7743], requires_grad=True)\n",
            "Loss: 22.482555389404297\n",
            "tensor([ 0.3035, -3.0755,  1.7743], requires_grad=True)\n",
            "Loss: 22.482545852661133\n",
            "tensor([ 0.3035, -3.0756,  1.7743], requires_grad=True)\n",
            "Loss: 22.48253631591797\n",
            "tensor([ 0.3035, -3.0756,  1.7743], requires_grad=True)\n",
            "Loss: 22.482532501220703\n",
            "tensor([ 0.3035, -3.0756,  1.7744], requires_grad=True)\n",
            "Loss: 22.482521057128906\n",
            "tensor([ 0.3035, -3.0756,  1.7744], requires_grad=True)\n",
            "Loss: 22.482513427734375\n",
            "tensor([ 0.3035, -3.0756,  1.7744], requires_grad=True)\n",
            "Loss: 22.48250389099121\n",
            "tensor([ 0.3035, -3.0756,  1.7745], requires_grad=True)\n",
            "Loss: 22.48249626159668\n",
            "tensor([ 0.3035, -3.0756,  1.7745], requires_grad=True)\n",
            "Loss: 22.482486724853516\n",
            "tensor([ 0.3035, -3.0756,  1.7745], requires_grad=True)\n",
            "Loss: 22.48247718811035\n",
            "tensor([ 0.3035, -3.0756,  1.7745], requires_grad=True)\n",
            "Loss: 22.48246955871582\n",
            "tensor([ 0.3035, -3.0756,  1.7746], requires_grad=True)\n",
            "Loss: 22.48246192932129\n",
            "tensor([ 0.3035, -3.0756,  1.7746], requires_grad=True)\n",
            "Loss: 22.482454299926758\n",
            "tensor([ 0.3035, -3.0756,  1.7746], requires_grad=True)\n",
            "Loss: 22.48244285583496\n",
            "tensor([ 0.3035, -3.0756,  1.7747], requires_grad=True)\n",
            "Loss: 22.48243522644043\n",
            "tensor([ 0.3035, -3.0756,  1.7747], requires_grad=True)\n",
            "Loss: 22.482425689697266\n",
            "tensor([ 0.3035, -3.0756,  1.7747], requires_grad=True)\n",
            "Loss: 22.482418060302734\n",
            "tensor([ 0.3035, -3.0757,  1.7747], requires_grad=True)\n",
            "Loss: 22.482410430908203\n",
            "tensor([ 0.3035, -3.0757,  1.7748], requires_grad=True)\n",
            "Loss: 22.48240089416504\n",
            "tensor([ 0.3035, -3.0757,  1.7748], requires_grad=True)\n",
            "Loss: 22.482391357421875\n",
            "tensor([ 0.3035, -3.0757,  1.7748], requires_grad=True)\n",
            "Loss: 22.482383728027344\n",
            "tensor([ 0.3035, -3.0757,  1.7749], requires_grad=True)\n",
            "Loss: 22.482376098632812\n",
            "tensor([ 0.3035, -3.0757,  1.7749], requires_grad=True)\n",
            "Loss: 22.48236656188965\n",
            "tensor([ 0.3035, -3.0757,  1.7749], requires_grad=True)\n",
            "Loss: 22.482358932495117\n",
            "tensor([ 0.3035, -3.0757,  1.7749], requires_grad=True)\n",
            "Loss: 22.482349395751953\n",
            "tensor([ 0.3035, -3.0757,  1.7750], requires_grad=True)\n",
            "Loss: 22.482341766357422\n",
            "tensor([ 0.3035, -3.0757,  1.7750], requires_grad=True)\n",
            "Loss: 22.482332229614258\n",
            "tensor([ 0.3035, -3.0757,  1.7750], requires_grad=True)\n",
            "Loss: 22.48232650756836\n",
            "tensor([ 0.3035, -3.0757,  1.7751], requires_grad=True)\n",
            "Loss: 22.482315063476562\n",
            "tensor([ 0.3035, -3.0757,  1.7751], requires_grad=True)\n",
            "Loss: 22.48230743408203\n",
            "tensor([ 0.3035, -3.0757,  1.7751], requires_grad=True)\n",
            "Loss: 22.4822998046875\n",
            "tensor([ 0.3035, -3.0757,  1.7751], requires_grad=True)\n",
            "Loss: 22.482290267944336\n",
            "tensor([ 0.3035, -3.0758,  1.7752], requires_grad=True)\n",
            "Loss: 22.482280731201172\n",
            "tensor([ 0.3035, -3.0758,  1.7752], requires_grad=True)\n",
            "Loss: 22.48227310180664\n",
            "tensor([ 0.3035, -3.0758,  1.7752], requires_grad=True)\n",
            "Loss: 22.482263565063477\n",
            "tensor([ 0.3035, -3.0758,  1.7753], requires_grad=True)\n",
            "Loss: 22.482255935668945\n",
            "tensor([ 0.3035, -3.0758,  1.7753], requires_grad=True)\n",
            "Loss: 22.482248306274414\n",
            "tensor([ 0.3035, -3.0758,  1.7753], requires_grad=True)\n",
            "Loss: 22.48223876953125\n",
            "tensor([ 0.3035, -3.0758,  1.7753], requires_grad=True)\n",
            "Loss: 22.482229232788086\n",
            "tensor([ 0.3035, -3.0758,  1.7754], requires_grad=True)\n",
            "Loss: 22.482219696044922\n",
            "tensor([ 0.3035, -3.0758,  1.7754], requires_grad=True)\n",
            "Loss: 22.48221206665039\n",
            "tensor([ 0.3035, -3.0758,  1.7754], requires_grad=True)\n",
            "Loss: 22.48220443725586\n",
            "tensor([ 0.3035, -3.0758,  1.7755], requires_grad=True)\n",
            "Loss: 22.482194900512695\n",
            "tensor([ 0.3035, -3.0758,  1.7755], requires_grad=True)\n",
            "Loss: 22.482187271118164\n",
            "tensor([ 0.3035, -3.0758,  1.7755], requires_grad=True)\n",
            "Loss: 22.482179641723633\n",
            "tensor([ 0.3035, -3.0758,  1.7755], requires_grad=True)\n",
            "Loss: 22.4821720123291\n",
            "tensor([ 0.3035, -3.0758,  1.7756], requires_grad=True)\n",
            "Loss: 22.482162475585938\n",
            "tensor([ 0.3035, -3.0759,  1.7756], requires_grad=True)\n",
            "Loss: 22.482152938842773\n",
            "tensor([ 0.3035, -3.0759,  1.7756], requires_grad=True)\n",
            "Loss: 22.482145309448242\n",
            "tensor([ 0.3035, -3.0759,  1.7757], requires_grad=True)\n",
            "Loss: 22.482135772705078\n",
            "tensor([ 0.3035, -3.0759,  1.7757], requires_grad=True)\n",
            "Loss: 22.482126235961914\n",
            "tensor([ 0.3035, -3.0759,  1.7757], requires_grad=True)\n",
            "Loss: 22.482118606567383\n",
            "tensor([ 0.3035, -3.0759,  1.7757], requires_grad=True)\n",
            "Loss: 22.48211097717285\n",
            "tensor([ 0.3035, -3.0759,  1.7758], requires_grad=True)\n",
            "Loss: 22.482101440429688\n",
            "tensor([ 0.3035, -3.0759,  1.7758], requires_grad=True)\n",
            "Loss: 22.482091903686523\n",
            "tensor([ 0.3035, -3.0759,  1.7758], requires_grad=True)\n",
            "Loss: 22.48208236694336\n",
            "tensor([ 0.3035, -3.0759,  1.7759], requires_grad=True)\n",
            "Loss: 22.48207664489746\n",
            "tensor([ 0.3035, -3.0759,  1.7759], requires_grad=True)\n",
            "Loss: 22.482067108154297\n",
            "tensor([ 0.3035, -3.0759,  1.7759], requires_grad=True)\n",
            "Loss: 22.482057571411133\n",
            "tensor([ 0.3035, -3.0759,  1.7759], requires_grad=True)\n",
            "Loss: 22.4820499420166\n",
            "tensor([ 0.3035, -3.0759,  1.7760], requires_grad=True)\n",
            "Loss: 22.48204231262207\n",
            "tensor([ 0.3035, -3.0759,  1.7760], requires_grad=True)\n",
            "Loss: 22.482030868530273\n",
            "tensor([ 0.3035, -3.0760,  1.7760], requires_grad=True)\n",
            "Loss: 22.482025146484375\n",
            "tensor([ 0.3035, -3.0760,  1.7761], requires_grad=True)\n",
            "Loss: 22.48201560974121\n",
            "tensor([ 0.3035, -3.0760,  1.7761], requires_grad=True)\n",
            "Loss: 22.482006072998047\n",
            "tensor([ 0.3035, -3.0760,  1.7761], requires_grad=True)\n",
            "Loss: 22.481998443603516\n",
            "tensor([ 0.3035, -3.0760,  1.7761], requires_grad=True)\n",
            "Loss: 22.481990814208984\n",
            "tensor([ 0.3035, -3.0760,  1.7762], requires_grad=True)\n",
            "Loss: 22.48198127746582\n",
            "tensor([ 0.3035, -3.0760,  1.7762], requires_grad=True)\n",
            "Loss: 22.481971740722656\n",
            "tensor([ 0.3035, -3.0760,  1.7762], requires_grad=True)\n",
            "Loss: 22.481964111328125\n",
            "tensor([ 0.3035, -3.0760,  1.7763], requires_grad=True)\n",
            "Loss: 22.48195457458496\n",
            "tensor([ 0.3035, -3.0760,  1.7763], requires_grad=True)\n",
            "Loss: 22.481948852539062\n",
            "tensor([ 0.3035, -3.0760,  1.7763], requires_grad=True)\n",
            "Loss: 22.4819393157959\n",
            "tensor([ 0.3035, -3.0760,  1.7763], requires_grad=True)\n",
            "Loss: 22.481929779052734\n",
            "tensor([ 0.3035, -3.0760,  1.7764], requires_grad=True)\n",
            "Loss: 22.481922149658203\n",
            "tensor([ 0.3035, -3.0760,  1.7764], requires_grad=True)\n",
            "Loss: 22.481914520263672\n",
            "tensor([ 0.3035, -3.0760,  1.7764], requires_grad=True)\n",
            "Loss: 22.48190689086914\n",
            "tensor([ 0.3035, -3.0761,  1.7765], requires_grad=True)\n",
            "Loss: 22.481895446777344\n",
            "tensor([ 0.3035, -3.0761,  1.7765], requires_grad=True)\n",
            "Loss: 22.481887817382812\n",
            "tensor([ 0.3035, -3.0761,  1.7765], requires_grad=True)\n",
            "Loss: 22.48187828063965\n",
            "tensor([ 0.3035, -3.0761,  1.7765], requires_grad=True)\n",
            "Loss: 22.481870651245117\n",
            "tensor([ 0.3035, -3.0761,  1.7766], requires_grad=True)\n",
            "Loss: 22.481861114501953\n",
            "tensor([ 0.3035, -3.0761,  1.7766], requires_grad=True)\n",
            "Loss: 22.481855392456055\n",
            "tensor([ 0.3035, -3.0761,  1.7766], requires_grad=True)\n",
            "Loss: 22.481843948364258\n",
            "tensor([ 0.3035, -3.0761,  1.7767], requires_grad=True)\n",
            "Loss: 22.481836318969727\n",
            "tensor([ 0.3035, -3.0761,  1.7767], requires_grad=True)\n",
            "Loss: 22.481826782226562\n",
            "tensor([ 0.3035, -3.0761,  1.7767], requires_grad=True)\n",
            "Loss: 22.48181915283203\n",
            "tensor([ 0.3035, -3.0761,  1.7767], requires_grad=True)\n",
            "Loss: 22.481809616088867\n",
            "tensor([ 0.3035, -3.0761,  1.7768], requires_grad=True)\n",
            "Loss: 22.481800079345703\n",
            "tensor([ 0.3035, -3.0761,  1.7768], requires_grad=True)\n",
            "Loss: 22.481794357299805\n",
            "tensor([ 0.3035, -3.0761,  1.7768], requires_grad=True)\n",
            "Loss: 22.48178482055664\n",
            "tensor([ 0.3035, -3.0761,  1.7769], requires_grad=True)\n",
            "Loss: 22.481775283813477\n",
            "tensor([ 0.3035, -3.0762,  1.7769], requires_grad=True)\n",
            "Loss: 22.481765747070312\n",
            "tensor([ 0.3035, -3.0762,  1.7769], requires_grad=True)\n",
            "Loss: 22.481760025024414\n",
            "tensor([ 0.3035, -3.0762,  1.7769], requires_grad=True)\n",
            "Loss: 22.481748580932617\n",
            "tensor([ 0.3035, -3.0762,  1.7770], requires_grad=True)\n",
            "Loss: 22.48174285888672\n",
            "tensor([ 0.3035, -3.0762,  1.7770], requires_grad=True)\n",
            "Loss: 22.481733322143555\n",
            "tensor([ 0.3035, -3.0762,  1.7770], requires_grad=True)\n",
            "Loss: 22.481725692749023\n",
            "tensor([ 0.3035, -3.0762,  1.7771], requires_grad=True)\n",
            "Loss: 22.481718063354492\n",
            "tensor([ 0.3035, -3.0762,  1.7771], requires_grad=True)\n",
            "Loss: 22.481708526611328\n",
            "tensor([ 0.3035, -3.0762,  1.7771], requires_grad=True)\n",
            "Loss: 22.48169708251953\n",
            "tensor([ 0.3035, -3.0762,  1.7771], requires_grad=True)\n",
            "Loss: 22.481691360473633\n",
            "tensor([ 0.3035, -3.0762,  1.7772], requires_grad=True)\n",
            "Loss: 22.48168182373047\n",
            "tensor([ 0.3035, -3.0762,  1.7772], requires_grad=True)\n",
            "Loss: 22.481672286987305\n",
            "tensor([ 0.3035, -3.0762,  1.7772], requires_grad=True)\n",
            "Loss: 22.481664657592773\n",
            "tensor([ 0.3035, -3.0762,  1.7773], requires_grad=True)\n",
            "Loss: 22.481657028198242\n",
            "tensor([ 0.3035, -3.0762,  1.7773], requires_grad=True)\n",
            "Loss: 22.481647491455078\n",
            "tensor([ 0.3035, -3.0763,  1.7773], requires_grad=True)\n",
            "Loss: 22.481637954711914\n",
            "tensor([ 0.3035, -3.0763,  1.7773], requires_grad=True)\n",
            "Loss: 22.48162841796875\n",
            "tensor([ 0.3035, -3.0763,  1.7774], requires_grad=True)\n",
            "Loss: 22.48162269592285\n",
            "tensor([ 0.3035, -3.0763,  1.7774], requires_grad=True)\n",
            "Loss: 22.481613159179688\n",
            "tensor([ 0.3035, -3.0763,  1.7774], requires_grad=True)\n",
            "Loss: 22.481603622436523\n",
            "tensor([ 0.3035, -3.0763,  1.7775], requires_grad=True)\n",
            "Loss: 22.481595993041992\n",
            "tensor([ 0.3035, -3.0763,  1.7775], requires_grad=True)\n",
            "Loss: 22.48158836364746\n",
            "tensor([ 0.3035, -3.0763,  1.7775], requires_grad=True)\n",
            "Loss: 22.481576919555664\n",
            "tensor([ 0.3035, -3.0763,  1.7775], requires_grad=True)\n",
            "Loss: 22.481569290161133\n",
            "tensor([ 0.3035, -3.0763,  1.7776], requires_grad=True)\n",
            "Loss: 22.4815616607666\n",
            "tensor([ 0.3035, -3.0763,  1.7776], requires_grad=True)\n",
            "Loss: 22.48155403137207\n",
            "tensor([ 0.3035, -3.0763,  1.7776], requires_grad=True)\n",
            "Loss: 22.481544494628906\n",
            "tensor([ 0.3035, -3.0763,  1.7777], requires_grad=True)\n",
            "Loss: 22.481536865234375\n",
            "tensor([ 0.3035, -3.0763,  1.7777], requires_grad=True)\n",
            "Loss: 22.481529235839844\n",
            "tensor([ 0.3035, -3.0763,  1.7777], requires_grad=True)\n",
            "Loss: 22.481517791748047\n",
            "tensor([ 0.3035, -3.0764,  1.7777], requires_grad=True)\n",
            "Loss: 22.481510162353516\n",
            "tensor([ 0.3035, -3.0764,  1.7778], requires_grad=True)\n",
            "Loss: 22.48150062561035\n",
            "tensor([ 0.3035, -3.0764,  1.7778], requires_grad=True)\n",
            "Loss: 22.48149299621582\n",
            "tensor([ 0.3035, -3.0764,  1.7778], requires_grad=True)\n",
            "Loss: 22.48148536682129\n",
            "tensor([ 0.3035, -3.0764,  1.7779], requires_grad=True)\n",
            "Loss: 22.481475830078125\n",
            "tensor([ 0.3035, -3.0764,  1.7779], requires_grad=True)\n",
            "Loss: 22.48146629333496\n",
            "tensor([ 0.3035, -3.0764,  1.7779], requires_grad=True)\n",
            "Loss: 22.48145866394043\n",
            "tensor([ 0.3035, -3.0764,  1.7779], requires_grad=True)\n",
            "Loss: 22.4814510345459\n",
            "tensor([ 0.3035, -3.0764,  1.7780], requires_grad=True)\n",
            "Loss: 22.481441497802734\n",
            "tensor([ 0.3035, -3.0764,  1.7780], requires_grad=True)\n",
            "Loss: 22.48143196105957\n",
            "tensor([ 0.3035, -3.0764,  1.7780], requires_grad=True)\n",
            "Loss: 22.48142433166504\n",
            "tensor([ 0.3035, -3.0764,  1.7780], requires_grad=True)\n",
            "Loss: 22.481416702270508\n",
            "tensor([ 0.3035, -3.0764,  1.7781], requires_grad=True)\n",
            "Loss: 22.481407165527344\n",
            "tensor([ 0.3035, -3.0764,  1.7781], requires_grad=True)\n",
            "Loss: 22.481399536132812\n",
            "tensor([ 0.3035, -3.0764,  1.7781], requires_grad=True)\n",
            "Loss: 22.48138999938965\n",
            "tensor([ 0.3035, -3.0765,  1.7782], requires_grad=True)\n",
            "Loss: 22.481380462646484\n",
            "tensor([ 0.3035, -3.0765,  1.7782], requires_grad=True)\n",
            "Loss: 22.481372833251953\n",
            "tensor([ 0.3035, -3.0765,  1.7782], requires_grad=True)\n",
            "Loss: 22.48136329650879\n",
            "tensor([ 0.3035, -3.0765,  1.7782], requires_grad=True)\n",
            "Loss: 22.48135757446289\n",
            "tensor([ 0.3035, -3.0765,  1.7783], requires_grad=True)\n",
            "Loss: 22.481348037719727\n",
            "tensor([ 0.3035, -3.0765,  1.7783], requires_grad=True)\n",
            "Loss: 22.481340408325195\n",
            "tensor([ 0.3035, -3.0765,  1.7783], requires_grad=True)\n",
            "Loss: 22.48133087158203\n",
            "tensor([ 0.3035, -3.0765,  1.7784], requires_grad=True)\n",
            "Loss: 22.481321334838867\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-229-b27323130781>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-226-58b9afc5eef8>\u001b[0m in \u001b[0;36mstep_forward\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss: {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    429\u001b[0m             )\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     def backward(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_current_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mguard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DisableFuncTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    593\u001b[0m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                         \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{{:.{PRINT_OPTS.precision}f}}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig,ax = plt.subplots()\n",
        "ax.scatter(x, target)\n",
        "ax.scatter(x, pred.detach().numpy(), color=\"red\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "wTRHhTnukO_H",
        "outputId": "d16d6a10-883c-4271-e13d-d165021ab274"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7962d25cc220>"
            ]
          },
          "metadata": {},
          "execution_count": 230
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jIPbFIizlHBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}